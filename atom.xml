<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Marshall</title>
  <subtitle>Comm. Tech. Blog</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://marshallcomm.github.io/"/>
  <updated>2017-08-04T11:46:18.157Z</updated>
  <id>https://marshallcomm.github.io/</id>
  
  <author>
    <name>Marshall</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Polar Code（17）高斯近似（2）</title>
    <link href="https://marshallcomm.github.io/2017/08/04/polar-code-17-gaussian-approximation2/"/>
    <id>https://marshallcomm.github.io/2017/08/04/polar-code-17-gaussian-approximation2/</id>
    <published>2017-08-04T07:51:43.000Z</published>
    <updated>2017-08-04T11:46:18.157Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><br>“假设全零发送”，这个看似简单以至于在许多论文里都一笔带过的假设，却引发了最近的一段思考。这个话题源于<a href="http://marshallcomm.cn/2017/03/07/polar-code-4-encoding-chan-rel-est/" target="_blank" rel="external">《Polar Code（4）编码之极化信道可靠性估计》</a>一文评论区的讨论。这段讨论是十分有益的，并把这一话题不断地引向了深入。</p><h1 id="由个别到一般"><a href="#由个别到一般" class="headerlink" title="由个别到一般"></a>由个别到一般</h1><p><br>从基本的高斯信道说起，对于一个BAWGN信道，其接收符号$y$表示为：</p><script type="math/tex;mode=display">\begin{align}
y=s+z
\end{align}</script><p>其中$z$为服从$N\left( 0,{ {\sigma }^{2}} \right)$的高斯白噪声，$s$为调制符号，调制方式采用BPSK。$s=1-2x$或者$s=2x-1$取决于怎样定义BPSK映射。若定义BPSK映射规则为：</p><p>\begin{align}<br>s=\left\{ \begin{matrix}<br>+1, x=0 \\<br>-1, x=1 \\<br>\end{matrix} \right.<br>\end{align}</p><p>其中$x\in \left\{ 0,1 \right\}$为编码比特，则接收符号$y$重写为：</p><script type="math/tex;mode=display">\begin{align}
y=\left( 1-2x \right)+z
\end{align}</script><a id="more"></a><p>下面考察接收符号$y$的对数似然比LLR：</p><script type="math/tex;mode=display">\begin{align}
LLR\left( y \right)=\ln \frac{p\left( y|x=0 \right)}{p\left( y|x=1 \right)}=\ln \frac{\frac{1}{\sqrt{2\pi { {\sigma }^{2}}}}{ {e}^{-\frac{\left( y-\left( 1-2x \right) \right)}{2{ {\sigma }^{2}}}}}\left| x=0 \right.}{\frac{1}{\sqrt{2\pi { {\sigma }^{2}}}}{ {e}^{-\frac{\left( y-\left( 1-2x \right) \right)}{2{ {\sigma }^{2}}}}}|x=1}=\frac{2}{ { {\sigma }^{2}}}y
\end{align}</script><p>接收符号$y$是服从$N\left( a,{ {\sigma }^{2}} \right)$的高斯随机变量，$a=E\left( y \right)$为$y$的均值，而$LLR\left( y \right)$也是一个高斯随机变量，其均值和方差取决于接收符号$y$的均值和方差。下面考察$y=\left( 1-2x \right)+z$的均值和方差。</p><p>现在已知：$E\left( z \right)=0,Var\left( z \right)={ {\sigma }^{2}}$。</p><h2 id="y的均值"><a href="#y的均值" class="headerlink" title="y的均值"></a>y的均值</h2><p><br><script type="math/tex">\begin{align}
E\left( y \right)=E\left( 1-2x \right)+E\left( z \right)=E\left( 1-2x \right)
\end{align}</script></p><p>目前$x$还是未知的，要想求出$E\left( y \right)$，就得进一步具体化，到现在就不得不做个假设了。其中一个最简单的假设就是，“假设全零发送”。于是$y$的均值为：</p><script type="math/tex;mode=display">\begin{align}
E\left( y \right)=E\left( 1-2x \right)=1
\end{align}</script><h2 id="y的方差"><a href="#y的方差" class="headerlink" title="y的方差"></a>y的方差</h2><p><br>在全零发送的假设下，$\left( 1-2x \right)$总是等于1，$z$在$y$中是唯一的变量，则</p><script type="math/tex;mode=display">\begin{align}
Var\left( y \right)=Var\left( z \right)={ {\sigma }^{2}}
\end{align}</script><p>现在已经得到$E\left( y \right)$和$Var\left( y \right)$，下面继续考察$LLR\left( y \right)$的均值和方差。</p><h2 id="LLR-y-的均值"><a href="#LLR-y-的均值" class="headerlink" title="LLR(y)的均值"></a>LLR(y)的均值</h2><p><br><script type="math/tex">\begin{align}
E\left[ LLR\left( y \right) \right]=E\left( \frac{2}{ { {\sigma }^{2}}}y \right)=\frac{2}{ { {\sigma }^{2}}}E\left( y \right)=\frac{2}{ { {\sigma }^{2}}}
\end{align}</script></p><h2 id="LLR-y-的方差"><a href="#LLR-y-的方差" class="headerlink" title="LLR(y)的方差"></a>LLR(y)的方差</h2><p><br><script type="math/tex">\begin{align}
Var\left[ LLR\left( y \right) \right]=Var\left( \frac{2}{ { {\sigma }^{2}}}y \right)={ {\left( \frac{2}{ { {\sigma }^{2}}} \right)}^{2}}Var\left( y \right)= & \frac{4}{ { {\sigma }^{4}}}\cdot { {\sigma }^{2}}=\frac{4}{ { {\sigma }^{2}}}
\end{align}</script></p><p>观察式（8）和（9），怎么这么巧：</p><p><br><script type="math/tex">\begin{align}
Var\left[ LLR\left( y \right) \right]=2E\left[ LLR\left( y \right) \right]
\end{align}</script></p><p>上式说明$LLR\left( y \right)$的方差是其均值的2倍。</p><p><strong>小结1</strong>：在式（2）所示的BPSK映射规则下，只有在“全零发送”的假设条件下，式（10）才成立。否则，假如把全零序列中某几个元素替换为1，变成混合的0/1序列，式（10）就不一定成立了。若1的个数大于0的个数，则$y$的均值将会是负值；若为全1序列，则$y$的均值为-1。</p><p>“全零发送”的假设作为一个特例，得到$LLR\left( y \right)$的方差是其均值的2倍的结论，有什么意义呢？个人认为，许多论文叙述这一段，是为了引出“高斯近似”。但以上的叙述都不是高斯近似，而是作为铺垫，作为利用高斯近似的引子。</p><p><strong>小结2</strong>：上文由全零发送的假设，得到了一个特例之下的结论：<strong>$LLR\left( y \right)$方差是其均值的2倍</strong>。这个结论好像在哪听说过，对，是高斯近似。高斯近似法脱胎于密度进化法，必然要满足密度进化法的对称条件，该对称条件可简化为${ {\sigma }^{2}}=2m$，即<strong>$LLR\left( y \right)$方差是其均值的2倍</strong>。一不小心，全零发送假设的特例下，满足了高斯近似的条件，如下图所示。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170804/162218468.jpg" alt="mark"></p><p>这仅仅是个特例。这是由个别指向了一般规律，但反过来还不能成立。</p><h1 id="由一般到个别"><a href="#由一般到个别" class="headerlink" title="由一般到个别"></a>由一般到个别</h1><p><br>现在要想让这个一般规律适用于所有的事例，则需要另一个假设：<strong>令每个子信道的LLR都服从方差为均值2倍的高斯分布</strong>，即</p><p><br><script type="math/tex">\begin{align}
L_{N}^{\left( i \right)}\sim N\left( m_{N}^{\left( i \right)},2m_{N}^{\left( i \right)} \right)
\end{align}</script></p><p>其中，$m_{1}^{\left( 1 \right)}=\frac{2}{ { {\sigma }^{2}}}$。这就是“<strong>高斯近似假设</strong>”。</p><p>每个子信道（每个比特）都服从这个一般规律，那么上面那张图就可以改为：</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170804/162521216.jpg" alt="mark"></p><p>这是由一般规律指向个别，以至于指向了所有可能的比特组合。</p><p>利用这个一般规律来重新构造各个子信道。具体的构造方法就是通过式（12~14）计算各个子信道的均值，由此得到各个子信道的方差，从而得到各个子信道的概率密度函数，最后进一步求得各个子信道的错误概率。</p><script type="math/tex;mode=display">\begin{align}
m_{2N}^{\left( 2i\text{-}1 \right)}={ {\varphi }^{-1}}\left( 1-{ {\left[ 1-\varphi \left( m_{N}^{\left( i \right)} \right) \right]}^{2}} \right)
\end{align}</script><script type="math/tex;mode=display">\begin{align}
m_{2N}^{\left( 2i \right)}=2m_{N}^{\left( i \right)}
\end{align}</script><script type="math/tex;mode=display">\begin{align}
m_{1}^{\left( 1 \right)}={2}/{ { {\sigma }^{2}}}\;
\end{align}</script><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p><br>如此，由一个个别现象指向了一个特例之下的结论。恰好，这个结论正是一个一般规律。我们正好希望用这个一般规律来构造所有的子信道，让所有子信道都适用于这个一般规律。更进一步地，把高斯近似假设和信道极化原理相结合，就是式（12~14）所呈现的样子。</p><p>个人认为，即使没有“由个别到一般”的那些叙述，而是一上来直接利用高斯近似假设来构造子信道都是可以的。所以，有关于全零假设的那些叙述可有可无，删掉也无妨，不要被这段叙述所迷惑。</p><h1 id="相关链接："><a href="#相关链接：" class="headerlink" title="相关链接："></a>相关链接：</h1><p><br><a href="http://marshallcomm.cn/2017/03/07/polar-code-4-encoding-chan-rel-est/" target="_blank" rel="external">《Polar Code（4）编码之极化信道可靠性估计》</a><br><a href="http://marshallcomm.cn/2017/03/17/polar-code-8-gaussian-approximation/" target="_blank" rel="external">《Polar Code（8）高斯近似》</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --&gt;&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;&lt;br&gt;“假设全零发送”，这个看似简单以至于在许多论文里都一笔带过的假设，却引发了最近的一段思考。这个话题源于&lt;a href=&quot;http://marshallcomm.cn/2017/03/07/polar-code-4-encoding-chan-rel-est/&quot;&gt;《Polar Code（4）编码之极化信道可靠性估计》&lt;/a&gt;一文评论区的讨论。这段讨论是十分有益的，并把这一话题不断地引向了深入。&lt;/p&gt;&lt;h1 id=&quot;由个别到一般&quot;&gt;&lt;a href=&quot;#由个别到一般&quot; class=&quot;headerlink&quot; title=&quot;由个别到一般&quot;&gt;&lt;/a&gt;由个别到一般&lt;/h1&gt;&lt;p&gt;&lt;br&gt;从基本的高斯信道说起，对于一个BAWGN信道，其接收符号$y$表示为：&lt;/p&gt;&lt;script type=&quot;math/tex;mode=display&quot;&gt;\begin{align}
y=s+z
\end{align}&lt;/script&gt;&lt;p&gt;其中$z$为服从$N\left( 0,{ {\sigma }^{2}} \right)$的高斯白噪声，$s$为调制符号，调制方式采用BPSK。$s=1-2x$或者$s=2x-1$取决于怎样定义BPSK映射。若定义BPSK映射规则为：&lt;/p&gt;&lt;p&gt;\begin{align}&lt;br&gt;s=\left\{ \begin{matrix}&lt;br&gt;+1, x=0 \\&lt;br&gt;-1, x=1 \\&lt;br&gt;\end{matrix} \right.&lt;br&gt;\end{align}&lt;/p&gt;&lt;p&gt;其中$x\in \left\{ 0,1 \right\}$为编码比特，则接收符号$y$重写为：&lt;/p&gt;&lt;script type=&quot;math/tex;mode=display&quot;&gt;\begin{align}
y=\left( 1-2x \right)+z
\end{align}&lt;/script&gt;
    
    </summary>
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/categories/Polar-Code/"/>
    
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/tags/Polar-Code/"/>
    
  </entry>
  
  <entry>
    <title>更换评论系统</title>
    <link href="https://marshallcomm.github.io/2017/07/27/change-comment-system/"/>
    <id>https://marshallcomm.github.io/2017/07/27/change-comment-system/</id>
    <published>2017-07-27T02:08:40.000Z</published>
    <updated>2017-08-04T09:06:59.721Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --><p>本博客使用了第三方评论系统，网易云跟帖将在2017年8月1日关闭，也就是说云跟帖倒闭了。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170727/101036290.png" alt="mark"></p><p>今天更换了评论系统，朋友们可以继续留言。但遗憾是，由于新的评论系统不支持数据导入，意味着从前所有的评论数据将丢失。</p><p>评论系统对一个博客来说还是比较重要的，它给人们提供了交流的平台。在过去的几个月里，许多研究极化码的朋友在博客里参与讨论，我也从中获益良多。许多朋友也指出我的错误，我了解到以后也一一改正，使文章更完善。</p><p>感谢所有曾经参与评论的朋友。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --&gt;&lt;p&gt;本博客使用了第三方评论系统，网易云跟帖将在2017年8月1日关闭，也就是说云跟帖倒闭了。&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;http://olyzl84
    
    </summary>
    
      <category term="Blog" scheme="https://marshallcomm.github.io/categories/Blog/"/>
    
    
      <category term="Blog" scheme="https://marshallcomm.github.io/tags/Blog/"/>
    
  </entry>
  
  <entry>
    <title>Polar Code（16）3GPP RAN1 adhoc#2</title>
    <link href="https://marshallcomm.github.io/2017/07/01/polar-code-16-3gpp-ran1-adhoc2/"/>
    <id>https://marshallcomm.github.io/2017/07/01/polar-code-16-3gpp-ran1-adhoc2/</id>
    <published>2017-07-01T02:20:29.000Z</published>
    <updated>2017-08-04T09:06:29.919Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --><p>3GPP RAN1 ad hoc#2会议于6月27~30日在青岛召开。关于Polar Code达成如下结论：</p><h1 id="Code-construction"><a href="#Code-construction" class="headerlink" title="Code construction"></a>Code construction</h1><p><br><img src="http://olyzl8414.bkt.clouddn.com/blog/20170704/102252079.png" alt="mark"></p><a id="more"></a><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170704/102419678.png" alt="mark"></p><h1 id="Sequence-design"><a href="#Sequence-design" class="headerlink" title="Sequence design"></a>Sequence design</h1><p><br><img src="http://olyzl8414.bkt.clouddn.com/blog/20170704/102453611.png" alt="mark"></p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170704/102504190.png" alt="mark"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --&gt;&lt;p&gt;3GPP RAN1 ad hoc#2会议于6月27~30日在青岛召开。关于Polar Code达成如下结论：&lt;/p&gt;&lt;h1 id=&quot;Code-construction&quot;&gt;&lt;a href=&quot;#Code-construction&quot; class=&quot;headerlink&quot; title=&quot;Code construction&quot;&gt;&lt;/a&gt;Code construction&lt;/h1&gt;&lt;p&gt;&lt;br&gt;&lt;img src=&quot;http://olyzl8414.bkt.clouddn.com/blog/20170704/102252079.png&quot; alt=&quot;mark&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="3GPP_PolarCode" scheme="https://marshallcomm.github.io/categories/3GPP-PolarCode/"/>
    
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/tags/Polar-Code/"/>
    
      <category term="3GPP" scheme="https://marshallcomm.github.io/tags/3GPP/"/>
    
  </entry>
  
  <entry>
    <title>Polar Code（15）3GPP RAN1#89</title>
    <link href="https://marshallcomm.github.io/2017/05/19/polar-code-15-3gpp-ran1-89/"/>
    <id>https://marshallcomm.github.io/2017/05/19/polar-code-15-3gpp-ran1-89/</id>
    <published>2017-05-19T01:53:07.000Z</published>
    <updated>2017-08-04T09:06:23.250Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><br>3GPP标准化会议于5月15~19日在杭州召开。本周在杭州参加3GPP RAN1 #89次会议，亲历了5G标准化进程中的一个时间点。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170529/095532334.JPG" title="3GPP RAN1#89 主会场（杭州）"></p><a id="more"></a><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170529/095722749.JPG" title="3GPP RAN1#89 信道编码分会场"></p><p>本文简要介绍polar code在3GPP 5G NR讨论的最新进展。</p><h1 id="Code-construction"><a href="#Code-construction" class="headerlink" title="Code construction"></a>Code construction</h1><p><br>本周召开的RAN1 #89会议，<strong>关于Code construction达成的结论为：</strong></p><p><strong>对于下行链路：</strong></p><ul><li>J’的长度为3或6（下次会议再进一步做出选择）；</li><li>若J’=6，工作假设：J+J’bits以分布式的方式分布（在编码结构中支持Early termination）（不排除非分布式的方式）；</li><li>若J’=3，J+J’bits是否采用分布式的方式分布（在编码结构中支持Early termination）有待进一步研究。</li></ul><p>在编码结构中，J+J’bits以分布式的方式插入到信息比特中以实现Early termination的方案：</p><ul><li>支持者：DCM, Nokia, HW, ZTE, CATT, IDC, CL, NEC, Mediatek, Accelercomm, Spreadtrum</li><li>反对者：Intel, LG, QC, Eri, Sams, Fuji, ETRI, Tsofun, IAESI</li></ul><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170529/100741806.PNG" alt="mark"></p><h1 id="Sequence-design"><a href="#Sequence-design" class="headerlink" title="Sequence design"></a>Sequence design</h1><p><br><strong>关于Sequence design本次会议达成的结论为：</strong></p><ul><li><strong>工作假设（1）</strong>：一个母码长度对应一个single fixed sequence，以提供信息比特和冻结比特的选择</li><li>多个不同母码长度对应着一个固定序列（fixed sequences）的集合，这些固定序列来源于“single reference mother code size”，<ul><li>单参考母码长度的最大值为512或64（下次会议进一步确定）。</li><li>如果修改上述<strong>工作假设（1）</strong>，使得对于最大母码长度存在多于一个的序列，则由其他母码长度派生出额外的序列集合。</li></ul></li><li>选择序列时，至少考虑已知的CCE大小，如果可能，考虑到典型的有效载荷。</li></ul><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170529/101358568.JPG" alt="mark"></p><h1 id="Rate-matching"><a href="#Rate-matching" class="headerlink" title="Rate matching"></a>Rate matching</h1><p><br><strong>关于速率匹配方案RAN1今后使用的术语：</strong></p><p><strong>Puncturing</strong>：凿孔比特是指那些不传输的编码比特，接收端对于这些不传输的比特是<strong>未知的</strong>，相应的LLR被设置为0；</p><p><strong>Shortening</strong>：将输入比特设定为已知，接收端对于这些不传输的比特是<strong>已知的</strong>，相应的LLR设置为一个较大的值。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170529/101526024.JPG" alt="mark"></p><p>关于这两种凿孔方案有必要再交代一下。博文<a href="http://marshallcomm.cn/2017/03/21/polar-code-10-rcpp/" target="_blank" rel="external">《Polar Code（10）速率适配的凿孔极化码》</a>中提到过，极化码的凿孔方案分为两类：一类被称为“C0”（capacity-zero）凿孔模式，就是RAN1在此定义的Puncturing方案；另一类被称为“C1”（capacity-one）凿孔模式，就是RAN1在此定义的Shortening方案。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170529/101624100.JPG" alt="mark"></p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170529/101659864.JPG" alt="mark"></p><p><strong>本次会议关于速率匹配达成的结论：</strong></p><p>码块分段之后（如果有的话）：</p><ul><li>$K$是信息比特数（包括CRC）</li><li>$M$是传输的编码比特数</li><li>${ {N}_{DM}}$是满足2的幂次方并且大于等于$M$的最小值</li><li>${ {N}_{M}}$是<ul><li>${ { {N}_{DM}}}/{2}\;$，如果$M&lt;\beta *{ { {N}_{DM}}}/{2}\;$且${K}/{M}\;&lt;{ {R}_{repthr}},1\le \beta &lt;2$（准确的$\beta $有待进一步研究；不排除$\beta $是${ {N}_{DM}}$的函数）</li><li>否则，${ {N}_{DM}}$</li><li>${ {R}_{repthr}}$的值有待进一步研究；不排除${ {R}_{repthr}}=0$</li></ul></li><li>${ {N}_{R}}$是满足2的幂次方并且大于等于${K}/{ { {R}_{\min }}}\;$的最小值<ul><li>${ {R}_{\min }}$是所支持的最小码率</li><li>$\sim {1}/{12\le }\;{ {R}_{\min }}\le \sim {1}/{5}\;$，准确值有待进一步研究</li></ul></li><li>${ {N}_{\max }}$是所支持的最大母码长度</li><li>母码长度$N$由$\min \left( { {N}_{M}},{ {N}_{R}},{ {N}_{\max }} \right)$确定</li><li>当$M&gt;N$时，采用重复（<strong>Repetition</strong>）编码</li><li>当$M&lt;N$时，采用Puncturing or Shortening：<ul><li>低码率时采用<strong>Puncturing</strong>，例如当码率小于等于${ {R}_{psthr}}$时，和或其他条件</li><li>高码率时采用<strong>Shortening</strong>，例如当码率大于${ {R}_{psthr}}$时，和或其他条件</li><li>${ {R}_{psthr}}$的值有待进一步研究</li></ul></li></ul><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --&gt;&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;&lt;br&gt;3GPP标准化会议于5月15~19日在杭州召开。本周在杭州参加3GPP RAN1 #89次会议，亲历了5G标准化进程中的一个时间点。&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;http://olyzl8414.bkt.clouddn.com/blog/20170529/095532334.JPG&quot; title=&quot;3GPP RAN1#89 主会场（杭州）&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="3GPP_PolarCode" scheme="https://marshallcomm.github.io/categories/3GPP-PolarCode/"/>
    
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/tags/Polar-Code/"/>
    
      <category term="3GPP" scheme="https://marshallcomm.github.io/tags/3GPP/"/>
    
  </entry>
  
  <entry>
    <title>Polar Code（14）3GPP RAN1#88bis</title>
    <link href="https://marshallcomm.github.io/2017/05/15/polar-code-14-3gpp-ran1-88b/"/>
    <id>https://marshallcomm.github.io/2017/05/15/polar-code-14-3gpp-ran1-88b/</id>
    <published>2017-05-15T01:25:33.000Z</published>
    <updated>2017-08-04T09:06:05.657Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><br>RAN1#87次会议已将Polar code确定为eMBB场景下控制信道的信道编码，因此3GPP对极化码的讨论并不是在单纯地讨论编码理论，而是在讨论极化码在5G NR控制信道框架下的应用。所以随着3GPP对极化码讨论的深入，关于极化码达成的结论会自然地和控制信道的特性结合在一起。也就是说，你所看到的3GPP关于极化码达成的结论，未必是Polar code本身应该具有的，但它一定是<strong>5G NR控制信道下的Polar code</strong>应该具有的。所以仍然有必要把学术界研究的极化码与工程界研究的极化码做个区分。</p><p>言归正传，从3GPP RAN1#88bis次会议开始，对极化码的讨论分为两个部分：一是Code construction，二是Sequence design。</p><a id="more"></a><h1 id="Code-construction"><a href="#Code-construction" class="headerlink" title="Code construction"></a>Code construction</h1><p><br>Code construction讨论的是编码结构，犹如一个盒子，$k$比特输入，$N$比特输出。只要这个盒子的内部结构确定，输入任意$k$个信息比特，都可以得到$N$比特的极化码编码序列。这个编码结构简略地说就是“<strong>J+J’检错比特 + basic polar</strong>”的控制信道编码结构。J bits是CRC，主要用于错误检测，但也可以用于辅助译码。J’ bits用于辅助译码。</p><p>根据Arikan的结论，极化码在码长趋于无穷长时，由于信道极化完全而能够达到香农容量。但实际的码长是有限长的，采用SC/SCL译码算法并不能达到理想的译码性能。添加一些检错比特以辅助译码，则能够以较低的复杂度提高译码检错能力，从而提高译码性能。3GPP所讨论的主要是基于辅助的极化码方案，目前有CRC-polar、PC-polar和Hash-polar三种方案，甚至是它们的组合。所以J’ bits可以是CRC或PC或Hash code，或它们的组合。</p><p>此外，极化码编码结构要考虑Early termination，在不降低BLRE性能或增加时延的前提下，不必等到译出全部比特才去判断该码字是否正确，而是在译出一部分比特的时候就可以提前发现错误。这样做的好处，一是在译码过程中能够尽早发现译码错误，减少译码复杂度；二是对于控制信道可以减少盲检测的数量。</p><h1 id="Sequence-design"><a href="#Sequence-design" class="headerlink" title="Sequence design"></a>Sequence design</h1><p><br>Sequence design涉及极化码信息比特和冻结比特位置的选择问题。对极化码而言，由于信道极化特性，某些比特位置（子信道）总是比其他比特位置更可靠。构造极化码时，需要一个基于可靠性度量的比特位置顺序序列（ordered sequence），指示信息比特和检错比特放置在可靠性较高的比特位置上，冻结比特放置在可靠性较低的比特位置上。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170529/094419143.jpg" title="The structure of Polar codes for NR"></p><p>上图红色方框表示的序列就是ordered sequence。有了“<strong>J+J’检错比特 + basic polar</strong>”的编码结构，加上指示信息比特/冻结比特位置的<strong>ordered sequence</strong>，最后加上<strong>速率匹配方案</strong>以突破码长$N$必须为2的幂次方的限制，最终构成了一套适用于NR-PDCCH的极化码编码方案。</p><p>关于Sequence design，本次会议并没有达成任何实质性结论。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --&gt;&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;&lt;br&gt;RAN1#87次会议已将Polar code确定为eMBB场景下控制信道的信道编码，因此3GPP对极化码的讨论并不是在单纯地讨论编码理论，而是在讨论极化码在5G NR控制信道框架下的应用。所以随着3GPP对极化码讨论的深入，关于极化码达成的结论会自然地和控制信道的特性结合在一起。也就是说，你所看到的3GPP关于极化码达成的结论，未必是Polar code本身应该具有的，但它一定是&lt;strong&gt;5G NR控制信道下的Polar code&lt;/strong&gt;应该具有的。所以仍然有必要把学术界研究的极化码与工程界研究的极化码做个区分。&lt;/p&gt;&lt;p&gt;言归正传，从3GPP RAN1#88bis次会议开始，对极化码的讨论分为两个部分：一是Code construction，二是Sequence design。&lt;/p&gt;
    
    </summary>
    
      <category term="3GPP_PolarCode" scheme="https://marshallcomm.github.io/categories/3GPP-PolarCode/"/>
    
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/tags/Polar-Code/"/>
    
      <category term="3GPP" scheme="https://marshallcomm.github.io/tags/3GPP/"/>
    
  </entry>
  
  <entry>
    <title>Polar Code（13）信道极化</title>
    <link href="https://marshallcomm.github.io/2017/05/04/Polar-Code-13-channel-polarization/"/>
    <id>https://marshallcomm.github.io/2017/05/04/Polar-Code-13-channel-polarization/</id>
    <published>2017-05-04T08:28:28.000Z</published>
    <updated>2017-08-04T09:05:49.132Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170505/114130398.jpg" title="图 1 信道${W_{4}}$"></p><a id="more"></a><p><strong>1、</strong> 信道极化是一种现象，把它看作一种原理，而极化码编码则是对这一原理的应用。理解极化码可以分两部分，一部分是理论，一部分是应用。</p><p><strong>2、</strong> 从图上看，信道极化过程是一目了然的。但从数学上看，信道极化要分两个阶段，第一阶段是信道联合，第二阶段就是信道分裂。信道分裂是信道极化的一部分。</p><p><strong>3、</strong> 信道极化作为一种原理，它也有它的结构。它的结构就是：原本$N$条平行线，互不相交，谁和谁都没有联系，换句话说，是$N$条原始信道的独立副本；经过各种连线、模二加，连来连去，连成了现在的样子；现在是$N$条线彼此都有联系。这个过程就是信道联合，把原本相互独立的$N$条细线扭成一条粗线。</p><p><strong>4、</strong> 信道联合是从宏观的角度观察，把信道极化过程看作一个整体，输入是$N$比特，输出也是$N$比特。经过联合的信道总是以整体的形式表达，如联合信道${ {W}_{4}}:{ {X}^{4}}\to { {Y}^{4}}$，以及联合信道的转移概率${ {W}_{4}}\left( y_{1}^{4}|u_{1}^{4} \right)$。</p><p><strong>5、</strong> 但只有信道联合是不够的，你无法确知各个子信道的输入和输出是什么关系。这就需要对信道极化过程有一个微观的表达，这个微观表达是通过信道分裂过程来实现的。到信道联合这一步还看不出“极化”的概念，必须经过信道分裂才能体现出极化现象。</p><p><strong>6、</strong> 信道分裂使已经扭成一条粗线的联合信道又重新一条一条地展现在世人面前，就好比两条绳子打结（信道联合），然后再区分出两端谁是谁（信道分裂）。经过分裂的信道总是以单个的形式表达，如分裂子信道$W_{N}^{\left( i \right)}:X\to { {Y}^{N}}\times { {X}^{i-1}}$，以及分裂子信道的转移概率$W_{N}^{\left( i \right)}\left( y_{1}^{N},u_{1}^{i-1}|{ {u}_{i}} \right)$。</p><p><strong>7、</strong> 宏观和微观合在一起就构成了对信道极化过程的完整表达。我们的目的不只是观其大概，更要搞清楚各个子信道，求分裂子信道的转移概率。<a href="http://marshallcomm.cn/2017/04/09/Polar-Code-12-BDMC-Symmetric-Capacity/" target="_blank" rel="external">《Polar Code（12）B-DMC对称容量》</a>一文中提到，输入符号概率、输出符号概率和转移概率完整地定义了一种信道。不搞清楚各分裂子信道的转移概率就无法完成对分裂信道的定义。从以下定义式就可以看出联合信道和分裂子信道的关系了：</p><script type="math/tex;mode=display">\begin{align}
W_{N}^{\left( i \right)}\left( y_{1}^{N},u_{1}^{i-1}|{ {u}_{i}} \right)\triangleq \sum\limits_{u_{i+1}^{N}\in { {X}^{N-i}}}{\frac{1}{ { {2}^{N-1}}}{ {W}_{N}}\left( y_{1}^{N}|u_{1}^{N} \right)}
\end{align}</script><p><strong>8、</strong> 但式（1）是不易求的。观察图1，整个信道极化过程恰好是一种递归形式。因此用两个递归式来计算各个分裂子信道的转移概率：</p><script type="math/tex;mode=display">\begin{align}
W_{N}^{\left( 2i-1 \right)}\left( y_{1}^{N},u_{1}^{2i-2}|{ {u}_{2i-1}} \right)=\sum\limits_{ { {u}_{2i}}}{\frac{1}{2}W_{ {N}/{2}\;}^{\left( i \right)}\left( y_{1}^{ {N}/{2}\;},u_{1,o}^{2i-2}\oplus u_{1,e}^{2i-2}|{ {u}_{2i-1}}\oplus { {u}_{2i}} \right)\cdot W_{ {N}/{2}\;}^{\left( i \right)}\left( y_{ {N}/{2}\;+1}^{N},u_{1,e}^{2i-2}|{ {u}_{2i}} \right)}
\end{align}</script><script type="math/tex;mode=display">\begin{align}
W_{N}^{\left( 2i \right)}\left( y_{1}^{N},u_{1}^{2i-1}|{ {u}_{2i}} \right)=\frac{1}{2}W_{ {N}/{2}\;}^{\left( i \right)}\left( y_{1}^{ {N}/{2}\;},u_{1,o}^{2i-2}\oplus u_{1,e}^{2i-2}|{ {u}_{2i-1}}\oplus { {u}_{2i}} \right)\cdot W_{ {N}/{2}\;}^{\left( i \right)}\left( y_{ {N}/{2}\;+1}^{N},u_{1,e}^{2i-2}|{ {u}_{2i}} \right)
\end{align}</script><p><strong>9、</strong> 求得各个分裂子信道的转移概率有什么用？在实际编译码中并没有直接用。当我在3月12日那个时间点上写<a href="http://marshallcomm.cn/2017/03/12/polar-code-5-encoding-chan-trans-prob/" target="_blank" rel="external">《Polar Code（5）编码之信道转移概率》</a>的时候，认为转移概率是有用的，并且认为在编码端和译码端都会直接使用，至少对于BEC信道计算巴氏参数时会直接使用。但随着研究的深入，尤其在研究了密度进化和高斯近似之后，对此的认识得到了更新：</p><ol><li>转移概率是有用的，但并不直接使用，而是使用两个转移概率的之比的对数，即对数似然比（LLR）;</li><li>高斯近似法令转移概率为服从高斯分布的随机变量，并使用对数似然比，直接规避了计算（2）式和（3）式，所以转移概率的两个式子就沦为了铺路者；</li><li>但式（2~3）的递归形式是十分有用的，译码时计算LLR就利用这种递归形式。</li></ol><p>有关高斯近似详见<a href="http://marshallcomm.cn/2017/03/17/polar-code-8-gaussian-approximation/" target="_blank" rel="external">《Polar Code（8）高斯近似》</a>，而<a href="http://marshallcomm.cn/2017/03/12/polar-code-5-encoding-chan-trans-prob/" target="_blank" rel="external">《Polar Code（5）编码之信道转移概率》</a>通过分析转移概率的计算过程也能更好的理解编码过程。</p><p><strong>10、</strong> 编码。极化码是对信道极化原理的应用。然而编码过程又是基于另一套思路，它沿着线性分组码的编码思路，用生成矩阵的方式产生极化码。而生成矩阵的构造又体现着信道极化的原理，用递归形式来构造生成矩阵。</p><p>书不尽言，言不尽意。以上几点，是我对信道极化的理解。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --&gt;&lt;p&gt;&lt;img src=&quot;http://olyzl8414.bkt.clouddn.com/blog/20170505/114130398.jpg&quot; title=&quot;图 1 信道${W_{4}}$&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/categories/Polar-Code/"/>
    
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/tags/Polar-Code/"/>
    
  </entry>
  
  <entry>
    <title>Polar Code（12）B-DMC对称容量</title>
    <link href="https://marshallcomm.github.io/2017/04/09/Polar-Code-12-BDMC-Symmetric-Capacity/"/>
    <id>https://marshallcomm.github.io/2017/04/09/Polar-Code-12-BDMC-Symmetric-Capacity/</id>
    <published>2017-04-09T12:15:27.000Z</published>
    <updated>2017-08-04T09:05:39.461Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><br>任何一本信息论书籍讲到离散信道容量时都会涉及形如$I\left( X;Y \right)=\sum\limits_{i,j}{ { {p}_{i}}{ {p}_{ij}}\log \frac{ { {p}_{ij}}}{ { {q}_{j}}}}$的公式。但这个公式，我理解是经过转化得来的，不是直接得到的。怎么转化呢？请继续阅读。</p><p>输入符号概率${ {p}_{i}}=p\left( { {x}_{i}} \right)$，输出符号概率${ {q}_{j}}=q\left( { {y}_{j}} \right)$，输入符号到输出符号的转移概率${ {p}_{ij}}=p\left( { {y}_{j}}|{ {x}_{i}} \right)$，这三种概率完全地表达了一个信道。对于信道容量，第一个概念是互信息量。</p><a id="more"></a><h1 id="互信息量"><a href="#互信息量" class="headerlink" title="互信息量"></a>互信息量</h1><p><br>互信息量定义为<strong>后验概率与先验概率比值的对数</strong>。虽然有这个定义，但必须先要明确观察者的角度才能进一步确定后验概率是谁，先验概率是谁。$I\left( X;Y \right)$是站在接收端的角度观察，是$Y$对$X$的平均互信息量；而$I\left( Y;X \right)$是站在发送端角度观察，是$X$对$Y$的平均互信息量。我们只说第一种角度，即以接收者的视角来观察信道。</p><p>通常接收端可以预知信息$X$发出的各个符号的集合，以及它们的概率分布，也就是说发送符号概率$p\left( { {x}_{i}} \right)$是<strong>先验概率</strong>。当接收端收到一个符号${ {y}_{j}}$后，接收端可以计算发送端消息的条件概率$p\left( { {x}_{i}}|{ {y}_{j}} \right)$，这种条件概率就是<strong>后验概率</strong>。根据互信息量定义，${ {y}_{j}}$对${ {x}_{i}}$的互信息量为：</p><script type="math/tex;mode=display">\begin{align}
I\left( { {x}_{i}};{ {y}_{j}} \right)=\log \frac{p\left( { {x}_{i}}|{ {y}_{j}} \right)}{p\left( { {x}_{i}} \right)}
\end{align}</script><h1 id="平均互信息量"><a href="#平均互信息量" class="headerlink" title="平均互信息量"></a>平均互信息量</h1><p><br>只有$I\left( { {x}_{i}};{ {y}_{j}} \right)$是没有意义的，因为通常无法确定$p\left( { {x}_{i}}|{ {y}_{j}} \right)$和$p\left( { {x}_{i}} \right)$的大小关系，$I\left( { {x}_{i}};{ {y}_{j}} \right)$不一定大于或等于0。由于发送符号$X$和接收符号$Y$都是随机变量，要探知$Y$对$X$的互信息量得用统计的方法去计算$I\left( { {x}_{i}};{ {y}_{j}} \right)$的平均值，准确地说是计算$I\left( { {x}_{i}};{ {y}_{j}} \right)$在发送符号集合$X$和接收符号集合$Y$上的概率加权统计平均值，这就是平均互信息量：</p><script type="math/tex;mode=display">\begin{align}
I\left( X;Y \right)=\sum\limits_{i}{\sum\limits_{j}{p\left( { {x}_{i}}{ {y}_{j}} \right)}\log }\frac{p\left( { {x}_{i}}|{ {y}_{j}} \right)}{p\left( { {x}_{i}} \right)}
\end{align}</script><p>其中$p\left( { {x}_{i}}{ {y}_{j}} \right)$是发送符号${ {x}_{i}}$与接收符号${ {y}_{j}}$的联合概率。</p><h1 id="联合概率、后验概率与转移概率的关系"><a href="#联合概率、后验概率与转移概率的关系" class="headerlink" title="联合概率、后验概率与转移概率的关系"></a>联合概率、后验概率与转移概率的关系</h1><script type="math/tex;mode=display">\begin{align}
p\left( { {x}_{i}}{ {y}_{j}} \right)=p\left( { {x}_{i}} \right)p\left( { {y}_{j}}|{ {x}_{i}} \right)=p\left( { {y}_{j}} \right)p\left( { {x}_{i}}|{ {y}_{j}} \right)
\end{align}</script><p>这个关系式相当重要！它打通了前向与后向之间的联系。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170409/202751865.jpg" alt="mark"></p><p>研究互信息量自然离不开对信道的定义。而信道是由输入符号、输出符号和转移概率三者确定的。转移概率$p\left( { {y}_{j}}|{ {x}_{i}} \right)$是站在发送端的角度观察，方向是$X\to Y$，因此也称为<strong>前向概率</strong>。后验概率$p\left( { {x}_{i}}|{ {y}_{j}} \right)$是站在接收端的角度观察，方向是$Y\to X$，因此也称为<strong>后向概率</strong>。后验概率是逆向思维，不仅难以理解而且还不易求，既然如此那就全部按正向来吧。根据关系式（3），把<strong>后验概率用转移概率来表示</strong>：</p><script type="math/tex;mode=display">\begin{align}
p\left( { {x}_{i}}|{ {y}_{j}} \right)=\frac{p\left( { {x}_{i}} \right)p\left( { {y}_{j}}|{ {x}_{i}} \right)}{p\left( { {y}_{j}} \right)}
\end{align}</script><p>带入式（2）则平均互信息量$I\left( X;Y \right)$用转移概率可重新表示为：</p><script type="math/tex;mode=display">\begin{align}
I\left( X;Y \right)=\sum\limits_{i}{\sum\limits_{j}{p\left( { {x}_{i}} \right)p\left( { {y}_{j}}|{ {x}_{i}} \right)}\log }\frac{p\left( { {y}_{j}}|{ {x}_{i}} \right)}{p\left( { {y}_{j}} \right)}
\end{align}</script><p>其中$p\left( { {x}_{i}} \right)$是先验概率自不必说，$p\left( { {y}_{j}} \right)$是接收符号概率也可以用转移概率表示：</p><script type="math/tex;mode=display">\begin{align}
p\left( { {y}_{j}} \right)=\sum\limits_{i}{p\left( { {x}_{i}} \right)}p\left( { {y}_{j}}|{ {x}_{i}} \right)
\end{align}</script><p>通过式（5~6）可以看出，在信道给定的情况下，平均互信息量$I\left( X;Y \right)$的大小由输入符号的概率分布$p\left( { {x}_{i}} \right)$来确定。</p><h1 id="信道容量"><a href="#信道容量" class="headerlink" title="信道容量"></a>信道容量</h1><p><br>进一步，<strong>信道容量</strong>定义为平均互信息量$I\left( X;Y \right)$的最大值，用符号$C$来表示，即</p><script type="math/tex;mode=display">\begin{align}
C=\underset{p\left( { {x}_{i}} \right)}{\mathop{\max }}\,I\left( X;Y \right)=\underset{p\left( { {x}_{i}} \right)}{\mathop{\max }}\,\sum\limits_{i}{\sum\limits_{j}{p\left( { {x}_{i}} \right)p\left( { {y}_{j}}|{ {x}_{i}} \right)}\log }\frac{p\left( { {y}_{j}}|{ {x}_{i}} \right)}{\sum\limits_{i}{p\left( { {x}_{i}} \right)}p\left( { {y}_{j}}|{ {x}_{i}} \right)}
\end{align}</script><p>什么时候$I\left( X;Y \right)$取得最大值呢？——<strong>发送符号等概率时</strong>。</p><h1 id="B-DMC信道容量"><a href="#B-DMC信道容量" class="headerlink" title="B-DMC信道容量"></a>B-DMC信道容量</h1><p><br>对于二进制的离散无记忆信道，信源符号以等概率发送时有$p\left( 0 \right)=p\left( 1 \right)=\frac{1}{2}$，带入式（7）得到：</p><script type="math/tex;mode=display">\begin{align}
C=I\left( X;Y \right)=\sum\limits_{i}{\sum\limits_{j}{\frac{1}{2}p\left( { {y}_{j}}|{ {x}_{i}} \right)}\log }\frac{p\left( { {y}_{j}}|{ {x}_{i}} \right)}{\sum\limits_{i}{p\left( { {x}_{i}} \right)}p\left( { {y}_{j}}|{ {x}_{i}} \right)}
\end{align}</script><p>分母展开$\sum\limits_{i}{p\left( { {x}_{i}} \right)}p\left( { {y}_{j}}|{ {x}_{i}} \right)=\frac{1}{2}p\left( { {y}_{j}}|0 \right)+\frac{1}{2}p\left( { {y}_{j}}|1 \right)$，并带入式（8）得到B-DMC信道容量为：</p><script type="math/tex;mode=display">\begin{align}
I\left( X;Y \right)=\sum\limits_{i}{\sum\limits_{j}{\frac{1}{2}p\left( { {y}_{j}}|{ {x}_{i}} \right)}\log \frac{p\left( { {y}_{j}}|{ {x}_{i}} \right)}{\frac{1}{2}p\left( { {y}_{j}}|0 \right)+\frac{1}{2}p\left( { {y}_{j}}|1 \right)}}
\end{align}</script><h1 id="对称信道容量"><a href="#对称信道容量" class="headerlink" title="对称信道容量"></a>对称信道容量</h1><p><br>如果转移概率矩阵$\mathbf{P}$的每一行都是第一行的置换，称该矩阵是输入对称的；如果转移概率矩阵$\mathbf{P}$的每一列都是第一列的置换，称该矩阵是输出对称的；如果输入、输出都对称，则称该DMC为<strong>对称的DMC信道</strong>。</p><p>满足对称条件的B-DMC有两个典型例子：BSC和BEC。其中BSC的转移概率矩阵为</p><script type="math/tex;mode=display">\begin{align}
\mathbf{P}=\left[ \begin{matrix}
   p & 1-p  \\
   1-p & p  \\
\end{matrix} \right]
\end{align}</script><p>显然式（10）的每一行、每一列都分别是第一行、第一列的置换，因此转移概率满足式（10）的信道是一种对称信道。把BSC转移概率带入式（9）就得到了<strong>BSC的对称信道容量</strong>：</p><script type="math/tex;mode=display">\begin{align}
I\left( X;Y \right)=p\log 2p+\left( 1-p \right)\log 2\left( 1-p \right)
\end{align}</script><h1 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h1><p><br>既然是离散信道，其输入、输出必然都是离散的。为什么输出符号是任意的？站在发送端的角度去看，发送端唯一确知的就是自己能够发什么，发送符号取值范围是{0,1}，这是明确的。我发的信号我做主，发送端只管得了自己，但它不并知道信道是什么样的，也不知道接收端能收到什么。所以对于发送端而言，信道和接收符号都是未知的、任意的。概率也仅仅表达了一种可能性。弓箭手射箭，一旦射出，箭就不由弓箭手所控制了。</p><p>为什么Arikan由B-DMC直接给出了对称容量？式（9）给出的就是B-DMC的信道容量，此时还没涉及对称的概念。注意，式（9）是一个不完整的计算式，它有4个转移概率值仍是未知的。因此你必须对B-DMC有进一步的定义，而此时式（9）的值则完全取决于信道类型。转移概率满足什么样的特性，它就定义了什么样的信道类型。当满足$P\left( 0|0 \right)=P\left( 1|1 \right)=p$、$P\left( 1|0 \right)=P\left( 0|1 \right)=1-p$时，B-DMC就是BSC信道。对称，发0的情况和发1的情况完全相同，这就是对称。BSC是研究二元编解码最简单，最常用的信道模型。</p><p>研究编解码离不开具体的信道模型，只谈B-DMC是不够的，它还有4个概率值需要进一步给出定义。当进一步研究编码时不可能凭空讨论，一定要更加具体，是B-DMC下的BSC，还是B-DMC下的BEC？如此这般才构成讨论的基础。为什么一定要对称？因为它是最简单最基础的模型。定义就是定义，不需要纠结于为什么要这么定义。一上来就给出讨论的前提，在这种定义的框架下去讨论编码问题。</p><p>说“BSC的对称容量”、“BEC的对称容量”都没问题，因为BSC和BEC都是对称信道。说“B-DMC的对称容量”，其实是隐含地指出了B-DMC满足对称性，要么是BSC，要么是BEC。</p><p>BSC和BEC的相关链接：</p><p><a href="http://marshallcomm.cn/2017/03/12/polar-code-5-encoding-chan-trans-prob/" target="_blank" rel="external">Polar Code（5）编码之信道转移概率</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --&gt;&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;&lt;br&gt;任何一本信息论书籍讲到离散信道容量时都会涉及形如$I\left( X;Y \right)=\sum\limits_{i,j}{ { {p}_{i}}{ {p}_{ij}}\log \frac{ { {p}_{ij}}}{ { {q}_{j}}}}$的公式。但这个公式，我理解是经过转化得来的，不是直接得到的。怎么转化呢？请继续阅读。&lt;/p&gt;&lt;p&gt;输入符号概率${ {p}_{i}}=p\left( { {x}_{i}} \right)$，输出符号概率${ {q}_{j}}=q\left( { {y}_{j}} \right)$，输入符号到输出符号的转移概率${ {p}_{ij}}=p\left( { {y}_{j}}|{ {x}_{i}} \right)$，这三种概率完全地表达了一个信道。对于信道容量，第一个概念是互信息量。&lt;/p&gt;
    
    </summary>
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/categories/Polar-Code/"/>
    
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/tags/Polar-Code/"/>
    
  </entry>
  
  <entry>
    <title>写作即思考</title>
    <link href="https://marshallcomm.github.io/2017/03/31/writing-is-thinking/"/>
    <id>https://marshallcomm.github.io/2017/03/31/writing-is-thinking/</id>
    <published>2017-03-31T11:25:56.000Z</published>
    <updated>2017-03-31T11:39:07.185Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --><p>除了“问题即答案”，“写作即思考”是另一个关键过程。思考不是写作，但写作一定是思考的结果。其实在读研时就该这么做了，直到最近我才开始付诸实践。</p><p>书写，记录，把思考变为叙述。当问题A牵引出问题B，问题B牵引出问题C，C牵引出D，D牵引出E，你的大脑能缓存几级？我开始反复告诫自己，不要太相信自己的大脑，用不了多久你就会混乱，当你提取知识点时，你提取的不是点，也不是面，而是面掺了水的一团浆糊。</p><a id="more"></a><p>书写的重要作用在于清空大脑缓存。思考问题时，必然有一部分内存用于缓存ABCD，然后剩余的内存用来集中思考当前的问题E。记忆缓存太多，必然压缩思考内存，导致思考力不足，而且容易产生概念混淆。清空缓存，不是清空记忆。把记忆缓存整理输出，清清楚楚，明明白白。</p><p>开始发觉输出的重要性，追求有价值的输出，倒逼有价值的输入。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --&gt;&lt;p&gt;除了“问题即答案”，“写作即思考”是另一个关键过程。思考不是写作，但写作一定是思考的结果。其实在读研时就该这么做了，直到最近我才开始付诸实践。&lt;/p&gt;&lt;p&gt;书写，记录，把思考变为叙述。当问题A牵引出问题B，问题B牵引出问题C，C牵引出D，D牵引出E，你的大脑能缓存几级？我开始反复告诫自己，不要太相信自己的大脑，用不了多久你就会混乱，当你提取知识点时，你提取的不是点，也不是面，而是面掺了水的一团浆糊。&lt;/p&gt;
    
    </summary>
    
      <category term="随笔一记" scheme="https://marshallcomm.github.io/categories/%E9%9A%8F%E7%AC%94%E4%B8%80%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>问题即答案</title>
    <link href="https://marshallcomm.github.io/2017/03/30/the-question-is-the-answer/"/>
    <id>https://marshallcomm.github.io/2017/03/30/the-question-is-the-answer/</id>
    <published>2017-03-30T11:16:05.000Z</published>
    <updated>2017-03-31T11:33:17.783Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --><p>当就某一个问题翻阅了手边所有的资料，穷尽了你所有思考角度之后仍不得其解时，说明你已经到达了自己的思维边界。这时就该鸣金收兵来日再战。你已经恋战太久，或许你的思路已经偏离中心走了很远，这时需要重新回到问题的本源，应当重新审视问题的本质。</p><p>另一方面，思考的范围终究还是窄了，所以需要搜集新的材料，补充新的线索，找到新的角度，然后重新思考问题。</p><p>还有一种可能就是知识盲点，你不知道你不知道的那些知识，无形中阻碍着你的理解。</p><a id="more"></a><p>思考的密度、深度，必须要匹配长时间的思考持续度，假以时日，答案方能显现。根据以往的经验，这时日并不会太长，至少不是绝望式的那么遥不可及。然而答案的出现总是极具偶然性。你不能保证只要用了功，就一定在某日某时有了答案，但你的确有预感，在不久的将来，在某一个时间的邻域内，答案就快来了。事后证明，往往当你有这种预感时，答案的确快来了。</p><p>一个不能忽视的因素是心境。越是轻松的心境越能容易地找到答案，越是焦虑的心境越阻碍答案的获得。压力和焦虑是不一样的。我更倾向于认为压力无有好坏之分，如王阳明之善恶说，无善无恶心之体，有善有恶意之动。压力一来，向上是动力，向下是焦虑。但往往是左右互搏、上下游走、善恶并存，于是头脑分裂，变成了纠结。</p><p>有时候不仅要换一种思考角度，更要换一种思维高度。站得高的确看得远，跳出第一视角，站在第三视角，世界当有所不同。</p><p>对之前的资料没看仔细，断章取义，导致误读。在研究的道路上这样的陷阱不少。即使心态不焦虑，不纠结，但心浮气躁也是巨大的阻碍。心不能沉静，读文献望文生义，越到后面越费解，等回过头重新审视问题时才知以前的理解是错误的。</p><p>与其说沉静，不如说专注。沉静一定是专注之时的状态，不专注则一定不沉静。沉静是带有文学色彩的描述，而专注更具有可量化性。专注指向了可量化的工具，如时间管理；沉静则指向了诸如瑜伽冥想参禅打坐，完全随心而定，虚无缥缈，不可量化。</p><p>灯下黑。有些答案就在眼前，你却绕了许多弯路。直到又一个偶然，眼前一黑，却头脑一亮，有了答案。</p><p>读文献时常遇到这样一句话：“一个直接的想法是……”。看似是废话，但说明一个道理。当你把问题思考得很透彻，并且把问题界定得很清晰的话，那么答案往往是显而易见的。于是才有“一个直接的想法”，其中这个“直接”就来源于对问题的把握。这可能就是通常所说的“问题即答案”了。无论是老问题还是新问题，都要先把问题思考清楚。否则连问题是什么都不知道就急忙找方法，到头来方法没找到，问题也没搞清楚。</p><p>当然，一种更大的可能是，“一个直接的想法”只是个引子，这想法虽然直接但未必现实。于是话锋一转，然而这个直接的想法具有较高的复杂度，第二步才是你提出的更为可行的办法。如问题是地球环境破坏严重，越来越不适合人类居住，一个直接的想法是移民外太空，然而这个想法具有较高的复杂度，一个更为可行的办法是退耕还林、保护环境。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --&gt;&lt;p&gt;当就某一个问题翻阅了手边所有的资料，穷尽了你所有思考角度之后仍不得其解时，说明你已经到达了自己的思维边界。这时就该鸣金收兵来日再战。你已经恋战太久，或许你的思路已经偏离中心走了很远，这时需要重新回到问题的本源，应当重新审视问题的本质。&lt;/p&gt;&lt;p&gt;另一方面，思考的范围终究还是窄了，所以需要搜集新的材料，补充新的线索，找到新的角度，然后重新思考问题。&lt;/p&gt;&lt;p&gt;还有一种可能就是知识盲点，你不知道你不知道的那些知识，无形中阻碍着你的理解。&lt;/p&gt;
    
    </summary>
    
      <category term="随笔一记" scheme="https://marshallcomm.github.io/categories/%E9%9A%8F%E7%AC%94%E4%B8%80%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>Polar Code（11）3GPP标准化进展</title>
    <link href="https://marshallcomm.github.io/2017/03/22/polar-code-11-3gpp-standard-1/"/>
    <id>https://marshallcomm.github.io/2017/03/22/polar-code-11-3gpp-standard-1/</id>
    <published>2017-03-22T08:46:48.000Z</published>
    <updated>2017-08-04T09:05:09.769Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><br>时间终于来到了2017年，我的文章也终于要追上3GPP 5G NR标准化的进展了。自2016年11月3GPP RAN1 #87会议确定5G eMBB场景控制信道编码为Polar Code后，2017年1月在美国斯波坎市召开的3GPP RAN1 #AH1_NR会议上继续讨论了Polar Code设计议题。紧接着，2月（上个月）在希腊雅典召开了RAN1 #88次会议；3月（本月）在克罗地亚召开了RAN #75次全会，5G的研究阶段（Study Item，SI）结束，继而开启工作阶段（Work Item）；4月（下个月）3日又将在美国召开RAN1 #88b会议。5G的推进速度其实比外界想象得要快得多。</p><a id="more"></a><h1 id="RAN1-AH1-NR"><a href="#RAN1-AH1-NR" class="headerlink" title="RAN1 #AH1_NR"></a>RAN1 #AH1_NR</h1><h2 id="Polar-Code描述方法"><a href="#Polar-Code描述方法" class="headerlink" title="Polar Code描述方法"></a>Polar Code描述方法</h2><p><br>2017年1月召开的RAN1 #AH1_NR会议上统一了Polar Code描述方法。一直以来Polar Code有两种等价的描述方法。</p><ul><li><strong>Description #1</strong>：实施比特反转（bit reversal）的编码。也就是Arikan最初发明的编码方法。我的文章也一直采用这种描述方法，见<a href="https://marshallcomm.github.io/2017/03/04/polar-code-2-encoding-principle/">《Polar Code（2）编码原理》</a>图1~3。</li><li><strong>Description #2</strong>：不进行比特反转（bit reversal）的编码。这是最近比较流行的描述方法。为了便于各公司进行Polar Code设计，消除混淆，应当统一描述方法。</li></ul><p><strong>会议同意了Description #2的描述</strong>，并把这种描述称为“<strong>basic polar</strong>”。注意，这并不影响Polar code其他方面的设计，如凿孔模式的设计、冻结比特模式的设计等。basic polar描述如下：</p><ul><li>Polar编码器输出为<script type="math/tex;mode=display">x_{0}^{N-1}=u_{0}^{N-1}{ {G}_{N}}</script></li></ul><p>${ {G}_{N}}$是N维的生成矩阵</p><ul><li><script type="math/tex;mode=display">{ {G}_{2}}=\left[ \begin{matrix}
 1 & 0  \\
 1 & 1  \\
\end{matrix} \right]</script></li><li><script type="math/tex;mode=display">{ {G}_{N}}={ {F}^{\otimes n}}</script></li></ul><p>其中$N={ {2}^{n}},n\ge 1$</p><ul><li><script type="math/tex;mode=display">F=\left[ \begin{matrix}
 1 & 0  \\
 1 & 1  \\
\end{matrix} \right]</script></li></ul><p>${ {F}^{\otimes n}}$是矩阵$F$的n次克罗内克积</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170322/171402368.gif" alt="mark"></p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170322/171428130.gif" alt="mark"></p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170322/171437427.gif" alt="mark"></p><h2 id="最大母码长度范围"><a href="#最大母码长度范围" class="headerlink" title="最大母码长度范围"></a>最大母码长度范围</h2><p><br>Polar Code最大母码长度$N={ {2}^{n}}$确定了以下范围：</p><ul><li>下行控制信息：$256\le { {N}_{\max ,DCI}}\le 1024$</li><li>上行控制信息：$1024\le { {N}_{\max ,UCI}}\le 2048$</li><li>准确值将在RAN1 #88会议进一步确定</li></ul><h2 id="评估方法和可选编码方案"><a href="#评估方法和可选编码方案" class="headerlink" title="评估方法和可选编码方案"></a>评估方法和可选编码方案</h2><p><br>从RAN1 #86b开始，华为就提出了基于奇偶校验（parity-check）的Polar编译码方案，即PC-Polar。#87会议虽然确定控制信道采用Polar Code，但还没确定究竟采用哪一种Polar Code。目前争论的焦点主要集中在CA-Polar和PC-Polar上。会议同意了以下评估方法和二选一的编码方案：</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170322/172144658.jpg" alt="mark"></p><h1 id="RAN1-88"><a href="#RAN1-88" class="headerlink" title="RAN1 #88"></a>RAN1 #88</h1><h2 id="确定最大母码长度"><a href="#确定最大母码长度" class="headerlink" title="确定最大母码长度"></a>确定最大母码长度</h2><ul><li>下行控制信息：${ {N}_{\max ,DCI}}=512$</li><li>上行控制信息：${ {N}_{\max ,UCI}}=1024$</li></ul><h2 id="编码方案"><a href="#编码方案" class="headerlink" title="编码方案"></a>编码方案</h2><p><br>本次会议决定，把Alt.1和Alt.2两种可选方案进一步做了融合：</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170322/172334924.jpg" alt="mark"></p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p><br>截止目前，Polar Code上下行控制信息编码的母码长度确定了。性能评估指标一个是BLER，一个是FAR。编码方案仍会在下一次会议（4月）中进一步讨论。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><br>[1] Draft_Minutes_report_RAN1#AH1_NR_v010<br>[2] Draft_Minutes_report_RAN1#88_v010</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --&gt;&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;&lt;br&gt;时间终于来到了2017年，我的文章也终于要追上3GPP 5G NR标准化的进展了。自2016年11月3GPP RAN1 #87会议确定5G eMBB场景控制信道编码为Polar Code后，2017年1月在美国斯波坎市召开的3GPP RAN1 #AH1_NR会议上继续讨论了Polar Code设计议题。紧接着，2月（上个月）在希腊雅典召开了RAN1 #88次会议；3月（本月）在克罗地亚召开了RAN #75次全会，5G的研究阶段（Study Item，SI）结束，继而开启工作阶段（Work Item）；4月（下个月）3日又将在美国召开RAN1 #88b会议。5G的推进速度其实比外界想象得要快得多。&lt;/p&gt;
    
    </summary>
    
      <category term="3GPP_PolarCode" scheme="https://marshallcomm.github.io/categories/3GPP-PolarCode/"/>
    
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/tags/Polar-Code/"/>
    
      <category term="3GPP" scheme="https://marshallcomm.github.io/tags/3GPP/"/>
    
  </entry>
  
  <entry>
    <title>Polar Code（10）速率适配的凿孔极化码</title>
    <link href="https://marshallcomm.github.io/2017/03/21/polar-code-10-rcpp/"/>
    <id>https://marshallcomm.github.io/2017/03/21/polar-code-10-rcpp/</id>
    <published>2017-03-21T10:12:21.000Z</published>
    <updated>2017-08-04T09:04:03.396Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><br>Arikan发明极化码时给出了编码算法和SC译码算法，后来的研究者提出SCL和CA-SCL译码算法对SC算法进行了改进，使译码性能得到提升。但不要忘记这些编译码算法都对码长有限定条件，即码长必须满足2的幂次方：$N={ {2}^{n}}$。虽然当码长$N$固定时，信息比特长度$K$可以任意取值，编码速率$R={K}/{N}\;$也能随之自由变化。但在信息比特长度一定的情况下，要通过调整码长而调整编码速率就无法实现了。从实际角度出发，我们更希望设计一对编译码器能够在不改变基本的编译码结构的情况下，使码长和编码速率都能够自适应调节。在设计速率可变的编码时，凿孔是一种普遍采用的方法。</p><a id="more"></a><h1 id="速率适配的凿孔极化码"><a href="#速率适配的凿孔极化码" class="headerlink" title="速率适配的凿孔极化码"></a>速率适配的凿孔极化码</h1><p><br>对于速率适配的凿孔极化（rate-compatible punctured polar，RCPP）码，如何凿孔以及如何缩短码长是关键问题。极化码的凿孔方案大致分为两类：第一类方案，在编码端凿掉一些比特，但译码端没有这些凿孔比特的先验信息，因此译码端把这些比特信道被视为容量为0的信道。这类方案被称为“C0”（capacity-zero）凿孔模式<sup>[1]</sup>。第二类方案，凿孔比特是编、译码器事先知道的，因此这些比特信道被视为容量为1的信道。这类方案被称为“C1”（capacity-one）凿孔模式。本文介绍一种准均匀凿孔算法属于C0凿孔模式。</p><h1 id="准均匀凿孔算法"><a href="#准均匀凿孔算法" class="headerlink" title="准均匀凿孔算法"></a>准均匀凿孔算法</h1><p><br>在速率适配极化码框架下，文献[2]提出准均匀凿孔（Quasi-uniform Puncturing，QUP）算法。</p><h2 id="RCPP方案"><a href="#RCPP方案" class="headerlink" title="RCPP方案"></a>RCPP方案</h2><p><br>基于CRC辅助译码的速率适配极化码（RCPP）方案如图1所示。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170321/183817210.jpg" title="图 1 RCPP coding and CRC-aided decoding scheme"></p><p>在发送端，首先$k$个信息比特输入CRC单元，添加$m$个校验比特，输出比特数为$K=k+m$。然后$K$比特源序列经过Polar编码器输出$N$个比特的编码序列。之后输入凿孔单元，被凿掉$N-M$个比特后，最终得到$M$比特的凿孔极化码。速率适配凿孔极化（RCPP）码方案的编码速率定义为$R={K}/{M}\;$。</p><p>RCPP码由长度为$N$的母码（Parent Code）利用凿孔向量（Puncturing Vector）得到：</p><script type="math/tex;mode=display">\mathbf{p}=\left( { {p}_{1}},{ {p}_{1}},...,{ {p}_{N}} \right)</script><p>其中${ {p}_{i}}\in \left\{ 0,1 \right\}$，$i=1,2,…,N$，取值为0的${ {p}_{i}}$指示凿孔比特位置。</p><p>由于被凿掉的比特并未实际传输，但接收端可以将这些凿孔比特信道视为容量为0的信道，也即凿孔比特可视为被传输了，只是被传输在容量为0的信道上。因此接收端不需要改变SCL译码结构，而是直接将凿孔比特信道对应的对数似然比（LLR）设置为全零。假设信道模型为BAWGN信道，根据高斯近似，$M$个实际传输的比特信道，其LLR服从$\left( m_{N}^{\left( i \right)},2m_{N}^{\left( i \right)} \right)$高斯分布；而$N-M$个凿孔比特信道未用于实际传输，但可以把这些信道视为LLR服从$\left( 0,0 \right)$的高斯信道。</p><h2 id="QUP算法"><a href="#QUP算法" class="headerlink" title="QUP算法"></a>QUP算法</h2><p><br>母码码长为$N={ {2}^{n}}$，凿孔比特数为${ {N}_{p}}=N-M$，凿孔向量$\mathbf{p}$是二进制向量，取值为0的元素指示凿孔比特位置。QUP算法描述如下：</p><p><strong>stage1）</strong>初始化向量$\mathbf{p}$为全1，设置前${ {N}_{p}}$个元素为0；<br><strong>stage2）</strong>对向量$\mathbf{p}$实施比特反转排序（bit-reversal permutation）操作，从而得到凿孔向量。</p><h2 id="QUP算法举例"><a href="#QUP算法举例" class="headerlink" title="QUP算法举例"></a>QUP算法举例</h2><p><br>对于$N=8,M=5,{ {N}_{p}}=3$的例子。初始化向量为$\mathbf{p}=\left( 00011111 \right)$，经过比特反转排序后的向量即为所求凿孔向量$\mathbf{p}=\left( 01010111 \right)$。其中序号为1，3，5的位置为凿孔比特位置。</p><h1 id="对QUP算法的理解"><a href="#对QUP算法的理解" class="headerlink" title="对QUP算法的理解"></a>对QUP算法的理解</h1><p><br>对于速率适配的凿孔极化码，$N$不再表示码长，而是表示母码长度，实际的Polar编码码长则为$M$，$M$比特中仍然包含信息比特和冻结比特，其中信息比特数为$K$，冻结比特数为$M-K$。信息比特又包含$k$个原始信息比特和$m$个CRC校验比特。</p><p>在编码端，首先还是利用巴氏参数或密度进化或高斯近似法估计信道错误概率，从而得到信息比特位置集$A$和冻结比特位置集${ {A}^{c}}$。注意这一步是按照母码长度$N$来计算的，因此有$\left| A \right|=K$，$\left| { {A}^{c}} \right|\text{=}N-K$。凿孔当然要在冻结比特${ {A}^{c}}$中去凿。凿掉${ {N}_{p}}$比特后，实际传输的冻结比特数应该有$M-K=N-K-{ {N}_{p}}$。编码速率为$R={K}/{M}\;$。</p><p>凿孔向量$\mathbf{p}$是凿孔比特数${ {N}_{p}}$的函数，只要收发双方约定好凿孔比特数${ {N}_{p}}$，那么$\mathbf{p}$对于编译码器就都是已知的。译码时仍然按照深度为$d=0,1,…,N$的码树来进行CA-SCL译码，得到$N$比特的估计序列。最后再根据凿孔向量$\mathbf{p}$凿掉相应的${ {N}_{p}}$个比特，最后输出$M$比特的估计序列。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><br>[1] Niu K, Dai J, Chen K, et al. Rate-Compatible Punctured Polar Codes: Optimal Construction Based on Polar Spectra[J]. 2016.<br>[2] Niu K, Chen K, Lin J R. Beyond turbo codes: Rate-compatible punctured polar codes[C]// IEEE International Conference on Communications. IEEE, 2013:3423-3427.</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --&gt;&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;&lt;br&gt;Arikan发明极化码时给出了编码算法和SC译码算法，后来的研究者提出SCL和CA-SCL译码算法对SC算法进行了改进，使译码性能得到提升。但不要忘记这些编译码算法都对码长有限定条件，即码长必须满足2的幂次方：$N={ {2}^{n}}$。虽然当码长$N$固定时，信息比特长度$K$可以任意取值，编码速率$R={K}/{N}\;$也能随之自由变化。但在信息比特长度一定的情况下，要通过调整码长而调整编码速率就无法实现了。从实际角度出发，我们更希望设计一对编译码器能够在不改变基本的编译码结构的情况下，使码长和编码速率都能够自适应调节。在设计速率可变的编码时，凿孔是一种普遍采用的方法。&lt;/p&gt;
    
    </summary>
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/categories/Polar-Code/"/>
    
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/tags/Polar-Code/"/>
    
  </entry>
  
  <entry>
    <title>Polar Code（9）CA-SCL译码算法</title>
    <link href="https://marshallcomm.github.io/2017/03/18/polar-code-9-ca-scl-decoder/"/>
    <id>https://marshallcomm.github.io/2017/03/18/polar-code-9-ca-scl-decoder/</id>
    <published>2017-03-18T12:09:48.000Z</published>
    <updated>2017-08-04T09:03:52.810Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><br>循环冗余校验（Cyclic redundancy check，CRC）是一种信道检错技术，在实际数字通信系统中已经得到了广泛应用。对于Polar码而言，在SCL译码结束时得到一组候选路径，能够以非常低的复杂度与CRC进行联合检测译码，选择能够通过CRC检测的候选序列作为译码器输出序列，从而提高译码算法的纠错能力。</p><h1 id="CA-SCL译码算法"><a href="#CA-SCL译码算法" class="headerlink" title="CA-SCL译码算法"></a>CA-SCL译码算法</h1><p><br>文献[1]提出了CRC辅助的SCL（CRC-aided SCL，CA-SCL）译码算法，在信息比特序列中添加CRC校验比特序列，利用SCL译码算法正常译码获得$L$条搜索路径，然后借助“正确信息比特可以通过CRC校验”的先验信息，对这$L$条搜索路径进行挑选，从而输出最佳译码路径。给定Polar码码长为$N$，CRC校验码码长为$m$，若极化码的信息为长度为$K$，编码信息比特的长度为$k$，如图1所示，有$K=k+m$。Polar码的码率仍然为$R={K}/{N}\;$。</p><a id="more"></a><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170318/201254373.jpg" title="图 1 Polar Coding and CRC-aided Decoding Scheme"></p><p>定义${ {L}^{\left( i \right)}}$为SCL译码码树第$i$层对应的候选路径集合，搜索列表宽度为$L$的CRC-aided SCL译码算法表示为CA-SCL（L），有如下算法步骤：</p><p>1、<strong>初始化</strong>：候选路径列表初始化为一条空路径，对应的路径度量值设置为0：${ {L}^{\left( 0 \right)}}=\left\{ \varnothing \right\}$，$M\left( \varnothing \right)=0$。</p><p>2、<strong>扩展</strong>：对于列表中的每个序列，产生2个长度为$i$的序列，分别对应译码${ {\hat{u}}_{i}}$为比特0或1，即</p><script type="math/tex;mode=display">{ {L}^{\left( i \right)}}=\left\{ \left( d_{1}^{i-1},{ {d}_{i}} \right)|d_{1}^{i-1}\in { {L}^{\left( i-1 \right)}},{ {d}_{i}}\in \left\{ 0,1 \right\} \right\}</script><p>对于每个$d_{1}^{i}\in { {L}^{\left( i \right)}}$更新路径度量值。</p><p>3、<strong>竞争</strong>：若经过步骤2后，列表中的路径数未达到$L$条，则跳过此步；否则，保存路径度量值最小的$L$条路径，并删除其余路径。</p><p>4、<strong>CRC辅助路径选择</strong>：重复步骤2和3直到码树第$N$层。把列表中的候选路径按度量值从小到大排序，依次进行CRC校验。第1个通过CRC校验的路径即为译码器输出的估计序列。若没有路径通过CRC检测，则把第1条路径作为译码器输出估计序列。</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p><br>CA-SCL译码算法是对SCL算法的增强，SCL的内核不变，只是在Polar编码之前给信息比特添加CRC，在SCL译码获得候选路径之后，进行CRC校验辅助路径选择，以较低的复杂度提升了Polar译码性能。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><br>[1] Niu K, Chen K. CRC-Aided Decoding of Polar Codes[J]. IEEE Communications Letters, 2012, 16(10):1668-1671.</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --&gt;&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;&lt;br&gt;循环冗余校验（Cyclic redundancy check，CRC）是一种信道检错技术，在实际数字通信系统中已经得到了广泛应用。对于Polar码而言，在SCL译码结束时得到一组候选路径，能够以非常低的复杂度与CRC进行联合检测译码，选择能够通过CRC检测的候选序列作为译码器输出序列，从而提高译码算法的纠错能力。&lt;/p&gt;&lt;h1 id=&quot;CA-SCL译码算法&quot;&gt;&lt;a href=&quot;#CA-SCL译码算法&quot; class=&quot;headerlink&quot; title=&quot;CA-SCL译码算法&quot;&gt;&lt;/a&gt;CA-SCL译码算法&lt;/h1&gt;&lt;p&gt;&lt;br&gt;文献[1]提出了CRC辅助的SCL（CRC-aided SCL，CA-SCL）译码算法，在信息比特序列中添加CRC校验比特序列，利用SCL译码算法正常译码获得$L$条搜索路径，然后借助“正确信息比特可以通过CRC校验”的先验信息，对这$L$条搜索路径进行挑选，从而输出最佳译码路径。给定Polar码码长为$N$，CRC校验码码长为$m$，若极化码的信息为长度为$K$，编码信息比特的长度为$k$，如图1所示，有$K=k+m$。Polar码的码率仍然为$R={K}/{N}\;$。&lt;/p&gt;
    
    </summary>
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/categories/Polar-Code/"/>
    
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/tags/Polar-Code/"/>
    
  </entry>
  
  <entry>
    <title>Polar Code（8）高斯近似</title>
    <link href="https://marshallcomm.github.io/2017/03/17/polar-code-8-gaussian-approximation/"/>
    <id>https://marshallcomm.github.io/2017/03/17/polar-code-8-gaussian-approximation/</id>
    <published>2017-03-17T09:25:03.000Z</published>
    <updated>2017-08-04T09:09:19.436Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><br>通过系列文章《Polar Code（1~7）》大致梳理了Polar Code从编码到译码的基本原理和算法步骤。本文回过头再来谈一谈高斯近似。高斯近似已在前文<a href="https://marshallcomm.github.io/2017/03/07/polar-code-4-encoding-chan-rel-est/">《Polar Code（4）编码之极化信道可靠性估计》</a>中有所介绍。对于Polar码的研究从BEC到一般类型的B-DMC，再到BAWGNC，越来越从理想走向实际。密度进化法把BEC扩展到了所有类型的B-DMC，高斯近似法则把B-DMC再次扩展到了BAWGNC。本文将梳理高斯近似在Polar Code编码和译码中的具体应用。</p><a id="more"></a><h1 id="Polar编码中的高斯近似"><a href="#Polar编码中的高斯近似" class="headerlink" title="Polar编码中的高斯近似"></a>Polar编码中的高斯近似</h1><p><br>高斯近似<sup>[1]</sup>是对密度进化的简化处理方法，早已广泛应用于LDPC码。<strong>高斯近似在Polar Code编码中用于信道的可靠性估计</strong><sup>[2]</sup>，即估计各个极化信道的错误概率。应用高斯近似法的基本前提是满足<strong>对称性条件</strong>，因为这正是密度进化法必须满足的条件。如果接收符号对数似然比的概率密度函数满足$f\left( x \right)=f\left( -x \right){ {e}^{x}}$，那么高斯分布的均值$m$和方差${ {\sigma }^{2}}$具有如下关系：${ {\sigma }^{2}}=2m$。由于高斯分布本身可以根据其均值和方差完全决定，所以在高斯近似假设条件下，只需要跟踪信息的均值变化就可以知道概率密度的变化。同时定义高斯变量的等效SNR为${ { {m}^{2}}}/{ { {\sigma }^{2}}}\;$，所以SNR为${m}/{2}\;$，跟踪均值也相当于跟踪SNR。</p><p>对于方差为${ {\sigma }^{2}}$的BAWGN信道$W$，源比特序列用BPSK调制，其转移概率为</p><script type="math/tex;mode=display">\begin{align}
W\left( y|x \right)=\frac{1}{\sqrt{2\pi { {\sigma }^{2}}}}{ {e}^{-\frac{ { {\left( y-\left( 1-2x \right) \right)}^{2}}}{2{ {\sigma }^{2}}}}}
\end{align}</script><p>接收符号 的对数似然比（LLR）定义为</p><script type="math/tex;mode=display">\begin{align}
L\left( y \right)=\ln \frac{W\left( y|0 \right)}{W\left( y|1 \right)}=\frac{2y}{ { {\sigma }^{2}}}
\end{align}</script><p>由于此时信道满足了对称性条件，那么译码错误概率与传输的码字无关，因此不失一般性，我们可以假设码字为全零发送，则LLR是服从均值为$\frac{2}{ { {\sigma }^{2}}}$，方差为$\frac{4}{ { {\sigma }^{2}}}$的高斯分布。</p><h2 id="高斯近似假设"><a href="#高斯近似假设" class="headerlink" title="高斯近似假设"></a>高斯近似假设</h2><p><br><strong>GA assumption</strong>：每个子信道的LLR都服从方差为均值2倍的高斯分布，即</p><script type="math/tex;mode=display">\begin{align}
L_{N}^{\left( i \right)}\sim N\left( m_{N}^{\left( i \right)},2m_{N}^{\left( i \right)} \right)
\end{align}</script><p>其中，$m_{1}^{\left( 1 \right)}=\frac{2}{ { {\sigma }^{2}}}$。</p><p>基于这样的高斯近似假设，唯一需要考虑的问题就是如何计算均值。根据密度进化中的设定，令$a_{N}^{\left( i \right)}$表示$L_{N}^{\left( i \right)}\left( y_{1}^{N},0_{1}^{i-1} \right)$的概率密度函数，那么$a_{N}^{\left( i \right)}$是服从$N\left( m_{N}^{\left( i \right)},2m_{N}^{\left( i \right)} \right)$的高斯分布。再根据高斯近似的构造理论，将密度进化的计算转化为对均值$m_{N}^{\left( i \right)}$的递归计算：</p><script type="math/tex;mode=display">\begin{align}
m_{2N}^{\left( 2i\text{-}1 \right)}={ {\varphi }^{-1}}\left( 1-{ {\left[ 1-\varphi \left( m_{N}^{\left( i \right)} \right) \right]}^{2}} \right)
\end{align}</script><script type="math/tex;mode=display">\begin{align}
m_{2N}^{\left( 2i \right)}=2m_{N}^{\left( i \right)}
\end{align}</script><script type="math/tex;mode=display">\begin{align}
m_{1}^{\left( 1 \right)}={2}/{ { {\sigma }^{2}}}\;
\end{align}</script><p>其中函数</p><script type="math/tex;mode=display">\begin{align}
\varphi \left( x \right)=\left\{ \begin{matrix}
   1-\frac{1}{\sqrt{4\pi x}}\int_{-\infty }^{\infty }{\tanh \frac{u}{2}\cdot \exp \left( -\frac{ { {\left( u-x \right)}^{2}}}{4x} \right)du,x>0}  \\
   1\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ ,x=0  \\
\end{matrix} \right.
\end{align}</script><p>$\varphi \left( x \right)$在$\left[ 0,\infty \right)$上连续单调递减，$\varphi \left( 0 \right)\text{=}1$，$\varphi \left( +\infty \right)\text{=0}$，其反函数用${ {\varphi }^{-1}}\left( x \right)$表示。一般情况下，函数$\varphi \left( x \right)$可以使用如下GA近似式（AGA）<sup>[1]</sup>计算</p><script type="math/tex;mode=display">\begin{align}
\varphi \left( x \right)=\left\{ \begin{matrix}
   \sqrt{\frac{\pi }{x}}\left( 1-\frac{10}{7x} \right)\exp \left( -\frac{x}{4} \right),x\ge 10  \\
   \exp \left( -0.4527{ {x}^{0.86}}+0.0218 \right),0<x<10  \\
\end{matrix} \right.
\end{align}</script><h2 id="我发现的问题"><a href="#我发现的问题" class="headerlink" title="我发现的问题"></a>我发现的问题</h2><p><br><strong>注意式（8）的第二个式子中0.86应当是个正数</strong>，其出处在Sae-Young Chung于2001年发表的论文<sup>[1]</sup>中，如图1所示。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170317/183242980.png" title="图 1 phi(x) in Sae-Young Chung’s Paper"></p><p>许多中文文献虽然同样引用了这篇论文，但$\gamma $值却是-0.86。这些使用-0.86的文献不乏最近一两年（2015、2016）的硕博士论文，这里并不一一举例，仅就事论事地指出这个问题可能值得商榷。由于密度进化和高斯近似在LDPC码中早已应用，也可以举一个关于LDPC码早已成书的例子，在2008年出版的《LDPC码理论与应用》<sup>[3]</sup>一书中，在120页就使用了-0.86，如图2所示。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170317/183501206.png" title="图 2 《LDPC码理论与应用》P120"></p><p>下面就比较一下0.86和-0.86对$\varphi \left( x \right)$函数的影响有何不同，如图2和图3所示。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170317/183630103.bmp" title="图 3 gamma取0.86时，$\varphi \left( x \right)$的曲线"></p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170317/183715241.bmp" title="图 4 gamma取-0.86时，$\varphi \left( x \right)$的曲线"></p><p>$x\ge 10$的范围是完全相同的；不同的地方就在于$0&lt;x&lt;10$。这会影响均值的取值，从而影响LLR的概率密度。这一点很重要，涉及到仿真参数的配置和仿真性能。</p><p>关于这一点就说到这里，<strong>我的结论是：gamma的取值还是回到Sae-Young Chung的原始论文，取值为正0.86。</strong></p><h2 id="改进的AGA"><a href="#改进的AGA" class="headerlink" title="改进的AGA"></a>改进的AGA</h2><p><br>高斯近似是对密度进化的简化，既然是简化，就会以损失一部分性能为代价。幸运的是，这代价很小，是可以接受的范围，如图2所说，高斯近似与密度进化的信道参数极限值仅相差$0.3%\sim 1.2%$。但式（7）计算起来稍显复杂，于是Sae-Young Chung提出了对高斯近似的近似式（Approximate version of GA，AGA），也就是式（8）。</p><p>不过对于Polar Code，当码长$N$很长时，由于式（8）的计算误差会带来很大的性能损失，于是Jincheng Dai等人提出了改进的AGA。文献[4]采用累积对数误差（cumulative-logarithmic error，CLE）来定量评估AGA在对数域上的余补误差，提出了新的两段式估计函数</p><script type="math/tex;mode=display">\begin{align}
{ {\varphi }_{AGA-2}}\left( x \right)=\left\{ \begin{matrix}
   { {e}^{0.0116{ {x}^{2}}-0.4212x}},\ 0<x\le a  \\
   { {e}^{-0.2944x-0.3169}},\ a<x  \\
\end{matrix} \right.
\end{align}</script><p>其中，临界点$a=7.0633$。与此同时，还提出了一种适合于Polar Code，特别是对于长码的三段式估计函数</p><script type="math/tex;mode=display">\begin{align}
{ {\varphi }_{AGA-3}}\left( x \right)\text{=}\left\{ \begin{matrix}
   { {e}^{0.06725{ {x}^{2}}-0.4908x}},\ 0<x\le a  \\
   { {e}^{-0.4527{ {x}^{0.86}}}}+0.0218,\ a<x\le b  \\
   { {e}^{-0.2832x-0.4254}},\ b<x  \\
\end{matrix} \right.
\end{align}</script><p>其中，临界点$a=0.6357,b=9.2254$。</p><p>通过式（4~6）、式（9）或式（10）即可递归求出各极化信道的均值。</p><h2 id="极化子信道错误概率"><a href="#极化子信道错误概率" class="headerlink" title="极化子信道错误概率"></a>极化子信道错误概率</h2><p><br>根据式（3）的高斯近似假设，各个极化子信道的错误概率为</p><script type="math/tex;mode=display">\begin{align}
{ {P}_{e}}\left( W_{N}^{\left( i \right)} \right)=Q\left( \frac{m_{N}^{\left( i \right)}}{\sqrt{2m_{N}^{\left( i \right)}}} \right)=Q\left( \sqrt{\frac{m_{N}^{\left( i \right)}}{2}} \right)
\end{align}</script><p>其中$Q\left( x \right)=\frac{1}{\sqrt{2\pi }}\int_{x}^{+\infty }{ { {e}^{-\frac{ { {t}^{2}}}{2}}}}dt$为余补误差函数。</p><p>至此，高斯近似在Polar Code编码中的使命就完成了。接下来就是<a href="https://marshallcomm.github.io/2017/03/05/polar-code-3-encoding-example/">《Polar Code（3）编码实例》</a>中的第二步比特混合了。</p><h1 id="Polar译码中的高斯近似"><a href="#Polar译码中的高斯近似" class="headerlink" title="Polar译码中的高斯近似"></a>Polar译码中的高斯近似</h1><p><br>在接收端译码时，首先要计算如图5最右端所示的信道对数似然比$L_{1}^{\left( 1 \right)}\left( { {y}_{j}} \right)$。假设接收端的接收序列为$y_{1}^{N}$，直接由式（2）即可依次计算出：</p><script type="math/tex;mode=display">\begin{align}
L_{1}^{\left( 1 \right)}\left( { {y}_{j}} \right)=\ln \frac{W\left( y|0 \right)}{W\left( y|1 \right)}=\frac{2{ {y}_{j}}}{ { {\sigma }^{2}}}
\end{align}</script><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170314/134726685.jpg" title="图 5 $L_{1}^{\left( 1 \right)}\left( { {y}_{j}} \right)$"></p><p>接下来就可以利用LLR递归式依次计算各个节点的LLR值了。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p><br>转移概率，多么重要的信道参数。高斯近似，多么重要的估计方法。有了这两点，就可以把Polar Code编码和译码各个环节串联起来。在编码端，通过高斯近似估计子信道错误概率，扬长避短，择其善者而传信息，避其不善者而冻结。然后比特混合，构造生成矩阵，终成一列极化码。在译码端，还是通过高斯近似估计信道对数似然值，构造判决函数，或深度优先或广度优先，逐比特判决，从而估计出源比特序列。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><br>[1] Chung S Y, Richardson T J, Urbanke R L. Analysis of sum-product decoding of low-density parity-check codes using a Gaussian approximation[J]. IEEE Transactions on Information Theory, 2001, 47(2):657-670.<br>[2] Trifonov P. Efficient Design and Decoding of Polar Codes[J]. IEEE Transactions on Communications, 2012, 60(11):3221-3227.<br>[3] 袁东风, 张海刚. LDPC码理论与应用[M]. 人民邮电出版社, 2008.<br>[4] Dai J, Niu K, Si Z, et al. Evaluation and Optimization of Gaussian Approximation for Polar Codes[J]. Proceedings of the American Society for Information Science &amp; Technology, 2016, 51(1):1-2.</p><h1 id="相关链接"><a href="#相关链接" class="headerlink" title="相关链接"></a>相关链接</h1><p><br><a href="http://marshallcomm.cn/2017/08/04/polar-code-17-gaussian-approximation2/" target="_blank" rel="external">《Polar Code（17）高斯近似（2）》</a><br><a href="http://marshallcomm.cn/2017/03/07/polar-code-4-encoding-chan-rel-est/" target="_blank" rel="external">《Polar Code（4）编码之极化信道可靠性估计》</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --&gt;&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;&lt;br&gt;通过系列文章《Polar Code（1~7）》大致梳理了Polar Code从编码到译码的基本原理和算法步骤。本文回过头再来谈一谈高斯近似。高斯近似已在前文&lt;a href=&quot;https://marshallcomm.github.io/2017/03/07/polar-code-4-encoding-chan-rel-est/&quot;&gt;《Polar Code（4）编码之极化信道可靠性估计》&lt;/a&gt;中有所介绍。对于Polar码的研究从BEC到一般类型的B-DMC，再到BAWGNC，越来越从理想走向实际。密度进化法把BEC扩展到了所有类型的B-DMC，高斯近似法则把B-DMC再次扩展到了BAWGNC。本文将梳理高斯近似在Polar Code编码和译码中的具体应用。&lt;/p&gt;
    
    </summary>
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/categories/Polar-Code/"/>
    
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/tags/Polar-Code/"/>
    
  </entry>
  
  <entry>
    <title>Polar Code（7）SCL译码算法</title>
    <link href="https://marshallcomm.github.io/2017/03/15/polar-code-7-scl-decoder/"/>
    <id>https://marshallcomm.github.io/2017/03/15/polar-code-7-scl-decoder/</id>
    <published>2017-03-15T12:40:17.000Z</published>
    <updated>2017-08-04T09:03:21.203Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><br>Polar Code在码长趋于无穷时，信道极化才越完全。但在有限码长下，由于信道极化并不完全，依然会存在一些信息比特无法被正确译码。当前面$i-1$个信息比特的译码中发生错误之后，由于SC译码器在对后面的信息比特译码时需要用到之前的信息比特的估计值，这就会导致较为严重的错误传递。SC译码算法是一种贪婪算法，对码树的每一层仅仅搜索到最优路径就进行下一层，所以无法对错误进行修改。SCL译码算法就是对SC算法的改进。但在SCL之前，先来看看SC译码算法的码树表示。</p><a id="more"></a><h1 id="SC译码算法的码树表示"><a href="#SC译码算法的码树表示" class="headerlink" title="SC译码算法的码树表示"></a>SC译码算法的码树表示</h1><p><br>根据极化码在SC译码下各个比特判决之间的依赖关系，能够构造一颗码树$\Gamma =\left( \varepsilon ,V \right)$，其中$\varepsilon $和$V$分别表示码树中的边和节点集合。定义节点的深度为该节点到根节点的最短路径长度，对于一个码长为$N$的极化码，其码树节点集合$V$能够按照深度$d$划分成$N+1$个子集，记作${ {V}_{d}}$，其中$d=0,1,…,N$。特别地，${ {V}_{0}}$仅包含根节点，即$\left| { {V}_{0}} \right|=1$。除了叶节点（即$d=N$时），码树$\Gamma $中的每一个节点$v\in { {V}_{d}}$均分别通过两条标记着0、1的边与两个${ {V}_{d+1}}$中的后继节点相连。某一个节点$v$所对应的序列$u_{1}^{d}$的值定义为从根节点开始到达该节点$v$所需经过的各个边的标记序列。例如，若某一个节点$v$表示了序列$u_{1}^{i}$，则其左、右后继节点分别代表了路径$\left( u_{1}^{i},u_{1}^{i+1}=0 \right)$与$\left( u_{1}^{i},u_{1}^{i+1}=1 \right)$。于是，从根节点到每一个深度为$d$的节点$v\in { {V}_{d}}$的路径，均对应了一种$u_{1}^{d}$可能的取值，由于信源序列为二进制比特序列，所以$\left| { {V}_{d}} \right|={ {2}^{d}}$。定义连接着深度为$i-1$和$i$的节点的边所构成的集合为第$i$层边，记作${ {\varepsilon }_{i}}$。显然，对任意$i\in \left\{ 1,2,…,N \right\}$，有$\left| { {\varepsilon }_{i}} \right|={ {2}^{i}}$。从根节点到任何一个节点所形成的路径，均对应一个路径度量值（PM）。值得注意的是，该码树结构仅与码长$N$有关。极化码译码码树实质上是一个满二叉树，因此译码过程也就是在满二叉树上寻找合适的路径。如图1所示，给出了一个当$N=4$时极化码码树的示例，各节点旁的数字指示了对应的转移概率，在每个节点处选择转移概率最大的路径，最终译码序列为$\hat{u}_{1}^{N}=\left[ \begin{matrix}<br>0 &amp; 0 &amp; 1 &amp; 1 \\<br>\end{matrix} \right]$。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170315/205026503.jpg" title="图 1 码长为4的极化码译码码树"></p><h1 id="SCL译码算法"><a href="#SCL译码算法" class="headerlink" title="SCL译码算法"></a>SCL译码算法</h1><p><br>针对SC译码算法的缺点，一个直接的改进方案是，增加每一层路径搜索后允许保留的候选路径数量，从仅允许选择“最好的一条路径进行下一步扩展”改为“最大允许选择最好的 条路径进行下一步扩展”，其中$L\ge 1$。与SC算法一样，改进的算法依然从码树根节点开始，逐层依次向叶子节点层进行路径搜索。不同的是，每一层扩展后，尽可能多地保留后继路径（每一层保留的路径数不大于$L$）。完成一层的路径扩展后，选择路径度量值（Path Metrics，PM）最小的$L$条，保存在一个列表中，等待进行下一层的扩展。因此称该算法为<strong>串行抵消列表（Successive Cancellation List，SCL）译码算法</strong>，并称参数$L$为<strong>搜索宽度</strong>。当$L=1$时，SCL译码算法退化为SC译码算法；当$L\ge { {2}^{K}}$时，SCL译码等价于最大似然译码。</p><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p><br>现在思考一个问题：如图2所示，当Polar Code编译码结构用“蝶形图”表示时，在译码时只需要在每个节点处计算相应的对数似然比，从右到左依次计算，并最终得到$L_{N}^{\left( i \right)}\left( y_{1}^{N},u_{1}^{i-1} \right)$，若LLR值为非负则判决${ {\hat{u}}_{i}}=0$，否则判决${ {\hat{u}}_{i}}=1$。一共有$N\log N$个节点，因此相应地也要计算$N\log N$个LLR。对于图2来说这一过程没有任何问题。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170315/205500502.jpg" title="图 2 Polar Code编译码结构蝶形图表示"></p><p>现在转换思路，将译码结构用二叉树表示，一个LLR值指示了每个节点两条支路上的转移概率的比值关系。如果像图1那样，每条支路就用转移概率来表征，向左是发送为比特0的转移概率，向右是发送为比特1的转移概率。当然这样也可以，对于SC译码来说，图1使用转移概率和图2使用对数似然比实际上是等价的。但随着码长的增加，转移概率函数的数值会越来越小，译码器存在着下溢的风险，所以通常不直接使用转移概率。由于SC译码过程实质上是二值判决，因此通常还是要采用转移概率的对数似然比。</p><p>现在可以明确两点：一是使用对数似然比，二是在满二叉树上使用对数似然比。但仍然存在的问题是：SC算法实际上是SCL算法的特例，即搜索宽度$L=1$的情况；对于$L\ge 2$的情况，单单依靠LLR是无法在$2L$个后继节点中挑选$L$个最优节点作为后继译码路径的。这就需要在LLR的基础上对$2L$条路径度量值进行计算，以便可以实现在对数似然域上的SCL译码算法。因此需要明确的第三点就是：重新定义路径度量值（PM）。</p><h2 id="路径度量值"><a href="#路径度量值" class="headerlink" title="路径度量值"></a>路径度量值</h2><p><br>在SCL译码过程中，存在$L$条路径同时进行译码搜索，对于任意一条路径$l\in \left\{ 1,2,…,L \right\}$以及任意发送比特${ {u}_{i}}$（$i\in \left\{ 1,2,…,N \right\}$），其对应的路径度量值定义如下：</p><script type="math/tex;mode=display">\begin{align}
PM_{l}^{\left( i \right)}\triangleq \sum\limits_{j=1}^{i}{\ln \left( 1+\exp \left( -\left( 1-2{ { {\hat{u}}}_{j}}\left[ l \right] \right)\cdot L_{N}^{\left( j \right)} \right) \right)}
\end{align}</script><p>其中，$L_{N}^{\left( j \right)}\left[ l \right]=\ln \frac{W_{N}^{\left( i \right)}\left( y_{1}^{N},\hat{u}_{1}^{i-1}\left[ l \right]|0 \right)}{W_{N}^{\left( i \right)}\left( y_{1}^{N},\hat{u}_{1}^{i-1}\left[ l \right]|1 \right)}$。</p><p>如果发送端所有信息比特在$\left\{ 0,1 \right\}$上均匀分布，那么对于任意两条不同路径${ {l}_{1}},{ {l}_{2}}\in \left\{ 1,2,…,L \right\}$，当且仅当$PM_{ { {l}_{1}}}^{\left( i \right)}&gt;PM_{ { {l}_{2}}}^{\left( i \right)}$成立时，有如下关系成立：</p><script type="math/tex;mode=display">\begin{align}
W_{N}^{\left( i \right)}\left( y_{1}^{N},\hat{u}_{1}^{i-1}\left[ { {l}_{1}} \right]|\hat{u}_{1}^{i}\left[ { {l}_{1}} \right] \right)<W_{N}^{\left( i \right)}\left( y_{1}^{N},\hat{u}_{1}^{i-1}\left[ { {l}_{2}} \right]|\hat{u}_{1}^{i}\left[ { {l}_{2}} \right] \right)
\end{align}</script><p>由上式可见，路径对应的转移概率越大，路径度量值越小。基于这种关系就完全可以在对数似然比上对$2L$条路径进行挑选。式（1）可以近似表示为</p><script type="math/tex;mode=display">\begin{align}
\nonumber PM_{l}^{\left( i \right)}\approx \left\{ \begin{matrix}
   PM_{l}^{\left( i-1 \right)},\ \ if\ { { {\hat{u}}}_{i}}\left[ l \right]=\delta \left( L_{N}^{\left( i \right)}\left[ l \right] \right)  \\
   PM_{l}^{\left( i-1 \right)}+\left| L_{N}^{\left( i \right)}\left[ l \right] \right|,\ \ if\ { { {\hat{u}}}_{i}}\left[ l \right]\ne \delta \left( L_{N}^{\left( i \right)}\left[ l \right] \right)  \\
\end{matrix} \right.
\end{align}</script><p>但考虑译码过程中包含了信息比特和冻结比特，因此上式可以改写为</p><script type="math/tex;mode=display">PM_{l}^{\left( i \right)}=\left\{ \begin{align}
  \nonumber & PM_{l}^{\left( i-1 \right)}\ \ ,\ if\ { {u}_{i}}\ is\ \text{information or frozen bit}\ and\text{ }{ { {\hat{u}}}_{i}}\left[ l \right]=\delta \left( L_{N}^{\left( i \right)}\left[ l \right] \right) \\ 
 & PM_{l}^{\left( i-1 \right)}+\left| L_{N}^{\left( i \right)}\left[ l \right] \right|,\ if\ { {u}_{i}}\ is\ \text{information or frozen bit}\ and\text{ }{ { {\hat{u}}}_{i}}\left[ l \right]\ne \delta \left( L_{N}^{\left( i \right)}\left[ l \right] \right) \\ 
 \nonumber & +\infty \ \ ,\ if\ { {u}_{i}}\ is\ \text{frozen bit}\ and\ \text{incorrect value} \\ 
\end{align} \right.</script><p>其中$\delta \left( x \right)=\frac{1}{2}\left( 1-sign\left( x \right) \right)$，$PM_{l}^{\left( 0 \right)}=0$。对于信息比特的判决有</p><script type="math/tex;mode=display">\begin{align}
{ {\hat{u}}_{i}}=\delta \left( L_{N}^{\left( i \right)}\left( y_{1}^{N},\hat{u}_{1}^{i-1} \right) \right)
\end{align}</script><h1 id="SCL译码示例"><a href="#SCL译码示例" class="headerlink" title="SCL译码示例"></a>SCL译码示例</h1><p><br>下面仍然以<a href="https://marshallcomm.github.io/2017/03/13/polar-code-6-sc-decoder/">《Polar Code（6）SC译码算法》</a>中的SC译码的例子为例来说明SCL算法的具体实现过程。给定发送端原始比特序列$u_{1}^{4}=\left( \begin{matrix}<br>{ {u}_{1}} &amp; { {u}_{2}} &amp; { {u}_{3}} &amp; { {u}_{4}} \\<br>\end{matrix} \right)=\left( \begin{matrix}<br>0 &amp; 0 &amp; 0 &amp; 0 \\<br>\end{matrix} \right)$，其中${ {u}_{1}}$为冻结比特，$u_{2}^{4}$为信息比特。经过Polar编码以后通过AWGN信道传输。假设接收端已知各子信道对数似然比$L_{1}^{\left( 1 \right)}\left( y_{1}^{4} \right)=\left[ \begin{matrix}<br>1.5 &amp; 2 &amp; -1 &amp; 0.5 \\<br>\end{matrix} \right]$。</p><font color="#FF0000">每一条路径都拥有自己的一套LLR值，每一条路径的PM都要根据各自路径上的LLR值计算。以a、b、c、d表示路径1、路径2、路径3、路径4。为了便于说明SCL译码过程，PM值直接标注在示意图上，LLR值则用一个向量来表示。</font><h2 id="搜索第一层"><a href="#搜索第一层" class="headerlink" title="搜索第一层"></a>搜索第一层</h2><h3 id="计算第1个比特相关的LLR"><a href="#计算第1个比特相关的LLR" class="headerlink" title="计算第1个比特相关的LLR"></a>计算第1个比特相关的LLR</h3><p><br><script type="math/tex">L_{4}^{\left( 1 \right)}\left( y_{1}^{4} \right)=f\left( L_{2}^{\left( 1 \right)}\left( y_{1}^{2} \right),L_{2}^{\left( 1 \right)}\left( y_{3}^{4} \right) \right)</script></p><p>其中，$L_{2}^{\left( 1 \right)}\left( y_{1}^{2} \right)$和$L_{2}^{\left( 1 \right)}\left( y_{3}^{4} \right)$递归地计算为</p><script type="math/tex;mode=display">L_{2}^{\left( 1 \right)}\left( y_{1}^{2} \right)=f\left( L_{1}^{\left( 1 \right)}\left( { {y}_{1}} \right),L_{1}^{\left( 1 \right)}\left( { {y}_{2}} \right) \right)=f\left( 1.5,2 \right)=1.06</script><script type="math/tex;mode=display">L_{2}^{\left( 1 \right)}\left( y_{3}^{4} \right)=f\left( L_{1}^{\left( 1 \right)}\left( { {y}_{3}} \right),L_{1}^{\left( 1 \right)}\left( { {y}_{4}} \right) \right)=f\left( -1,0.5 \right)=-0.23</script><p>从而，<script type="math/tex">L_{4}^{\left( 1 \right)}\left( y_{1}^{4} \right)=f\left( 1.06,-0.23 \right)=-0.11</script>。</p><p><strong>建立向量LLR</strong></p><script type="math/tex;mode=display">\mathbf{LLR}=\left[ \begin{matrix}
   -0.11 & -0.11  \\
\end{matrix} \right]</script><h3 id="计算候选路径的度量值"><a href="#计算候选路径的度量值" class="headerlink" title="计算候选路径的度量值"></a>计算候选路径的度量值</h3><h4 id="a-0"><a href="#a-0" class="headerlink" title="a. 0"></a>a. 0</h4><p><br>$L_{4}^{\left( 1 \right)}$取向量$\mathbf{LLR}$的<font color="#FF0000"> 第1元素</font> ，即$L_{4}^{\left( 1 \right)}=-0.11$；比特估计值${ {\hat{u}}_{1}}=0$。</p><p>$\delta \left( L_{4}^{\left( 1 \right)} \right)=\frac{1}{2}\left( 1-sign\left( -0.11 \right) \right)=1$。由于${ {u}_{1}}$是冻结比特，但${ {\hat{u}}_{1}}\ne \delta \left( L_{4}^{\left( 1 \right)} \right)$，所以有</p><script type="math/tex;mode=display">PM\left( { { {\hat{u}}}_{1}}=0 \right)=PM_{1}^{\left( 0 \right)}+\left| L_{4}^{\left( 1 \right)} \right|=0+0.11=0.11</script><h4 id="b-1"><a href="#b-1" class="headerlink" title="b. 1"></a>b. 1</h4><p><br>$L_{4}^{\left( 1 \right)}$取向量$\mathbf{LLR}$的<font color="#FF0000"> 第2元素</font> ，即$L_{4}^{\left( 1 \right)}=-0.11$；比特估计值${ {\hat{u}}_{1}}=1$。</p><p>$\delta \left( L_{4}^{\left( 1 \right)} \right)=\frac{1}{2}\left( 1-sign\left( -0.11 \right) \right)=1$。由于${ {u}_{1}}$是冻结比特，但此时${ {\hat{u}}_{1}}=1$显然取值错误，所以有</p><script type="math/tex;mode=display">PM\left( { { {\hat{u}}}_{1}}=1 \right)=\text{+}\infty</script><h4 id="路径扩展"><a href="#路径扩展" class="headerlink" title="路径扩展"></a>路径扩展</h4><p><br>如图3所示，由于搜索宽度已达到$L=2$，因此第1层的2条路径均保留。继续在下一层扩展，至$2L$条路径，再从中挑选$L$条。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170315/221254645.jpg" title="图 3 SCL译码算法在第1层的扩展"></p><h2 id="搜索第二层"><a href="#搜索第二层" class="headerlink" title="搜索第二层"></a>搜索第二层</h2><h3 id="计算第2个比特相关的LLR"><a href="#计算第2个比特相关的LLR" class="headerlink" title="计算第2个比特相关的LLR"></a>计算第2个比特相关的LLR</h3><p><br>分别计算$2L$条路径在第2层对应的LLR。</p><h4 id="a-00"><a href="#a-00" class="headerlink" title="a. 00"></a>a. 00</h4><p><br>比特估计值${ {\hat{u}}_{1}}=0$，所以有</p><script type="math/tex;mode=display">\nonumber \begin{align}
  & L_{4}^{\left( 2 \right)}\left( y_{1}^{4},{ { {\hat{u}}}_{1}} \right)=g\left( L_{2}^{\left( 1 \right)}\left( y_{1}^{2} \right),L_{2}^{\left( 1 \right)}\left( y_{3}^{4} \right),{ { {\hat{u}}}_{1}} \right)\text{=}g\left( 1.06,-0.23,0 \right) \\ 
 \nonumber & ={ {\left( -1 \right)}^{0}}\times 1.06+\left( -0.23 \right) \\ 
 \nonumber & =0.83 \\ 
\end{align}</script><p><strong>重新建立向量LLR</strong></p><script type="math/tex;mode=display">\mathbf{LLR}=\left[ 0.83 \right]</script><h4 id="b-01"><a href="#b-01" class="headerlink" title="b. 01"></a>b. 01</h4><p><br>同上，$L_{4}^{\left( 2 \right)}\left( y_{1}^{4},{ { {\hat{u}}}_{1}} \right)=0.83$。</p><p><strong>更新向量LLR</strong></p><script type="math/tex;mode=display">\mathbf{LLR}=\left[ \begin{matrix}
   0.83 & 0.83  \\
\end{matrix} \right]</script><h4 id="c-10"><a href="#c-10" class="headerlink" title="c. 10"></a>c. 10</h4><p><br>比特估计值${ {\hat{u}}_{1}}=1$，所以有</p><script type="math/tex;mode=display">\begin{align}
  \nonumber & L_{4}^{\left( 2 \right)}\left( y_{1}^{4},{ { {\hat{u}}}_{1}} \right)=g\left( L_{2}^{\left( 1 \right)}\left( y_{1}^{2} \right),L_{2}^{\left( 1 \right)}\left( y_{3}^{4} \right),{ { {\hat{u}}}_{1}} \right)\text{=}g\left( 1.06,-0.23,1 \right) \\ 
 \nonumber & ={ {\left( -1 \right)}^{1}}\times 1.06+\left( -0.23 \right) \\ 
 \nonumber & =-1.29 \\ 
\end{align}\</script><p><strong>更新向量LLR</strong></p><script type="math/tex;mode=display">\mathbf{LLR}=\left[ \begin{matrix}
   \begin{matrix}
   0.83 & 0.83  \\
\end{matrix} & -1.29  \\
\end{matrix} \right]</script><h4 id="d-11"><a href="#d-11" class="headerlink" title="d. 11"></a>d. 11</h4><p><br>同上，$L_{4}^{\left( 2 \right)}\left( y_{1}^{4},{ { {\hat{u}}}_{1}} \right)=-1.29$。</p><p><strong>更新向量LLR</strong></p><script type="math/tex;mode=display">\mathbf{LLR}=\left[ \begin{matrix}
   \begin{matrix}
   \begin{matrix}
   0.83 & 0.83  \\
\end{matrix} & -1.29  \\
\end{matrix} & -1.29  \\
\end{matrix} \right]</script><h3 id="计算候选路径的度量值-1"><a href="#计算候选路径的度量值-1" class="headerlink" title="计算候选路径的度量值"></a>计算候选路径的度量值</h3><p><br>由于在上一层已经扩展至$L$条路径，那么在这一层将会计算$2L$条路径的度量值，然后保留PM最小的$L$条路径，并且删除其余路径。</p><h4 id="a-00-1"><a href="#a-00-1" class="headerlink" title="a. 00"></a>a. 00</h4><p><br>$L_{4}^{\left( 2 \right)}$取向量$\mathbf{LLR}$的<font color="#FF0000"> 第1元素</font> ，即$L_{4}^{\left( 2 \right)}=0.83$；比特估计值${ {\hat{u}}_{2}}=0$。</p><p>$\delta \left( L_{4}^{\left( 2 \right)} \right)=\frac{1}{2}\left( 1-sign\left( 0.83 \right) \right)=0$。由于${ {u}_{2}}$为信息比特，且${ {\hat{u}}_{2}}=\delta \left( L_{4}^{\left( 2 \right)} \right)$，所以有</p><script type="math/tex;mode=display">PM\left( \hat{u}_{1}^{2}=00 \right)=PM\left( { { {\hat{u}}}_{1}}=0 \right)=0.11</script><h4 id="b-01-1"><a href="#b-01-1" class="headerlink" title="b. 01"></a>b. 01</h4><p><br>$L_{4}^{\left( 2 \right)}$取向量$\mathbf{LLR}$的<font color="#FF0000"> 第2元素</font> ，即$L_{4}^{\left( 2 \right)}=0.83$；比特估计值${ {\hat{u}}_{2}}=1$。</p><p>$\delta \left( L_{4}^{\left( 2 \right)} \right)=\frac{1}{2}\left( 1-sign\left( 0.83 \right) \right)=0$。由于${ {u}_{2}}$为信息比特，且${ {\hat{u}}_{2}}\ne \delta \left( L_{4}^{\left( 2 \right)} \right)$，所以有</p><script type="math/tex;mode=display">PM\left( \hat{u}_{1}^{2}=01 \right)=PM\left( { { {\hat{u}}}_{1}}=0 \right)+\left| L_{4}^{\left( 2 \right)} \right|\text{=0}\text{.11+}0.83=0.94</script><p>截止目前的扩展路径如图4所示。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170315/221926567.jpg" title="图 4 SCL译码算法在第2层的扩展"></p><h4 id="c-10-1"><a href="#c-10-1" class="headerlink" title="c. 10"></a>c. 10</h4><p><br>$L_{4}^{\left( 2 \right)}$取向量$\mathbf{LLR}$的<font color="#FF0000"> 第3元素</font> ，即$L_{4}^{\left( 2 \right)}=-1.29$；比特估计值${ {\hat{u}}_{2}}=0$。</p><p>$\delta \left( L_{4}^{\left( 2 \right)} \right)=\frac{1}{2}\left( 1-sign\left( -1.29 \right) \right)=1$。由于${ {u}_{2}}$为信息比特，且${ {\hat{u}}_{2}}\ne \delta \left( L_{4}^{\left( 2 \right)} \right)$，所以有</p><script type="math/tex;mode=display">PM\left( \hat{u}_{1}^{2}=10 \right)=PM\left( { { {\hat{u}}}_{1}}=1 \right)\text{+}L_{4}^{\left( 2 \right)}\text{=}+\infty +1.29\to +\infty</script><h4 id="d-11-1"><a href="#d-11-1" class="headerlink" title="d. 11"></a>d. 11</h4><p><br>$L_{4}^{\left( 2 \right)}$取向量$\mathbf{LLR}$的<font color="#FF0000"> 第4元素</font> ，即$L_{4}^{\left( 2 \right)}=-1.29$；比特估计值${ {\hat{u}}_{2}}=1$。</p><p>$\delta \left( L_{4}^{\left( 2 \right)} \right)=\frac{1}{2}\left( 1-sign\left( -1.29 \right) \right)=1$。由于${ {u}_{2}}$为信息比特，且${ {\hat{u}}_{2}}=\delta \left( L_{4}^{\left( 2 \right)} \right)$，所以有</p><script type="math/tex;mode=display">PM\left( \hat{u}_{1}^{2}=11 \right)=PM\left( { { {\hat{u}}}_{1}}=1 \right)\text{=}+\infty</script><p>截止目前的扩展路径如图5所示。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170315/222254421.jpg" title="图 5 SCL译码算法在第2层的扩展"></p><h3 id="剪枝"><a href="#剪枝" class="headerlink" title="剪枝"></a>剪枝</h3><p><br>将已经计算出的$2L$路径按照PM值从小到大排序，对这$2L$条路径进行剪枝操作：保留$L$条PM值最小的路径，并且删掉其余路径。如图6所示，被保留的路径为红色，被剪枝的路径均已变成灰色。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170315/222502055.jpg" title="图 6 剪枝"></p><h2 id="搜索第三层"><a href="#搜索第三层" class="headerlink" title="搜索第三层"></a>搜索第三层</h2><p><br>分别计算 条路径在第3层对应的LLR。</p><h3 id="计算第3个比特相关的LLR"><a href="#计算第3个比特相关的LLR" class="headerlink" title="计算第3个比特相关的LLR"></a>计算第3个比特相关的LLR</h3><h4 id="a-000"><a href="#a-000" class="headerlink" title="a. 000"></a>a. 000</h4><p><br>比特估计值$\hat{u}{}_{1}=0,\hat{u}{}_{2}=0$。</p><script type="math/tex;mode=display">L_{4}^{\left( 3 \right)}\left( y_{1}^{4},\hat{u}_{1}^{2} \right)=f\left( L_{2}^{\left( 2 \right)}\left( y_{1}^{2},\hat{u}{}_{1}\oplus { { {\hat{u}}}_{2}} \right),L_{2}^{\left( 2 \right)}\left( y_{3}^{4},{ { {\hat{u}}}_{2}} \right) \right)</script><p>其中，$L_{2}^{\left( 2 \right)}\left( y_{1}^{2},\hat{u}{}_{1}\oplus { { {\hat{u}}}_{2}} \right)$和$L_{2}^{\left( 2 \right)}\left( y_{3}^{4},{ { {\hat{u}}}_{2}} \right)$递归地计算为</p><script type="math/tex;mode=display">\begin{align}
  \nonumber & L_{2}^{\left( 2 \right)}\left( y_{1}^{2},\hat{u}{}_{1}\oplus { { {\hat{u}}}_{2}} \right)=g\left( L_{1}^{\left( 1 \right)}\left( { {y}_{1}} \right),L_{1}^{\left( 1 \right)}\left( { {y}_{2}} \right),\hat{u}{}_{1}\oplus { { {\hat{u}}}_{2}} \right)=g\left( 1.5,2,0 \right) \\ 
 \nonumber & ={ {\left( -1 \right)}^{0}}\times 1.5+2 \\ 
 \nonumber & =3.5 \\ 
\end{align}</script><script type="math/tex;mode=display">\begin{align}
  \nonumber & L_{2}^{\left( 2 \right)}\left( y_{3}^{4},{ { {\hat{u}}}_{2}} \right)=g\left( L_{1}^{\left( 1 \right)}\left( { {y}_{3}} \right),L_{1}^{\left( 1 \right)}\left( { {y}_{4}} \right),{ { {\hat{u}}}_{2}} \right)=g\left( -1,0.5,0 \right) \\ 
 \nonumber & ={ {\left( -1 \right)}^{0}}\times \left( -1 \right)+0.5 \\ 
 \nonumber & =-0.5 \\ 
\end{align}</script><p>从而，$L_{4}^{\left( 3 \right)}\left( y_{1}^{4},\hat{u}_{1}^{2} \right)=f\left( 3.5,-0.5 \right)=-0.47$。</p><p><strong>重新建立向量LLR</strong></p><script type="math/tex;mode=display">\mathbf{LLR}=\left[ -0.47 \right]</script><h4 id="b-001"><a href="#b-001" class="headerlink" title="b. 001"></a>b. 001</h4><p><br>同上，$L_{4}^{\left( 3 \right)}\left( y_{1}^{4},\hat{u}_{1}^{2} \right)=f\left( 3.5,-0.5 \right)=-0.47$。</p><p><strong>更新向量LLR</strong></p><script type="math/tex;mode=display">\mathbf{LLR}=\left[ \begin{matrix}
   -0.47 & -0.47  \\
\end{matrix} \right]</script><h4 id="c-010"><a href="#c-010" class="headerlink" title="c. 010"></a>c. 010</h4><p><br>比特估计值$\hat{u}{}_{1}=0,\hat{u}{}_{2}=1$。</p><script type="math/tex;mode=display">\begin{align}
  \nonumber & L_{2}^{\left( 2 \right)}\left( y_{1}^{2},\hat{u}{}_{1}\oplus { { {\hat{u}}}_{2}} \right)=g\left( L_{1}^{\left( 1 \right)}\left( { {y}_{1}} \right),L_{1}^{\left( 1 \right)}\left( { {y}_{2}} \right),\hat{u}{}_{1}\oplus { { {\hat{u}}}_{2}} \right)=g\left( 1.5,2,1 \right) \\ 
 \nonumber & ={ {\left( -1 \right)}^{1}}\times 1.5+2 \\ 
 \nonumber & =0.5 \\ 
\end{align}</script><script type="math/tex;mode=display">\begin{align}
  \nonumber & L_{2}^{\left( 2 \right)}\left( y_{3}^{4},{ { {\hat{u}}}_{2}} \right)=g\left( L_{1}^{\left( 1 \right)}\left( { {y}_{3}} \right),L_{1}^{\left( 1 \right)}\left( { {y}_{4}} \right),{ { {\hat{u}}}_{2}} \right)=g\left( -1,0.5,1 \right) \\ 
 \nonumber & ={ {\left( -1 \right)}^{1}}\times \left( -1 \right)+0.5 \\ 
 \nonumber & =1.5 \\ 
\end{align}</script><p>从而，$L_{4}^{\left( 3 \right)}\left( y_{1}^{4},\hat{u}_{1}^{2} \right)=f\left( 0.5,1.5 \right)=0.31$。</p><p><strong>更新向量LLR</strong></p><script type="math/tex;mode=display">\mathbf{LLR}=\left[ \begin{matrix}
   \begin{matrix}
   -0.47 & -0.47  \\
\end{matrix} & 0.31  \\
\end{matrix} \right]</script><h4 id="d-011"><a href="#d-011" class="headerlink" title="d. 011"></a>d. 011</h4><p>同上，$L_{4}^{\left( 3 \right)}\left( y_{1}^{4},\hat{u}_{1}^{2} \right)=f\left( 0.5,1.5 \right)=0.31$。</p><p><strong>更新向量LLR</strong></p><script type="math/tex;mode=display">\mathbf{LLR}=\left[ \begin{matrix}
   \begin{matrix}
   \begin{matrix}
   -0.47 & -0.47  \\
\end{matrix} & 0.31  \\
\end{matrix} & 0.31  \\
\end{matrix} \right]</script><h3 id="计算候选路径的度量值-2"><a href="#计算候选路径的度量值-2" class="headerlink" title="计算候选路径的度量值"></a>计算候选路径的度量值</h3><p><br>分别计算$2L$条路径的度量值。</p><h4 id="a-000-1"><a href="#a-000-1" class="headerlink" title="a. 000"></a>a. 000</h4><p><br>$L_{4}^{\left( 3 \right)}$取向量$\mathbf{LLR}$的<font color="#FF0000"> 第1元素</font> ，即$L_{4}^{\left( 3 \right)}=-0.47$；比特估计值${ {\hat{u}}_{3}}=0$。</p><p>$\delta \left( L_{4}^{\left( 3 \right)} \right)=\frac{1}{2}\left( 1-sign\left( -0.47 \right) \right)=1$。由于${ {u}_{3}}$为信息比特，且${ {\hat{u}}_{3}}\ne \delta \left( L_{4}^{\left( 3 \right)} \right)$，所以有</p><script type="math/tex;mode=display">PM\left( \hat{u}_{1}^{3}=000 \right)=PM\left( \hat{u}_{1}^{2}=00 \right)+\left| L_{4}^{\left( 3 \right)} \right|=0.11+0.47=0.58</script><h4 id="b-001-1"><a href="#b-001-1" class="headerlink" title="b. 001"></a>b. 001</h4><p><br>$L_{4}^{\left( 3 \right)}$取向量$\mathbf{LLR}$的<font color="#FF0000"> 第2元素</font> ，即$L_{4}^{\left( 3 \right)}=-0.47$；比特估计值${ {\hat{u}}_{3}}=1$。</p><p>$\delta \left( L_{4}^{\left( 3 \right)} \right)=\frac{1}{2}\left( 1-sign\left( -0.47 \right) \right)=1$。由于${ {u}_{3}}$为信息比特，且${ {\hat{u}}_{3}}=\delta \left( L_{4}^{\left( 3 \right)} \right)$，所以有</p><script type="math/tex;mode=display">PM\left( \hat{u}_{1}^{3}=001 \right)=PM\left( \hat{u}_{1}^{2}=00 \right)\text{=}0.11</script><p>截止目前的扩展路径如图7所示。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170315/223032922.jpg" title="图 7 SCL译码算法在第3层的扩展"></p><h4 id="c-010-1"><a href="#c-010-1" class="headerlink" title="c. 010"></a>c. 010</h4><p><br>$L_{4}^{\left( 3 \right)}$取向量$\mathbf{LLR}$的<font color="#FF0000"> 第3元素</font> ，即$L_{4}^{\left( 3 \right)}=0.31$；比特估计值${ {\hat{u}}_{3}}=0$。</p><p>$\delta \left( L_{4}^{\left( 3 \right)} \right)=\frac{1}{2}\left( 1-sign\left( 0.31 \right) \right)=0$。由于${ {u}_{3}}$为信息比特，且${ {\hat{u}}_{3}}=\delta \left( L_{4}^{\left( 3 \right)} \right)$，所以有</p><script type="math/tex;mode=display">PM\left( \hat{u}_{1}^{3}=010 \right)=PM\left( \hat{u}_{1}^{2}=01 \right)=0.94</script><h4 id="d-011-1"><a href="#d-011-1" class="headerlink" title="d. 011"></a>d. 011</h4><p><br>$L_{4}^{\left( 3 \right)}$取向量$\mathbf{LLR}$的<font color="#FF0000"> 第4元素</font> ，即$L_{4}^{\left( 3 \right)}=0.31$；比特估计值${ {\hat{u}}_{3}}=1$。</p><p>$\delta \left( L_{4}^{\left( 3 \right)} \right)=\frac{1}{2}\left( 1-sign\left( 0.31 \right) \right)=0$。由于${ {u}_{3}}$为信息比特，且${ {\hat{u}}_{3}}\ne \delta \left( L_{4}^{\left( 3 \right)} \right)$，所以有</p><script type="math/tex;mode=display">PM\left( \hat{u}_{1}^{3}=011 \right)=PM\left( \hat{u}_{1}^{2}=01 \right)+L_{4}^{\left( 3 \right)}=0.94+0.31=1.25</script><p>截止目前的扩展路径如图8所示。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170427/134154868.jpg" title="图 8 SCL译码算法在第3层的扩展"></p><h3 id="剪枝-1"><a href="#剪枝-1" class="headerlink" title="剪枝"></a>剪枝</h3><p><br>将已经计算出的$2L$路径按照PM值从小到大排序，对这$2L$条路径进行剪枝操作：保留$L$条PM值最小的路径，并且删掉其余路径。如图9所示，被保留的路径为红色，被剪枝的路径均已变成灰色。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170427/134331096.jpg" title="图 9 剪枝"></p><h2 id="搜索第四层"><a href="#搜索第四层" class="headerlink" title="搜索第四层"></a>搜索第四层</h2><h3 id="计算第4个比特相关的LLR"><a href="#计算第4个比特相关的LLR" class="headerlink" title="计算第4个比特相关的LLR"></a>计算第4个比特相关的LLR</h3><p><br>分别计算$2L$条路径在第4层对应的LLR。</p><h4 id="a-0000"><a href="#a-0000" class="headerlink" title="a. 0000"></a>a. 0000</h4><p><br>比特估计值$\hat{u}{}_{1}=0,\hat{u}{}_{2}=0,\hat{u}{}_{3}=0$。</p><script type="math/tex;mode=display">\begin{align}
  \nonumber & L_{4}^{\left( 4 \right)}\left( y_{1}^{4},\hat{u}_{1}^{3} \right)=g\left( L_{2}^{\left( 2 \right)}\left( y_{1}^{2},{ { {\hat{u}}}_{1}}\oplus { { {\hat{u}}}_{2}} \right),L_{2}^{\left( 2 \right)}\left( y_{3}^{4},{ { {\hat{u}}}_{2}} \right),{ { {\hat{u}}}_{3}} \right)=g\left( 3.5,-0.5,0 \right) \\ 
 \nonumber & ={ {\left( -1 \right)}^{0}}\times 3.5+\left( -0.5 \right) \\ 
 \nonumber & =3 \\ 
\end{align}</script><p><strong>重新建立向量LLR</strong></p><script type="math/tex;mode=display">\mathbf{LLR}=\left[ 3 \right]</script><h4 id="b-0001"><a href="#b-0001" class="headerlink" title="b. 0001"></a>b. 0001</h4><p><br>同上，$L_{4}^{\left( 4 \right)}\left( y_{1}^{4},\hat{u}_{1}^{3} \right)=3$。</p><p><strong>更新向量LLR</strong></p><script type="math/tex;mode=display">\mathbf{LLR}=\left[ \begin{matrix}
   3 & 3  \\
\end{matrix} \right]</script><h4 id="c-0010"><a href="#c-0010" class="headerlink" title="c. 0010"></a>c. 0010</h4><p><br>比特估计值$\hat{u}{}_{1}=0,\hat{u}{}_{2}=0,\hat{u}{}_{3}=1$。</p><script type="math/tex;mode=display">\begin{align}
 \nonumber & L_{4}^{\left( 4 \right)}\left( y_{1}^{4},u_{1}^{3} \right)=g\left( L_{2}^{\left( 2 \right)}\left( y_{1}^{2},{ {u}_{1}}\oplus { {u}_{2}} \right),L_{2}^{\left( 2 \right)}\left( y_{3}^{4},{ {u}_{2}} \right),{ {u}_{3}} \right)=g\left( 3.5,-0.5,1 \right) \\ 
\nonumber & ={ {\left( -1 \right)}^{1}}\times 3.5+\left( -0.5 \right) \\ 
\nonumber & =-4 \\ 
\end{align}</script><p><strong>更新向量LLR</strong></p><script type="math/tex;mode=display">\mathbf{LLR}=\left[ \begin{matrix}
   3 & 3 & -4  \\
\end{matrix} \right]</script><h4 id="d-0011"><a href="#d-0011" class="headerlink" title="d. 0011"></a>d. 0011</h4><p><br>同上，$L_{4}^{\left( 4 \right)}\left( y_{1}^{4},\hat{u}_{1}^{3} \right)=-4$。</p><p><strong>更新向量LLR</strong></p><script type="math/tex;mode=display">\mathbf{LLR}=\left[ \begin{matrix}
   \begin{matrix}
   3 & 3 & -4  \\
\end{matrix} & -4  \\
\end{matrix} \right]</script><h3 id="计算候选路径的度量值-3"><a href="#计算候选路径的度量值-3" class="headerlink" title="计算候选路径的度量值"></a>计算候选路径的度量值</h3><p><br>终于到最后一层了，继续计算$2L$个路径的度量值。</p><h4 id="a-0000-1"><a href="#a-0000-1" class="headerlink" title="a. 0000"></a>a. 0000</h4><p><br>$L_{4}^{\left( 4 \right)}$取向量$\mathbf{LLR}$的<font color="#FF0000"> 第1元素</font> ，即$L_{4}^{\left( 4 \right)}=3$；比特估计值${ {\hat{u}}_{4}}=0$。</p><p>$\delta \left( L_{4}^{\left( 4 \right)} \right)=\frac{1}{2}\left( 1-sign\left( 3 \right) \right)=0$。由于${ {u}_{4}}$为信息比特，且${ {\hat{u}}_{4}}=\delta \left( L_{4}^{\left( 4 \right)} \right)$，所以有</p><script type="math/tex;mode=display">PM\left( \hat{u}_{1}^{4}=0000 \right)=PM\left( \hat{u}_{1}^{3}=000 \right)=0.58</script><h4 id="b-0001-1"><a href="#b-0001-1" class="headerlink" title="b. 0001"></a>b. 0001</h4><p><br>$L_{4}^{\left( 4 \right)}$取向量$\mathbf{LLR}$的<font color="#FF0000"> 第2元素</font> ，即$L_{4}^{\left( 4 \right)}=3$；比特估计值${ {\hat{u}}_{4}}=1$。</p><p>$\delta \left( L_{4}^{\left( 4 \right)} \right)=\frac{1}{2}\left( 1-sign\left( 3 \right) \right)=0$。由于${ {u}_{4}}$为信息比特，且${ {\hat{u}}_{4}}\ne \delta \left( L_{4}^{\left( 4 \right)} \right)$，所以有</p><script type="math/tex;mode=display">PM\left( \hat{u}_{1}^{4}=0001 \right)=PM\left( \hat{u}_{1}^{3}=000 \right)+L_{4}^{\left( 4 \right)}=0.58+3=3.58</script><p>截止目前的扩展路径如图10所示。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170427/135823406.jpg" title="图 10 SCL译码算法在4层的扩展"></p><h4 id="c-0010-1"><a href="#c-0010-1" class="headerlink" title="c. 0010"></a>c. 0010</h4><p><br>$L_{4}^{\left( 4 \right)}$取向量$\mathbf{LLR}$的<font color="#FF0000"> 第3元素</font> ，即$L_{4}^{\left( 4 \right)}=-4$；比特估计值${ {\hat{u}}_{4}}=0$。</p><p>$\delta \left( L_{4}^{\left( 4 \right)} \right)=\frac{1}{2}\left( 1-sign\left( -4 \right) \right)=1$。由于${ {u}_{4}}$为信息比特，且${ {\hat{u}}_{4}}\ne \delta \left( L_{4}^{\left( 4 \right)} \right)$，所以有</p><script type="math/tex;mode=display">PM\left( \hat{u}_{1}^{4}=0010 \right)=PM\left( \hat{u}_{1}^{3}=001 \right)+\left| L_{4}^{\left( 4 \right)} \right|=0.11+4=4.\text{11}</script><h4 id="d-0011-1"><a href="#d-0011-1" class="headerlink" title="d. 0011"></a>d. 0011</h4><p><br>$L_{4}^{\left( 4 \right)}$取向量$\mathbf{LLR}$的<font color="#FF0000"> 第4元素</font> ，即$L_{4}^{\left( 4 \right)}=-4$；比特估计值${ {\hat{u}}_{4}}=1$。</p><p>$\delta \left( L_{4}^{\left( 4 \right)} \right)=\frac{1}{2}\left( 1-sign\left( -4 \right) \right)=1$。由于${ {u}_{4}}$为信息比特，且${ {\hat{u}}_{4}}=\delta \left( L_{4}^{\left( 4 \right)} \right)$，所以有</p><script type="math/tex;mode=display">PM\left( \hat{u}_{1}^{4}=0011 \right)=PM\left( \hat{u}_{1}^{3}=001 \right)=0.11</script><p>截止目前的扩展路径如图11所示。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170427/140245285.jpg" title="图 11 SCL译码算法在4层的扩展"></p><h3 id="剪枝-2"><a href="#剪枝-2" class="headerlink" title="剪枝"></a>剪枝</h3><p><br>到了最后一层，选取PM最小的路径作为唯一路径，即为译码输出结果：$\hat{u}_{1}^{4}=\left( \begin{matrix}<br>0 &amp; 0 &amp; 1 &amp; 1 \\<br>\end{matrix} \right)$。如图12所示，只保留这一条路径，删除其余路径。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170427/140423071.jpg" title="图 12 SCL译码算法输出结果"></p><p>注意，此时的$\hat{u}_{1}^{4}=\left( \begin{matrix}<br>0 &amp; 0 &amp; 1 &amp; 1 \\<br>\end{matrix} \right)$并不是按正常顺序排列的译码结果。别忘了极化码编码时是经过比特反转的，$\left( \begin{matrix}<br>0 &amp; 0 &amp; 1 &amp; 1 \\<br>\end{matrix} \right)$对应的比特位置是$\left( \begin{matrix}<br>1 &amp; 3 &amp; 2 &amp; 4 \\<br>\end{matrix} \right)$。所以再比特反转一次，得到最终的译码比特$\left( \begin{matrix}<br>0 &amp; 1 &amp; 0 &amp; 1 \\<br>\end{matrix} \right)$，其中第2、4位发生了译码错误。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p><br>SC译码算法是深度优先的，要的是从根节点快速到达叶子节点。而SCL译码算法是广度优先的，先扩展，再剪枝，最终到达叶子节点。SCL译码算法的PM机制就像“马太效应”，越是错误的路径越要施加惩罚，越是正确的路径越可以直接继承父节点以便保证自己具有最小的PM。对于信息比特且${ {\hat{u}}_{i}}\left[ l \right]$与$\delta \left( L_{N}^{\left( i \right)}\left[ l \right] \right)$相等的情况，该比特直接继承父节点的PM；对于信息比特且${ {\hat{u}}_{i}}\left[ l \right]$与$\delta \left( L_{N}^{\left( i \right)}\left[ l \right] \right)$不相等的情况则次之，施加一个惩罚因子，该惩罚因子的大小就是LLR的模值；对于冻结比特而且还取值错误的情况是最坏的，施加的惩罚因子是无穷大。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><br>[1] Tal I, Vardy A. List Decoding of Polar Codes[J]. Information Theory IEEE Transactions on, 2012, 61(5):2213-2226.<br>[2] Balatsoukas-Stimming A, Parizi M B, Burg A. LLR-Based Successive Cancellation List Decoding of Polar Codes[J]. IEEE Transactions on Signal Processing, 2015, 63(19):5165-5179.<br>[3] 陈凯. 极化编码理论与实用方案研究[D]. 北京邮电大学, 2014.</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --&gt;&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;&lt;br&gt;Polar Code在码长趋于无穷时，信道极化才越完全。但在有限码长下，由于信道极化并不完全，依然会存在一些信息比特无法被正确译码。当前面$i-1$个信息比特的译码中发生错误之后，由于SC译码器在对后面的信息比特译码时需要用到之前的信息比特的估计值，这就会导致较为严重的错误传递。SC译码算法是一种贪婪算法，对码树的每一层仅仅搜索到最优路径就进行下一层，所以无法对错误进行修改。SCL译码算法就是对SC算法的改进。但在SCL之前，先来看看SC译码算法的码树表示。&lt;/p&gt;
    
    </summary>
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/categories/Polar-Code/"/>
    
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/tags/Polar-Code/"/>
    
  </entry>
  
  <entry>
    <title>Polar Code（6）SC译码算法</title>
    <link href="https://marshallcomm.github.io/2017/03/13/polar-code-6-sc-decoder/"/>
    <id>https://marshallcomm.github.io/2017/03/13/polar-code-6-sc-decoder/</id>
    <published>2017-03-13T14:23:42.000Z</published>
    <updated>2017-08-04T09:03:13.069Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><br>Arikan在文献[1]中给出了Polar Code译码算法，即串行抵消（Successive Cancellation，SL）译码算法。由Polar Code编码原理可知，极化码的构造就是一个极化信道的选择问题，而极化信道的选择实际上是按照最优化SC译码性能为标准的。根据极化信道转移概率函数式，各个极化信道并不是相互独立的，而是具有确定的依赖关系的：信道序号大的极化信道依赖于所有比其序号小的极化信道。基于极化信道之间的这一依赖关系，SC译码算法对各个比特进行译码判决时，需要假设之前步骤的译码得到的结果都是正确的。并且正是在这种译码算法下，极化码被证明了是信道容量可达的。因此对极化码而言，最合适的译码算法应当是基于SC译码的，只有这类译码算法才能充分利用极化码的结构，并且同时保证在码长足够长时容量可达。</p><a id="more"></a><h1 id="SC译码算法"><a href="#SC译码算法" class="headerlink" title="SC译码算法"></a>SC译码算法</h1><p><br>在进行译码时，从式（1）的转移概率可以看出，序号$i$极化信道$W_{N}^{\left( i \right)}$的输出包括信道接收信号$y_{1}^{N}$以及前$i-1$个极化信道的输入$u_{1}^{i-1}$两个部分。</p><script type="math/tex;mode=display">\begin{align}
W_{N}^{\left( i \right)}\left( y_{1}^{N},u_{1}^{i-1}|{ {u}_{i}} \right)\triangleq \sum\limits_{u_{i+1}^{N}\in { {X}^{N-i}}}{\frac{1}{ { {2}^{N-1}}}{ {W}_{N}}\left( y_{1}^{N}|u_{1}^{N} \right)}
\end{align}</script><p>因此，对于$i\in \left\{ 1,2,…,N \right\}$，比特${ {u}_{i}}$的估计值${ {\hat{u}}_{i}}$可以根据接收信号$y_{1}^{N}$和部分估计序列$u_{1}^{i-1}$通过计算当${ {\hat{u}}_{i}}=0$或${ {\hat{u}}_{i}}=1$时$W_{N}^{\left( i \right)}$的转移概率进行逐个地判断。这种译码算法称为串行抵消（SC）译码算法：对信道序号$i$从1到N取值，各个比特的估计值根据以下公式得到：</p><script type="math/tex;mode=display">\begin{align}
{ {\hat{u}}_{i}}=\left\{ \begin{matrix}
   { {h}_{i}}\left( y_{1}^{N},\hat{u}_{1}^{i-1} \right),\ \ if\ i\in A  \\
   { {u}_{i}},\ \ if\ i\in { {A}^{c}}  \\
\end{matrix} \right.
\end{align}</script><p>其中，当$i\in { {A}^{c}}$时，表明该比特为冻结比特，即收发端事先约定的比特，因此直接判决为${ {\hat{u}}_{i}}={ {u}_{i}}$；当$i\in A$时，表明该比特为承载信息的信息比特，判决函数为</p><script type="math/tex;mode=display">\begin{align}
{ {h}_{i}}\left( y_{1}^{N},\hat{u}_{1}^{i-1} \right)=\left\{ \begin{matrix}
   0,\ \ if\ L_{N}^{\left( i \right)}\left( y_{1}^{N},\hat{u}_{1}^{i-1} \right)\ge 0  \\
   1,\ \ if\ L_{N}^{\left( i \right)}\left( y_{1}^{N},\hat{u}_{1}^{i-1} \right)<0\   \\
\end{matrix} \right.
\end{align}</script><p>定义对数似然比（Log-Likelihood Ratio，LLR）为</p><script type="math/tex;mode=display">\begin{align}
L_{N}^{\left( i \right)}\left( y_{1}^{N},\hat{u}_{1}^{i-1} \right)\triangleq \ln \left( \frac{W_{N}^{\left( i \right)}\left( y_{1}^{N},\hat{u}_{1}^{i-1}|0 \right)}{W_{N}^{\left( i \right)}\left( y_{1}^{N},\hat{u}_{1}^{i-1}|1 \right)} \right)
\end{align}</script><p>LLR的计算可以通过递归完成。现定义函数$f$和$g$如下：</p><script type="math/tex;mode=display">\begin{align}
f\left( a,b \right)=\ln \left( \frac{1+{ {e}^{a+b}}}{ { {e}^{a}}+{ {e}^{b}}} \right)
\end{align}</script><script type="math/tex;mode=display">\begin{align}
g\left( a,b,{ {u}_{s}} \right)={ {\left( -1 \right)}^{ { {u}_{s}}}}a+b
\end{align}</script><p>其中，$a,b\in R,{ {u}_{s}}\in \left\{ 0,1 \right\}$。LLR的递归运算借助函数$f$和$g$表示如下：</p><script type="math/tex;mode=display">\begin{align}
L_{N}^{\left( 2i-1 \right)}\left( y_{1}^{N},\hat{u}_{1}^{2i-2} \right)=f\left( L_{N/2}^{\left( i \right)}\left( y_{1}^{ {N}/{2}\;},\hat{u}_{1,o}^{2i-2}\oplus \hat{u}_{1,e}^{2i-2} \right),L_{N/2}^{\left( i \right)}\left( y_{ {N}/{2}\;+1}^{N},\hat{u}_{1,e}^{2i-2} \right) \right)
\end{align}</script><script type="math/tex;mode=display">\begin{align}
L_{N}^{\left( 2i \right)}\left( y_{1}^{N},\hat{u}_{1}^{2i-1} \right)=g\left( L_{N/2}^{\left( i \right)}\left( y_{1}^{ {N}/{2}\;},\hat{u}_{1,o}^{2i-2}\oplus \hat{u}_{1,e}^{2i-2} \right),L_{N/2}^{\left( i \right)}\left( y_{ {N}/{2}\;+1}^{N},\hat{u}_{1,e}^{2i-2} \right),{ { {\hat{u}}}_{2i-1}} \right)
\end{align}</script><p>递归的终止条件为当$N=1$时，即到达了信道$W$端，此时$L_{1}^{\left( 1 \right)}\left( { {y}_{j}} \right)=\ln \frac{W\left( { {y}_{j}}|0 \right)}{W\left( { {y}_{j}}|1 \right)}$，可以根据信道$W$的转移概率和接收符号值直接计算出结果。</p><p>定义事件“SC译码算法得到的译码码块错误”为$E=\bigcup\nolimits_{i=1}^{N}{ { {B}_{i}}}$，其中事件</p><script type="math/tex;mode=display">\begin{align}
{ {B}_{i}}=\left\{ u_{1}^{N},y_{1}^{N}:u_{1}^{i-1}=\hat{u}_{1}^{i-1},W_{N}^{\left( i \right)}\left( y_{1}^{N},u_{1}^{i-1}|{ {u}_{i}} \right)<W_{N}^{\left( i \right)}\left( y_{1}^{N},u_{1}^{i-1}|{ {u}_{i}}\oplus 1 \right) \right\}
\end{align}</script><p>表示“SC译码过程中第一个错误判决发生在第$i$个比特”。由于${ {B}_{i}}\subset { {A}_{i}}$（事件${ {A}_{i}}$的定义参看<a href="https://marshallcomm.github.io/2017/03/07/polar-code-4-encoding-chan-rel-est/">《Polar Code（4）编码之极化信道可靠性估计》</a>前言），因此有$E\subset \sum\limits_{i\in A}{P\left( { {A}_{i}} \right)}$，于是</p><script type="math/tex;mode=display">\begin{align}
P\left( E \right)\le \sum\nolimits_{i\in A}{P\left( { {A}_{i}} \right)}
\end{align}</script><p>其中$P\left( { {A}_{i}} \right)$的值可根据前文所述的计算巴氏参数、密度进化或高斯近似方法得到。因此，通过式（6）可以得到极化码在SC译码下的误块率（BLER）性能上界。</p><h1 id="SC译码示例"><a href="#SC译码示例" class="headerlink" title="SC译码示例"></a>SC译码示例</h1><p><br>现在以码长$N=4$，消息比特数为$K=3$的极化码为例，对SC译码进行说明。在图1中，${ {u}_{1}}$为冻结比特并设定为零值，而消息比特也假设为全零，最右端的$L_{1}^{\left( 1 \right)}\left( { {y}_{j}} \right)$表示接收自信道的对数似然比。其他节点表示中间估计结果以及中间译码结果。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170314/134726685.jpg" title="图 1 极化码的SC译码，初始状态"></p><p>需要说明的是，编码过程中计算转移概率是从图的左边逐级向右边递归。而在译码过程中，计算信道的LLR要从右边逐级向左递归。</p><p>SC译码算法将首先计算${ {u}_{1}}$的对数似然比$L_{4}^{\left( 1 \right)}\left( y_{1}^{4} \right)$。根据式（5）和式（7），如图2所示，首先计算出$L_{2}^{\left( 1 \right)}\left( y_{1}^{2} \right)$和$L_{2}^{\left( 1 \right)}\left( y_{3}^{4} \right)$的值，其中</p><script type="math/tex;mode=display">\begin{align}
L_{2}^{\left( 1 \right)}\left( y_{1}^{2} \right)=f\left( L_{1}^{\left( 1 \right)}\left( { {y}_{1}} \right),L_{1}^{\left( 1 \right)}\left( { {y}_{2}} \right) \right)\text{=}\ln \left( \frac{1+{ {e}^{1.5+2}}}{ { {e}^{1.5}}+{ {e}^{2}}} \right)=1.06
\end{align}</script><script type="math/tex;mode=display">\begin{align}
L_{2}^{\left( 1 \right)}\left( y_{3}^{4} \right)=f\left( L_{1}^{\left( 1 \right)}\left( { {y}_{3}} \right),L_{1}^{\left( 1 \right)}\left( { {y}_{4}} \right) \right)\text{=}\ln \left( \frac{1+{ {e}^{-1+0.5}}}{ { {e}^{-1}}+{ {e}^{0.5}}} \right)=-0.23
\end{align}</script><p>接着计算出$L_{4}^{\left( 1 \right)}\left( y_{1}^{4} \right)$：</p><script type="math/tex;mode=display">\begin{align}
L_{4}^{\left( 1 \right)}\left( y_{1}^{4} \right)=f\left( L_{2}^{\left( 1 \right)}\left( y_{1}^{2} \right),L_{2}^{\left( 1 \right)}\left( y_{3}^{4} \right) \right)=\ln \left( \frac{1+{ {e}^{1.06-0.23}}}{ { {e}^{1.06}}+{ {e}^{-0.23}}} \right)=-0.11
\end{align}</script><p>虽然$L_{4}^{\left( 1 \right)}\left( y_{1}^{4} \right)&lt;0$，但由于${ {u}_{1}}$是冻结比特，我们依然将${ {u}_{1}}$判决为${ {\hat{u}}_{1}}=0$。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170314/134751778.jpg" title="图 2 极化码的SC译码，对${ {u}_{1}}$译码"></p><p>接着对${ {u}_{2}}$进行译码，如图3所示，根据式（6）和式（8）可得</p><script type="math/tex;mode=display">\begin{align}
L_{4}^{\left( 2 \right)}\left( y_{1}^{4},{ { {\hat{u}}}_{1}} \right)={ {\left( -1 \right)}^{ { { {\hat{u}}}_{1}}}}L_{2}^{\left( 1 \right)}\left( y_{1}^{2} \right)+L_{2}^{\left( 1 \right)}\left( y_{3}^{4} \right)={ {\left( -1 \right)}^{0}}\times 1.06+\left( -0.23 \right)=0.83
\end{align}</script><p>由于${ {u}_{2}}$是消息比特且$L_{4}^{\left( 2 \right)}\left( y_{1}^{4},{ { {\hat{u}}}_{1}} \right)&gt;0$，因此判决为${ {\hat{u}}_{2}}=0$，此处为正确译码。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170314/134810378.jpg" title="图 3 极化码的SC译码，对${ {u}_{2}}$译码"></p><p>接着对${ {u}_{3}}$进行译码，如图4所示，根据式（5）和式（7）可得</p><script type="math/tex;mode=display">\begin{align}
L_{4}^{\left( 3 \right)}\left( y_{1}^{4},\hat{u}_{1}^{2} \right)=f\left( L_{2}^{\left( 2 \right)}\left( y_{1}^{2},{ { {\hat{u}}}_{1}}\oplus { { {\hat{u}}}_{2}} \right),L_{2}^{\left( 2 \right)}\left( y_{3}^{4},{ { {\hat{u}}}_{2}} \right) \right)
\end{align}</script><p>这里需要先求$L_{2}^{\left( 2 \right)}\left( y_{1}^{2},{ { {\hat{u}}}_{1}}\oplus { { {\hat{u}}}_{2}} \right)$，根据式（6）和式（8）可得</p><script type="math/tex;mode=display">\begin{align}
L_{2}^{\left( 2 \right)}\left( y_{1}^{2},{ { {\hat{u}}}_{1}}\oplus { { {\hat{u}}}_{2}} \right)={ {\left( -1 \right)}^{ { { {\hat{u}}}_{1}}\oplus { { {\hat{u}}}_{2}}}}L_{1}^{\left( 1 \right)}\left( { {y}_{1}} \right)+L_{1}^{\left( 1 \right)}\left( { {y}_{2}} \right)={ {\left( -1 \right)}^{0}}\times 1.5+2=3.5
\end{align}</script><p>再求$L_{2}^{\left( 2 \right)}\left( y_{3}^{4},{ { {\hat{u}}}_{2}} \right)$，根据根据式（6）和式（8）可得</p><script type="math/tex;mode=display">\begin{align}
L_{2}^{\left( 2 \right)}\left( y_{3}^{4},{ { {\hat{u}}}_{2}} \right)\text{=}{ {\left( -1 \right)}^{ { { {\hat{u}}}_{2}}}}L_{1}^{\left( 1 \right)}\left( { {y}_{3}} \right)+L_{1}^{\left( 1 \right)}\left( { {y}_{4}} \right)={ {\left( -1 \right)}^{0}}\times \left( -1 \right)+0.5=-0.5
\end{align}</script><p>把式（16）和式（17）带入到式（15）得到</p><script type="math/tex;mode=display">\begin{align}
L_{4}^{\left( 3 \right)}\left( y_{1}^{4},\hat{u}_{1}^{2} \right)=f\left( 3.5,-0.5 \right)\text{=}\ln \left( \frac{1+{ {e}^{3.5-0.5}}}{ { {e}^{3.5}}+{ {e}^{-0.5}}} \right)=-0.47
\end{align}</script><p>由于$L_{4}^{\left( 3 \right)}\left( y_{1}^{4},\hat{u}_{1}^{2} \right)&lt;0$，因此判决${ {\hat{u}}_{3}}=1$，此处发生译码错误。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170314/134828384.jpg" title="图 4 极化码的SC译码，对${ {u}_{3}}$译码"></p><p>最后对${ {u}_{4}}$进行译码，如图5所示，根据式（6）和式（8）可得</p><script type="math/tex;mode=display">\begin{align}
  \nonumber & L_{4}^{\left( 4 \right)}\left( y_{1}^{4},\hat{u}_{1}^{3} \right)={ {\left( -1 \right)}^{ { { {\hat{u}}}_{3}}}}L_{2}^{\left( 2 \right)}\left( y_{1}^{2},{ { {\hat{u}}}_{1}}\oplus { { {\hat{u}}}_{2}} \right)+L_{2}^{\left( 2 \right)}\left( y_{3}^{4},{ { {\hat{u}}}_{2}} \right) \\ 
\nonumber & ={ {\left( -1 \right)}^{1}}\times 3.5+\left( -0.5 \right) \\ 
 & =-4 \\ 
\end{align}</script><p>由于$L_{4}^{\left( 4 \right)}\left( y_{1}^{4},\hat{u}_{1}^{3} \right)&lt;0$，因此判决${ {\hat{u}}_{4}}=1$，此处发生译码错误。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170314/134848915.jpg" title="图 5 极化码的SC译码，对${ {u}_{4}}$译码"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p><br>SC译码算法以LLR为判决准则，对每一个比特进行硬判决，按比特序号从小到大的顺序依次判决译码。当码长趋近于无穷时，由于各个分裂信道接近完全极化（其信道容量或者为0或者为1），毎个消息比特都会获得正确的译码结果，可以在理论上使得极化码达到信道的对称容量$I\left( W \right)$。而且SC译码器的复杂度仅为$O\left( N\log N \right)$和码长呈近似线性的关系。然而，在有限码长下，由于信道极化并不完全，依然会存在一些消息比特无法被正确译码。当前面$i-1$个消息比特的译码中发生错误之后，由于SC译码器在对后面的消息比特译码时需要用到之前的消息比特的估计值，这就会导致较为严重的错误传递。因此，对于有限码长的极化码，采用SC译码器往往不能达到理想的性能。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><br>[1] Arikan E. Channel Polarization: A Method for Constructing Capacity-Achieving Codes for Symmetric Binary-Input Memoryless Channels[J]. IEEE Transactions on Information Theory, 2008, 55(7):3051-3073.<br>[2] 张亮. 极化码的译码算法研究及其应用[D].浙江大学,2016.</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --&gt;&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;&lt;br&gt;Arikan在文献[1]中给出了Polar Code译码算法，即串行抵消（Successive Cancellation，SL）译码算法。由Polar Code编码原理可知，极化码的构造就是一个极化信道的选择问题，而极化信道的选择实际上是按照最优化SC译码性能为标准的。根据极化信道转移概率函数式，各个极化信道并不是相互独立的，而是具有确定的依赖关系的：信道序号大的极化信道依赖于所有比其序号小的极化信道。基于极化信道之间的这一依赖关系，SC译码算法对各个比特进行译码判决时，需要假设之前步骤的译码得到的结果都是正确的。并且正是在这种译码算法下，极化码被证明了是信道容量可达的。因此对极化码而言，最合适的译码算法应当是基于SC译码的，只有这类译码算法才能充分利用极化码的结构，并且同时保证在码长足够长时容量可达。&lt;/p&gt;
    
    </summary>
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/categories/Polar-Code/"/>
    
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/tags/Polar-Code/"/>
    
  </entry>
  
  <entry>
    <title>Polar Code（5）编码之信道转移概率</title>
    <link href="https://marshallcomm.github.io/2017/03/12/polar-code-5-encoding-chan-trans-prob/"/>
    <id>https://marshallcomm.github.io/2017/03/12/polar-code-5-encoding-chan-trans-prob/</id>
    <published>2017-03-12T13:31:26.000Z</published>
    <updated>2017-08-04T09:03:05.006Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><br>极化信道的可靠性估计是Polar Code编码的第一步，对于BEC信道，若计算巴氏参数，转移概率是绕不开的一步。此外对于译码判决来说，计算转移概率也是必须的。本文就尝试梳理一下极化信道的转移概率$W_{N}^{\left( i \right)}\left( y_{1}^{N},u_{1}^{i-1}|{ {u}_{i}} \right)$。</p><h1 id="离散信道的数学模型"><a href="#离散信道的数学模型" class="headerlink" title="离散信道的数学模型"></a>离散信道的数学模型</h1><p><br>信道是信号传输的媒介，是传送信息的通道。在信息论研究中不考虑信道的物理特性，而只是考虑它的概率特性。研究信道的目的主要是为了解决信息如何通过信道实现有效和可靠传输的问题。香农第二定理指出，信息传输速率小于信道容量是实现可靠传输的充分与必要的条件。信道容量是信息能够可靠传输的最大信息传输速率，是信道研究中的一个重要内容。信道容量定义为信道输入与输出平均互信息的最大值，它是信道本身固有特性的反映，仅与信道的<strong>转移概率</strong>有关，与信道的输入概率无关，但是信道输人概率必须与信道匹配才能达到容量。</p><a id="more"></a><p>设信道的输入符号集合$X$为随机变量集合，则输出符号集合$Y$也为随机变量集合。因为信道有随机噪声干扰，使$Y$在$X$给定条件下为随机变量，所以用条件概率或转移概率$P\left( y|x \right)$描述$Y$与$X$ 之间的关系，其中$x\in X,y\in Y$。信道模型如图1所示。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170312/214259492.jpg" title="图 1 离散信道模型"></p><p>一般的信道输入与输出均为随机矢量，设输入集合为${ {X}^{N}}={ {X}_{1}},{ {X}_{2}},…,{ {X}_{N}}$，集合中的矢量$\mathbf{x}={ {x}_{1}},{ {x}_{2}},…{ {x}_{N}},\mathbf{x}\in { {X}^{N}}$，输入单符号集为$A=\left\{ { {a}_{1}},{ {a}_{2}},…,{ {a}_{r}} \right\}$，其中${ {a}_{1}},{ {a}_{2}},…,{ {a}_{r}}$的概率分别是${ {p}_{1}},{ {p}_{2}},…{ {p}_{r}}$，且${ {x}_{n}}$取自$A$，$1\le n\le N$，输入矢量的符号集为${ {A}^{N}}$。输出集合为${ {Y}^{N}}={ {Y}_{1}},{ {Y}_{2}},…,{ {Y}_{N}}$，集合中的矢量为$\mathbf{y}={ {y}_{1}},{ {y}_{2}},…,{ {y}_{N}},\mathbf{y}\in { {Y}^{N}}$，输出单符号集为$B=\left\{ { {b}_{1}},{ {b}_{2}},…,{ {b}_{s}} \right\}$，其中${ {b}_{1}},{ {b}_{2}},…,{ {b}_{s}}$的概率分别是${ {q}_{1}},{ {q}_{2}},…,{ {q}_{s}}$，且${ {y}_{n}}$取自$B$，$1\le n\le N$，输出矢量的符号集为${ {B}^{N}}$。这种信道模型表示为$\left\{ { {X}^{N}},p\left( \mathbf{y}|\mathbf{x} \right),{ {Y}^{N}} \right\}$，其中$p\left( \mathbf{y}|\mathbf{x} \right)=p\left( { {y}_{1}},…,{ {y}_{N}}|{ {x}_{1}},…,{ {x}_{N}} \right)$。</p><h2 id="二进制离散无记忆信道"><a href="#二进制离散无记忆信道" class="headerlink" title="二进制离散无记忆信道"></a>二进制离散无记忆信道</h2><p><br>设信道的输入和输出分别是长为$N$的序列，若信道的转移概率满足</p><script type="math/tex;mode=display">p\left( \mathbf{y}|\mathbf{x} \right)=\prod\limits_{n=1}^{N}{p\left( { {y}_{n}}|{ {x}_{n}} \right)}</script><p>则称此信道为离散无记忆信道（DMC），其数学模型为：$\left\{ X,p\left( { {y}_{n}}|{ {x}_{n}} \right),Y \right\}$。若输入单符号集为$A=\left\{ { {a}_{1}},{ {a}_{2}} \right\}\text{=}\left\{ 0,1 \right\}$，则此信道为二进制离散无记忆信道（B-DMC）。</p><h3 id="二进制对称信道"><a href="#二进制对称信道" class="headerlink" title="二进制对称信道"></a>二进制对称信道</h3><p><br>二进制对称信道，简记为BSC（Binary Symmetric Channel），输入与输出符号集分别为$A=\left\{ 0,1 \right\}$，$B=\left\{ 0,1 \right\}$，信道转移概率满足${ {P}_{Y|X}}\left( 0|0 \right)={ {P}_{Y|X}}\left( 1|1 \right)=p$，${ {P}_{Y|X}}\left( 1|0 \right)={ {P}_{Y|X}}\left( 0|1 \right)=1-p$。BSC转移概率图如图2所示。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170312/215829213.jpg" title="图 2 二进制对称信道转移概率图"></p><h3 id="二进制删除信道"><a href="#二进制删除信道" class="headerlink" title="二进制删除信道"></a>二进制删除信道</h3><p><br>二进制删除信道，简记为BEC（Binary Erasure Channel），输入与输出符号集分别为$A=\left\{ 0,1 \right\}$，$B=\left\{ 0,2,1 \right\}$，信道转移概率满足${ {P}_{Y|X}}\left( 0|0 \right)={ {P}_{Y|X}}\left( 1|1 \right)=1-\varepsilon $，${ {P}_{Y|X}}\left( 2|0 \right)={ {P}_{Y|X}}\left( 2|1 \right)=\varepsilon $，$\varepsilon $称为错误率。BEC转移概率图如图3所示。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170312/220220784.jpg" title="图 3 二进制删除信道转移概率图"></p><h2 id="极化信道"><a href="#极化信道" class="headerlink" title="极化信道"></a>极化信道</h2><p><br>Arikan在研究极化信道和极化码时是基于B-DMC的。原始信道$W:X\to Y$如图4（a）所示，其转移概率为$W\left( y|u \right),u\in X,y\in Y$。将原始信道$W$的$N$个独立副本经过联合与分裂操作之后就形成了新的极化信道$W_{N}^{\left( i \right)}:X\to { {Y}^{N}}\times { {X}^{i-1}}$，如图4（b）所示，其转移概率为$W_{N}^{\left( i \right)}\left( y_{1}^{N},u_{1}^{i-1}|{ {u}_{i}} \right)$。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170312/220515878.jpg" title="图 4 原始信道与极化信道"></p><h1 id="极化信道转移概率"><a href="#极化信道转移概率" class="headerlink" title="极化信道转移概率"></a>极化信道转移概率</h1><p><br>对任何$n\ge 0,N={ {2}^{n}},1\le i\le {N}/{2}\;$，有递归式</p><script type="math/tex;mode=display">\begin{align}
  & W_{N}^{\left( 2i-1 \right)}\left( y_{1}^{N},u_{1}^{2i-2}|{ {u}_{2i-1}} \right)=\sum\limits_{ { {u}_{2i}}}{\frac{1}{2}W_{ {N}/{2}\;}^{\left( i \right)}\left( y_{1}^{ {N}/{2}\;},u_{1,o}^{2i-2}\oplus u_{1,e}^{2i-2}|{ {u}_{2i-1}}\oplus { {u}_{2i}} \right)} \\ 
 & \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \nonumber \cdot W_{ {N}/{2}\;}^{\left( i \right)}\left( y_{ {N}/{2}\;+1}^{N},u_{1,e}^{2i-2}|{ {u}_{2i}} \right) \\ 
\end{align}</script><script type="math/tex;mode=display">\begin{align}
  & W_{N}^{\left( 2i \right)}\left( y_{1}^{N},u_{1}^{2i-1}|{ {u}_{2i}} \right)=\frac{1}{2}W_{ {N}/{2}\;}^{\left( i \right)}\left( y_{1}^{ {N}/{2}\;},u_{1,o}^{2i-2}\oplus u_{1,e}^{2i-2}|{ {u}_{2i-1}}\oplus { {u}_{2i}} \right) \\ 
 & \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \nonumber \cdot W_{ {N}/{2}\;}^{\left( i \right)}\left( y_{ {N}/{2}\;+1}^{N},u_{1,e}^{2i-2}|{ {u}_{2i}} \right) \\ 
\end{align}</script><p>递归计算过程中对于任意$a_{i}^{j}$，只有$i\le j$的情况，如遇到$a_{i}^{j},i&gt;j$的情况则视为无效，并定义$W_{1}^{\left( 1 \right)}\triangleq { {W}_{1}}=W$，$y_{1}^{1}\triangleq { {y}_{1}}$，$u_{1}^{1}\triangleq { {u}_{1}}$。下面以$N=4$为例详细说明。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170312/224336662.jpg" title="图 5 极化信道${ {W}_{4}}$"></p><p><br>下面以BSC信道为例，计算各极化信道转移概率。</p><h2 id="W-1-left-1-right"><a href="#W-1-left-1-right" class="headerlink" title="$W_{1}^{\left( 1 \right)}$"></a>$W_{1}^{\left( 1 \right)}$</h2><p><br>当$N=1,i=1$时，利用式（1）计算信道$W_{1}^{\left( 1 \right)}\text{=}W$的转移概率：</p><script type="math/tex;mode=display">\begin{align}
W_{1}^{\left( 1 \right)}\left( y_{1}^{1},u_{1}^{0}|{ {u}_{1}} \right)=W\left( { {y}_{1}}|{ {u}_{1}} \right)=p
\end{align}</script><p>此时的信道即为如图4（a）所示的原始信道。类似的有$W\left( { {y}_{2}}|{ {u}_{2}} \right)=W\left( { {y}_{N}}|{ {u}_{N}} \right)=p$。</p><h2 id="W-2-left-1-right"><a href="#W-2-left-1-right" class="headerlink" title="$W_{2}^{\left( 1 \right)}$"></a>$W_{2}^{\left( 1 \right)}$</h2><p><br>当$N=2,i=1$时，利用式（1）计算信道$W_{2}^{\left( 1 \right)}$的转移概率：</p><script type="math/tex;mode=display">\begin{align}
  \nonumber W_{2}^{\left( 1 \right)}\left( y_{1}^{2},u_{1}^{0}|{ {u}_{1}} \right)=\sum\limits_{ { {u}_{2}}}{\frac{1}{2}}W_{1}^{\left( 1 \right)}\left( y_{1}^{1},u_{1,o}^{0}\oplus u_{1,e}^{0}|{ {u}_{1}}\oplus { {u}_{2}} \right)\cdot W_{1}^{\left( 1 \right)}\left( y_{2}^{2},u_{1,e}^{0}|{ {u}_{2}} \right) \\ 
  \downarrow  \\ 
  \nonumber W_{2}^{\left( 1 \right)}\left( y_{1}^{2}|{ {u}_{1}} \right)=\sum\limits_{ { {u}_{2}}}{\frac{1}{2}}W\left( { {y}_{1}}|{ {u}_{1}}\oplus { {u}_{2}} \right)\cdot W\left( { {y}_{2}}|{ {u}_{2}} \right) \\ 
\end{align}</script><p>此时的信道即为如图4（b）所示的第1个极化信道。考察对${ {u}_{1}}$的译码可知，根据运算关系有${ {u}_{1}}={ {y}_{1}}\oplus { {y}_{2}}$，当$\left\{ { {y}_{1}},{ {y}_{2}} \right\}$中有一个是错误符号时，${ {u}_{1}}$的值便无法获得，此时${ {u}_{1}}$译码失败，可以计算$W_{2}^{\left( 1 \right)}$的转移概率为</p><script type="math/tex;mode=display">\begin{align}
W_{2}^{\left( 1 \right)}\left( y_{1}^{2}|{ {u}_{1}} \right)=p\times p={ {p}^{2}}
\end{align}</script><p>两个原始信道$W$的副本经过信道极化构成极化信道${ {W}_{2}}$。如图5所示，${ {W}_{2}}$的一个分裂子信道${ {v}_{1}}$的转移概率即为$W_{2}^{\left( 1 \right)}$，${ {v}_{2}}$是${ {W}_{2}}$的另一个分裂子信道。下面求${ {v}_{2}}$的转移概率。</p><h2 id="W-2-left-2-right"><a href="#W-2-left-2-right" class="headerlink" title="$W_{2}^{\left( 2 \right)}$"></a>$W_{2}^{\left( 2 \right)}$</h2><p><br>当$N=2,i=1$时，利用式（2）计算信道$W_{2}^{\left( 2 \right)}$的转移概率：</p><script type="math/tex;mode=display">\begin{align}
  \nonumber W_{2}^{\left( 2 \right)}\left( y_{1}^{2},u_{1}^{1}|{ {u}_{2}} \right)=\frac{1}{2}W_{1}^{\left( 1 \right)}\left( y_{1}^{1},u_{1,o}^{0}\oplus u_{1,e}^{0}|{ {u}_{1}}\oplus { {u}_{2}} \right)\cdot W_{1}^{\left( 1 \right)}\left( y_{2}^{2},u_{1,e}^{0}|{ {u}_{2}} \right) \\ 
  \downarrow  \\ 
  \nonumber W_{2}^{\left( 2 \right)}\left( y_{1}^{2},{ {u}_{1}}|{ {u}_{2}} \right)=\frac{1}{2}W\left( { {y}_{1}}|{ {u}_{1}}\oplus { {u}_{2}} \right)\cdot W\left( { {y}_{2}}|{ {u}_{2}} \right) \\ 
\end{align}</script><p>此时的信道即为如图4（b）所示的第2个极化信道。考察对${ {u}_{2}}$的译码可知，根据运算关系有${ {u}_{2}}={ {y}_{1}}\oplus { {u}_{1}}$或${ {u}_{2}}={ {y}_{2}}$，只要这两个式子的任意一个提供了正确符号，那么${ {u}_{2}}$将必定被正确译码。即当${ {u}_{1}}$被正确译码时，只有$\left\{ { {y}_{1}},{ {y}_{2}} \right\}$全部是错误符号时，${ {u}_{2}}$才会译码失败。可以计算$W_{2}^{\left( 2 \right)}$的转移概率为</p><script type="math/tex;mode=display">\begin{align}
W_{2}^{\left( 2 \right)}\left( y_{1}^{2},{ {u}_{1}}|{ {u}_{2}} \right)=1-{ {\left( 1-p \right)}^{2}}
\end{align}</script><p>两个极化信道${ {W}_{2}}$的副本又进一步经过信道极化构成了极化信道${ {W}_{4}}$。${ {v}_{1}}$和${ {v}_{3}}$的转移概率相同，${ {v}_{2}}$和${ {v}_{4}}$的转移概率相同，如图6所示。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170314/082522769.jpg" title="图 6 极化信道${ {W}_{2}}$的转移概率"></p><h2 id="W-4-left-1-right"><a href="#W-4-left-1-right" class="headerlink" title="$W_{4}^{\left( 1 \right)}$"></a>$W_{4}^{\left( 1 \right)}$</h2><p><br>当$N=4,i=1$时，利用式（1）计算信道$W_{4}^{\left( 1 \right)}$的转移概率：</p><script type="math/tex;mode=display">\begin{align}
  \nonumber W_{4}^{\left( 1 \right)}\left( y_{1}^{4},u_{1}^{0}|{ {u}_{1}} \right)=\sum\limits_{ { {u}_{2}}}{\frac{1}{2}W_{2}^{\left( 1 \right)}\left( y_{1}^{2},u_{1,o}^{0}\oplus u_{1,e}^{0}|{ {u}_{1}}\oplus { {u}_{2}} \right)\cdot W_{2}^{\left( 1 \right)}\left( y_{3}^{4},u_{1,e}^{0}|{ {u}_{2}} \right)} \\ 
  \downarrow  \\ 
  \nonumber W_{4}^{\left( 1 \right)}\left( y_{1}^{4}|{ {u}_{1}} \right)=\sum\limits_{ { {u}_{2}}}{\frac{1}{2}W_{2}^{\left( 1 \right)}\left( y_{1}^{2}|{ {u}_{1}}\oplus { {u}_{2}} \right)\cdot W_{2}^{\left( 1 \right)}\left( y_{3}^{4}|{ {u}_{2}} \right)} \\ 
\end{align}</script><p>利用递归思想，将（4）式$W_{2}^{\left( 1 \right)}\left( y_{1}^{2}|{ {u}_{1}} \right)$的计算结果作为新的“原始信道”的转移概率，即根据$\left\{ \begin{matrix}<br>{ {y}_{1}}=v{}_{1}\oplus { {v}_{3}} \\<br>{ {y}_{2}}={ {v}_{3}} \\<br>\end{matrix} \right.$递归计算$W_{4}^{\left( 1 \right)}\left( y_{1}^{4}|{ {u}_{1}} \right)$的转移概率为${ {\left( { {p}^{2}} \right)}^{2}}$，如图7所示。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170314/082636188.jpg" title="图 7 $W_{4}^{\left( 1 \right)}\left( y_{1}^{4}|{ {u}_{1}} \right)$"></p><h2 id="W-4-left-2-right"><a href="#W-4-left-2-right" class="headerlink" title="$W_{4}^{\left( 2 \right)}$"></a>$W_{4}^{\left( 2 \right)}$</h2><p><br>当$N=4,i=1$时，利用式（2）计算信道$W_{4}^{\left( 2 \right)}$的转移概率：</p><script type="math/tex;mode=display">\begin{align}
  \nonumber & W_{4}^{\left( 2 \right)}\left( y_{1}^{4},{ {u}_{1}}|{ {u}_{2}} \right)=\frac{1}{2}W_{2}^{\left( 1 \right)}\left( y_{1}^{2}|{ {u}_{1}}\oplus { {u}_{2}} \right)\cdot W_{2}^{\left( 1 \right)}\left( y_{3}^{4}|{ {u}_{2}} \right) \\ 
 & =1-{ {\left( 1-{ {p}^{2}} \right)}^{2}} \\ 
\end{align}</script><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170314/082720011.jpg" title="图 8 $W_{4}^{\left( 2 \right)}\left( y_{1}^{4},{ {u}_{1}}|{ {u}_{2}} \right)$"></p><h2 id="W-4-left-3-right"><a href="#W-4-left-3-right" class="headerlink" title="$W_{4}^{\left( 3 \right)}$"></a>$W_{4}^{\left( 3 \right)}$</h2><p><br>当$N=4,i=2$时，利用式（1）计算信道$W_{4}^{\left( 3 \right)}$的转移概率：</p><script type="math/tex;mode=display">\begin{align}
  \nonumber & W_{4}^{\left( 3 \right)}\left( y_{1}^{4},u_{1}^{2}|{ {u}_{3}} \right)=\sum\limits_{ { {u}_{4}}}{\frac{1}{2}W_{2}^{\left( 2 \right)}\left( y_{1}^{2},{ {u}_{1}}\oplus { {u}_{2}}|{ {u}_{3}}\oplus { {u}_{4}} \right)\cdot W_{2}^{\left( 2 \right)}\left( y_{3}^{4},{ {u}_{2}}|{ {u}_{4}} \right)} \\ 
 & ={ {\left( 1-{ {\left( 1-p \right)}^{2}} \right)}^{2}} \\ 
\end{align}</script><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170314/082801240.jpg" title="图 9 $W_{4}^{\left( 3 \right)}\left( y_{1}^{4},u_{1}^{2}|{ {u}_{3}} \right)$"></p><h2 id="W-4-left-4-right"><a href="#W-4-left-4-right" class="headerlink" title="$W_{4}^{\left( 4 \right)}$"></a>$W_{4}^{\left( 4 \right)}$</h2><p><br>当$N=4,i=2$时，利用式（2）计算信道$W_{4}^{\left( 4 \right)}$的转移概率：</p><script type="math/tex;mode=display">\begin{align}
  \nonumber & W_{4}^{\left( 4 \right)}\left( y_{1}^{4},u_{1}^{3}|{ {u}_{4}} \right)=\frac{1}{2}W_{2}^{\left( 2 \right)}\left( y_{1}^{2},{ {u}_{1}}\oplus { {u}_{2}}|{ {u}_{3}}\oplus { {u}_{4}} \right)\cdot W_{2}^{\left( 2 \right)}\left( y_{3}^{4},{ {u}_{2}}|{ {u}_{4}} \right) \\ 
 & =1-{ {\left( { {\left( 1-p \right)}^{2}} \right)}^{2}} \\ 
\end{align}</script><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170314/082845515.jpg" title="图 10 $W_{4}^{\left( 4 \right)}\left( y_{1}^{4},u_{1}^{3}|{ {u}_{4}} \right)$"></p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p><br>经过以上运算得到了极化信道${ {W}_{4}}$的各个分裂子信道的转移概率：</p><script type="math/tex;mode=display">\begin{align}
\left\{ \begin{matrix}
   W_{4}^{\left( 1 \right)}\left( y_{1}^{4}|{ {u}_{1}} \right)={ {\left( { {p}^{2}} \right)}^{2}}  \\
   W_{4}^{\left( 2 \right)}\left( y_{1}^{4},{ {u}_{1}}|{ {u}_{2}} \right)=1-{ {\left( 1-{ {p}^{2}} \right)}^{2}}  \\
   W_{4}^{\left( 3 \right)}\left( y_{1}^{4},u_{1}^{2}|{ {u}_{3}} \right)={ {\left( 1-{ {\left( 1-p \right)}^{2}} \right)}^{2}}  \\
   W_{4}^{\left( 4 \right)}\left( y_{1}^{4},u_{1}^{3}|{ {u}_{4}} \right)=1-{ {\left( { {\left( 1-p \right)}^{2}} \right)}^{2}}  \\
\end{matrix} \right.
\end{align}</script><p>若信道为BSC，则${ {W}_{4}}$的各分裂子信道的转移概率即为式（12）。若信道为BEC，只需将$p$替换为$1-\varepsilon $，即</p><script type="math/tex;mode=display">\begin{align}
\left\{ \begin{matrix}
   W_{4}^{\left( 1 \right)}\left( y_{1}^{4}|{ {u}_{1}} \right)={ {\left( { {\left( 1-\varepsilon  \right)}^{2}} \right)}^{2}}  \\
   W_{4}^{\left( 2 \right)}\left( y_{1}^{4},{ {u}_{1}}|{ {u}_{2}} \right)=1-{ {\left( 1-{ {\left( 1-\varepsilon  \right)}^{2}} \right)}^{2}}  \\
   W_{4}^{\left( 3 \right)}\left( y_{1}^{4},u_{1}^{2}|{ {u}_{3}} \right)={ {\left( 1-{ {\varepsilon }^{2}} \right)}^{2}}  \\
   W_{4}^{\left( 4 \right)}\left( y_{1}^{4},u_{1}^{3}|{ {u}_{4}} \right)=1-{ {\left( { {\varepsilon }^{2}} \right)}^{2}}  \\
\end{matrix} \right.
\end{align}</script><h1 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h1><p><br>假设对于删除概率为$\varepsilon =0.5$的BEC，原始信道$W$的对称容量$I\left( W \right)=0.5$，利用式（13）可得各分裂信道转移概率</p><script type="math/tex;mode=display">\begin{align}
\left\{ \begin{matrix}
   W_{4}^{\left( 1 \right)}\left( y_{1}^{4}|{ {u}_{1}} \right)={ {\left( { {\left( 1-\varepsilon  \right)}^{2}} \right)}^{2}}=0.0625  \\
   W_{4}^{\left( 2 \right)}\left( y_{1}^{4},{ {u}_{1}}|{ {u}_{2}} \right)=1-{ {\left( 1-{ {\left( 1-\varepsilon  \right)}^{2}} \right)}^{2}}=0.4375  \\
   W_{4}^{\left( 3 \right)}\left( y_{1}^{4},u_{1}^{2}|{ {u}_{3}} \right)={ {\left( 1-{ {\varepsilon }^{2}} \right)}^{2}}=0.5625  \\
   W_{4}^{\left( 4 \right)}\left( y_{1}^{4},u_{1}^{3}|{ {u}_{4}} \right)=1-{ {\left( { {\varepsilon }^{2}} \right)}^{2}}=0.9375  \\
\end{matrix} \right.
\end{align}</script><p>进而求得各分裂信道的对称容量</p><script type="math/tex;mode=display">\begin{align}
\left\{ \begin{matrix}
   I\left( W_{4}^{\left( 1 \right)} \right)=0.0625  \\
   I\left( W_{4}^{\left( 2 \right)} \right)=\text{0}\text{.4375}  \\
   I\left( W_{4}^{\left( 3 \right)} \right)=\text{0}\text{.5625}  \\
   I\left( W_{4}^{\left( 4 \right)} \right)=\text{0}\text{.9375}  \\
\end{matrix} \right.
\end{align}</script><p>从式（15）可以看出原始信道$W$的4个独立副本经过信道极化以后，各分裂信道的容量呈现两极分化趋势。一部分子信道容量开始趋近于0，另一部分子信道容量开始趋近于1。并且信道总容量不变：$I\left( W_{4}^{\left( 1 \right)} \right)\text{+}I\left( W_{4}^{\left( 2 \right)} \right)\text{+}I\left( W_{4}^{\left( 3 \right)} \right)\text{+}I\left( W_{4}^{\left( 4 \right)} \right)\text{=}4\times I\left( W \right)$。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p><br>本文首先引入离散信道的数学模型，进而定义二进制对称信道和二进制删除信道的转移概率，并延伸出极化信道的转移概率。之后以$N=4$为例，推导了极化信道${ {W}_{4}}$各分裂子信道的转移概率。最后由各分裂信道的转移概率计算相应的对称容量，验证了信道极化现象。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><br>[1] 田宝玉. 信息论基础.第2版[M]. 人民邮电出版社, 2016.<br>[2] Arikan E. Channel Polarization: A Method for Constructing Capacity-Achieving Codes for Symmetric Binary-Input Memoryless Channels[J]. IEEE Transactions on Information Theory, 2008, 55(7):3051-3073.</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --&gt;&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;&lt;br&gt;极化信道的可靠性估计是Polar Code编码的第一步，对于BEC信道，若计算巴氏参数，转移概率是绕不开的一步。此外对于译码判决来说，计算转移概率也是必须的。本文就尝试梳理一下极化信道的转移概率$W_{N}^{\left( i \right)}\left( y_{1}^{N},u_{1}^{i-1}|{ {u}_{i}} \right)$。&lt;/p&gt;&lt;h1 id=&quot;离散信道的数学模型&quot;&gt;&lt;a href=&quot;#离散信道的数学模型&quot; class=&quot;headerlink&quot; title=&quot;离散信道的数学模型&quot;&gt;&lt;/a&gt;离散信道的数学模型&lt;/h1&gt;&lt;p&gt;&lt;br&gt;信道是信号传输的媒介，是传送信息的通道。在信息论研究中不考虑信道的物理特性，而只是考虑它的概率特性。研究信道的目的主要是为了解决信息如何通过信道实现有效和可靠传输的问题。香农第二定理指出，信息传输速率小于信道容量是实现可靠传输的充分与必要的条件。信道容量是信息能够可靠传输的最大信息传输速率，是信道研究中的一个重要内容。信道容量定义为信道输入与输出平均互信息的最大值，它是信道本身固有特性的反映，仅与信道的&lt;strong&gt;转移概率&lt;/strong&gt;有关，与信道的输入概率无关，但是信道输人概率必须与信道匹配才能达到容量。&lt;/p&gt;
    
    </summary>
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/categories/Polar-Code/"/>
    
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/tags/Polar-Code/"/>
    
  </entry>
  
  <entry>
    <title>Polar Code（4）编码之极化信道可靠性估计</title>
    <link href="https://marshallcomm.github.io/2017/03/07/polar-code-4-encoding-chan-rel-est/"/>
    <id>https://marshallcomm.github.io/2017/03/07/polar-code-4-encoding-chan-rel-est/</id>
    <published>2017-03-07T14:16:07.000Z</published>
    <updated>2017-08-04T09:02:57.268Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><br>由Arikan发明的Polar Code经典编码算法已在<a href="https://marshallcomm.github.io/2017/03/04/polar-code-2-encoding-principle/">《Polar Code（2）编码原理》</a>中阐明，<a href="https://marshallcomm.github.io/2017/03/05/polar-code-3-encoding-example/">《Polar Code（3）编码实例》</a>则是对前文的举例。在编码实例中，有两个前提假设：</p><ol><li>假设一个二进制删除信道（BEC）；</li><li>假设采用计算巴氏参数来评估各分裂子信道的可靠性。</li></ol><p>Arikan在讨论信道极化时，针对的是二进制离散无记忆信道（B-DMC），然而在构造极化码时需要计算的巴氏参数$Z\left( W \right)$的适用范围是二进制删除信道。BEC是B-DMC的子集。因此在Polar Code编码时只能回落的BEC来进行构造。</p><a id="more"></a><p>当信道不是BEC信道时，比如二元对称信道（BSC）或二进制高斯白噪声信道（BAWGNC），则超出了$Z\left( W \right)$的适用范围，各个分裂信道的$Z\left( W{}_{N}^{\left( i \right)} \right)$无法精确得到。为了更精确地估计信道极化中各分裂信道的可靠性，Mori等人提出了密度进化（Density Evolution，DE）的构造方法。该方法适用于所有类型的B-DMC。</p><p>定义错误概率：对信道$W$的$N$个独立时隙上进行信道极化以后，得到极化信道$W_{N}^{\left( i \right)}$，其中$i=1,2,…,N$。令事件${ {A}_{i}}$表示序号为$i$的极化信道$W_{N}^{\left( i \right)}$所承载的比特经过传输后接收发生错误，即</p><script type="math/tex;mode=display">{ {A}_{i}}=\left\{ u_{1}^{N},y_{1}^{N}:W_{N}^{\left( i \right)}\left( y_{1}^{N},u_{1}^{i-1}|{ {u}_{i}} \right)<W_{N}^{\left( i \right)}\left( y_{1}^{N},u_{1}^{i-1}|{ {u}_{i}}\oplus 1 \right) \right\}</script><p>则极化信道$W_{N}^{\left( i \right)}$的错误概率为$P\left( { {A}_{i}} \right)$。</p><h1 id="密度进化（DE）"><a href="#密度进化（DE）" class="headerlink" title="密度进化（DE）"></a>密度进化（DE）</h1><p><br>类似LDPC码等信道编码，信道极化也可以用Tanner图的结构来表示。下图给出了一个$N=8$的例子，图中圆圈表示变量节点，每个变量节点代码一个比特，同时也存储了该比特取值为0或1时的概率；而方框则表示校验节点，表示与之相连的各变量节点比特值的检验和为零。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170307/222559340.png" title="当N=8时，信道极化的Tanner图表示。图中加粗线条标记出了比特u4的译码树"></p><p>由于变量节点的比特值仅可能有0或1两种取值，因此，存储与变量节点的消息往往用对数似然比（LLR）值来表示。</p><script type="math/tex;mode=display">\begin{equation} 
L_{N}^{\left( i \right)}\left( y_{1}^{N},\hat{u}_{1}^{i-1} \right)=\ln \left( \frac{W_{N}^{\left( i \right)}\left( y_{1}^{N},\hat{u}_{1}^{i-1}|0 \right)}{W_{N}^{\left( i \right)}\left( y_{1}^{N},\hat{u}_{1}^{i-1}|1 \right)} \right) 
\end{equation}</script><p>根据<a href="https://marshallcomm.github.io/2017/03/04/polar-code-2-encoding-principle/">《Polar Code（2）编码原理》</a>中递归式$W_{N}^{\left( 2i-1 \right)}\left( y_{1}^{N},u_{1}^{2i-2}|{u_{2i-1}} \right)$与式$W_{N}^{\left( 2i \right)}\left( y_{1}^{N},u_{1}^{2i-1}|{u_{2i}} \right)$，Tanner图中各个变量节点的LLR值可以递归地计算得到</p><script type="math/tex;mode=display">\begin{align}
  & L_{N}^{\left( 2i-1 \right)}\left( y_{1}^{N},\hat{u}_{1}^{2i-2} \right)=2{\tanh ^{-1}}\left( \tanh \left( \frac{L_{N/{2}\;}^{\left( i \right)}\left( y_{1}^{N/{2}\;},\hat{u}_{1,o}^{2i-2}\oplus \hat{u}_{1,e}^{2i-2} \right)}{2} \right) \right) \\ 
 & \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \nonumber \cdot \tanh \left( \frac{L_{N/{2}\;}^{\left( i \right)}\left( y_{N/{2}\;+1}^{N},\hat{u}_{1,e}^{2i-2} \right)}{2} \right) \\ 
\end{align}</script><script type="math/tex;mode=display">\begin{align}
  & L_{N}^{\left( 2i \right)}\left( y_{1}^{N},\hat{u}_{1}^{2i-1} \right)=L_{ {N}/{2}\;}^{\left( i \right)}\left( y_{ {N}/{2}\;+1}^{N},\hat{u}_{1,e}^{2i-2} \right)+{ {\left( -1 \right)}^{ { { {\hat{u}}}_{2i-1}}}} \\ 
 & \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \nonumber \cdot L_{ {N}/{2}\;}^{\left( i \right)}\left( y_{1}^{ {N}/{2}\;},\hat{u}_{1,o}^{2i-2}\oplus \hat{u}_{1,e}^{2i-2} \right) \\ 
\end{align}</script><p>若最终得到的$L_{N}^{\left( i \right)}\left( y_{1}^{N},\hat{u}_{1}^{i-1} \right)\ge 0$，则判决为${\hat{u}_{i}}=0$；否则，判决${\hat{u}_{i}}=1$。</p><p>将某一个变量节点的LLR值视为一个随机变量，用$\mathbf{a}\left( z \right)$表示该随机变量的概率密度函数（PDF）。由于信道满足对称性，可以假设发送的比特为全零。从而该变量节点的比特判决值错误的概率为</p><script type="math/tex;mode=display">\begin{equation} 
{P_{e}}=\int_{-\infty }^{0}{\mathbf{a}\left( z \right)}dz
\end{equation}</script><p>在对第$i$个信道进行可靠性计算时，如上图中加粗线条所示，以比特${u_{i}}$对应的变量节点为根节点，逐层扩展，直至最右侧一列变量节点，构成译码树。</p><p>用${\mathbf{a}_{w}}$表示信道输入到最右侧一列变量节点的LLR值的PDF；用$\mathbf{a}_{N}^{\left( i \right)}$表示$L_{N}^{\left( i \right)}\left( y_{1}^{N},\hat{u}_{1}^{i-1} \right)$值的PDF。根据密度进化理论以及式（2）和式（3），假设发送序列为全零比特序列，在$u_{1}^{i-1}$值已知的条件下，序号为$i$的极化信道LLR值可以递归第计算如下</p><script type="math/tex;mode=display">\begin{equation} 
\mathbf{a}_{2N}^{\left( 2i-1 \right)}=\mathbf{a}_{N}^{\left( i \right)}\odot \mathbf{a}_{N}^{\left( i \right)}
\end{equation}</script><script type="math/tex;mode=display">\begin{equation}
\mathbf{a}_{2N}^{\left( i \right)}=\mathbf{a}_{N}^{\left( i \right)}*\mathbf{a}_{N}^{\left( i \right)}
\end{equation}</script><script type="math/tex;mode=display">\begin{equation}
\mathbf{a}_{1}^{\left( 1 \right)}\text{=}{\mathbf{a}_{w}}
\end{equation}</script><p>其中，运算$\odot $与$*$分布表示校验节点与变量节点上的卷积操作。通过概率密度函数$\mathbf{a}_{N}^{\left( i \right)}$与式（4）可以得到各个极化信道$W_{N}^{\left( i \right)}$的可靠性度量$P\left( {A_{i}} \right)$。</p><h1 id="高斯近似（GA）"><a href="#高斯近似（GA）" class="headerlink" title="高斯近似（GA）"></a>高斯近似（GA）</h1><p><br>通过密度进化对极化信道$W_{N}^{\left( i \right)}$的可靠性度量$P\left( {A_{i}} \right)$进行计算，可以适用于任意类型的B-DMC信道。然而，在实际算法实现时，需要维护一个高维的向量以存储（量化后的）概率密度函数$\mathbf{a}_{N}^{\left( i \right)}$。为保证计算结果精确，该向量的维度常取到${10^{6}}$，对如此高维的向量进行式（5）和式（6）的卷积操作，计算复杂度非常高。</p><p>在大多数研究场景下，信道编码的传输信道模型均为BAWGNC信道。在BAWGNC信道下，可以将密度进化中的LLR值的概率密度函数用一族方差为均值2倍的高斯分布来近似，从而简化成了对一维的均值的计算，大大降低计算量，这种对DE的简化计算即为高斯近似（Gaussian Approximation，GA）。</p><p>对噪声方差为${\sigma ^{2}}$的BAWGNC信道，调制方式采用BPSK，若从信道获取的接收信号为$y$。</p><script type="math/tex;mode=display">\begin{equation}
y=\left( 1-2x \right)+z
\end{equation}</script><p>其中发送比特$x\in \left\{ 0,1 \right\}$，$z\sim N\left( 0,{\sigma ^{2}} \right)$。</p><p>假设发送比特为全零序列，则对应的LLR值为</p><script type="math/tex;mode=display">\begin{equation}
LLR\left( y \right)=\ln \frac{p\left( y|x=0 \right)}{p\left( y|x=1 \right)}=\frac{2}{\sigma ^{2}}y
\end{equation}</script><p>其中$y\sim N\left( 1,{\sigma ^{2}} \right)$。因此式（9）中所得的LLR值符合均值为$2/{\sigma ^{2}}\;$、方差为$4/{\sigma ^{2}}\;$的高斯分布。根据已有的高斯近似理论，若输入的消息$\mathbf{a}_{N/{2}\;}^{\left( i \right)}$服从独立的高斯分布，对如式（6）所示的变量节点上的操作，则其输出$\mathbf{a}_{N}^{\left( i \right)}$也服从高斯分布；对如式（5）所示的变量节点上的操作，其输出$\mathbf{a}_{N}^{\left( 2i-1 \right)}$也非常接近高斯分布。由于高斯分布可以有其均值和方差完全决定，因此在概率密度函数的计算过程中值需要考虑均值和方差，但必需满足密度进化的对称条件。如果用$f\left( z \right)$表示LLR的概率密度，则对称条件表示为$f\left( z \right)\text{=}f\left( -z \right){e^{z}}$。对于均值为$m$、方差为${\sigma ^{2}}$的高斯分布，该对称条件可以简化为${\sigma ^{2}}=2m$。因此，在高斯近似中，仅需要考虑一维的变量，即均值$m$。设$\mathbf{a}_{N}^{\left( i \right)}$可以用$N\left( m_{N}^{\left( i \right)},2m_{N}^{\left( i \right)} \right)$表示，则式（5）、式（6）和式（7）中所示的LLR计算过程可以用高斯近似成为</p><script type="math/tex;mode=display">\begin{equation}
m_{2N}^{\left( 2i \right)}={ {\varphi }^{-1}}\left( 1-\left[ 1-\varphi { {\left( m_{N}^{\left( i \right)} \right)}^{2}} \right] \right)
\end{equation}</script><script type="math/tex;mode=display">\begin{equation}
m_{2N}^{\left( 2i \right)}=2m_{N}^{\left( i \right)}
\end{equation}</script><script type="math/tex;mode=display">\begin{equation}
m_{1}^{\left( 1 \right)}={2}/{ { {\sigma }^{2}}}\;
\end{equation}</script><p>其中函数</p><script type="math/tex;mode=display">\begin{equation}
\varphi \left( x \right)=\left\{ \begin{matrix}
   1-\frac{1}{\sqrt{4\pi x}}\int_{-\infty }^{\infty }{\tanh \frac{u}{2}\cdot \exp \left( -\frac{ { {\left( u-x \right)}^{2}}}{4x} \right)du,x>0}  \\
   0\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ ,x=0  \\
\end{matrix} \right.
\end{equation}</script><p>$\varphi \left( x \right)$在$\left[ 0,\infty \right)$上连续单调递减，$\varphi \left( 0 \right)\text{=}1$，$\varphi \left( \infty \right)\text{=0}$，其反函数用${ {\varphi }^{-1}}\left( x \right)$表示。一般情况下，函数$\varphi \left( x \right)$可以使用如下的近似形式计算</p><script type="math/tex;mode=display">\begin{equation}
\varphi \left( x \right)=\left\{ \begin{matrix}
   \sqrt{\frac{\pi }{x}}\left( 1-\frac{10}{7x} \right)\exp \left( -\frac{x}{4} \right),x\ge 10  \\
   \exp \left( -0.4527{ {x}^{-0.86}}+0.0218 \right),0<x<10  \\
\end{matrix} \right.
\end{equation}</script><p>在得到$m_{N}^{\left( i \right)}$后，各极化信道$W_{N}^{\left( i \right)}$在发送全零时对应的接收信号LLR值服从分布$N\left( m_{N}^{\left( i \right)},2m_{N}^{\left( i \right)} \right)$，于是可靠性度量$P\left( { {A}_{i}} \right)$即可计算如下</p><script type="math/tex;mode=display">\begin{equation}
P\left( { {A}_{i}} \right)\text{=}\int\limits_{-\infty }^{0}{\frac{1}{2\sqrt{\pi m_{N}^{\left( i \right)}}}\cdot \exp \left( \frac{-{ {\left( x-m_{N}^{\left( i \right)} \right)}^{2}}}{4m_{N}^{\left( i \right)}} \right)}dx
\end{equation}</script><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p><br>巴氏参数、密度进化和高斯近似法都是计算各分裂信道错误概率$P\left( { {A}_{i}} \right)$的方法，不同的方法有各自的适用范围。巴氏参数法仅适用于BEC，密度进化法适用于所有类型的B-DMC，而高斯近似法则适用于更加实际的BAWGNC。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><br>[1] Arikan E. Channel Polarization: A Method for Constructing Capacity-Achieving Codes for Symmetric Binary-Input Memoryless Channels[J]. IEEE Transactions on Information Theory, 2008, 55(7):3051-3073.<br>[2] 陈凯. 极化编码理论与实用方案研究[D]. 北京邮电大学, 2014.</p><h1 id="相关链接"><a href="#相关链接" class="headerlink" title="相关链接"></a>相关链接</h1><p><br><a href="http://marshallcomm.cn/2017/08/04/polar-code-17-gaussian-approximation2/" target="_blank" rel="external">《Polar Code（17）高斯近似（2）》</a><br><a href="http://marshallcomm.cn/2017/03/17/polar-code-8-gaussian-approximation/" target="_blank" rel="external">《Polar Code（8）高斯近似》</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --&gt;&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;&lt;br&gt;由Arikan发明的Polar Code经典编码算法已在&lt;a href=&quot;https://marshallcomm.github.io/2017/03/04/polar-code-2-encoding-principle/&quot;&gt;《Polar Code（2）编码原理》&lt;/a&gt;中阐明，&lt;a href=&quot;https://marshallcomm.github.io/2017/03/05/polar-code-3-encoding-example/&quot;&gt;《Polar Code（3）编码实例》&lt;/a&gt;则是对前文的举例。在编码实例中，有两个前提假设：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;假设一个二进制删除信道（BEC）；&lt;/li&gt;&lt;li&gt;假设采用计算巴氏参数来评估各分裂子信道的可靠性。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Arikan在讨论信道极化时，针对的是二进制离散无记忆信道（B-DMC），然而在构造极化码时需要计算的巴氏参数$Z\left( W \right)$的适用范围是二进制删除信道。BEC是B-DMC的子集。因此在Polar Code编码时只能回落的BEC来进行构造。&lt;/p&gt;
    
    </summary>
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/categories/Polar-Code/"/>
    
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/tags/Polar-Code/"/>
    
  </entry>
  
  <entry>
    <title>Polar Code（3）编码实例</title>
    <link href="https://marshallcomm.github.io/2017/03/05/polar-code-3-encoding-example/"/>
    <id>https://marshallcomm.github.io/2017/03/05/polar-code-3-encoding-example/</id>
    <published>2017-03-05T12:51:54.000Z</published>
    <updated>2017-08-04T09:02:50.312Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><br>在<a href="https://marshallcomm.github.io/2017/03/04/polar-code-2-encoding-principle/">《Polar Code（2）编码原理》</a>中详细阐述了Polar Code编码原理，为更好地理解编码过程，本文将给出一个编码实例。</p><p>设码长为$N=8$，消息比特数$K=4$。列出所有使用到的公式：</p><script type="math/tex;mode=display">c_{1}^{N}=u_{1}^{N}{G_{N}}</script><script type="math/tex;mode=display">{G_{N}}={B_{N}}{F^{\otimes n}}</script><a id="more"></a><script type="math/tex;mode=display">{F^{\otimes n}}=F\otimes {F^{\otimes \left( n-1 \right)}}</script><script type="math/tex;mode=display">F=\left[ \begin{matrix}
   1 & 0  \\
   1 & 1  \\
\end{matrix} \right]</script><script type="math/tex;mode=display">{B_{N}}={R_{N}}\left( {I_{2}}\otimes {B_{N/{2}\;}} \right)</script><script type="math/tex;mode=display">{B_{2}}={I_{2}}</script><h1 id="极化信道的可靠性估计"><a href="#极化信道的可靠性估计" class="headerlink" title="极化信道的可靠性估计"></a>极化信道的可靠性估计</h1><p><br>假设对于各二进制删除信道（BEC），已计算出各个分裂信道的巴氏参数$Z\left( W_{N}^{\left( i \right)} \right)$。</p><h1 id="比特混合"><a href="#比特混合" class="headerlink" title="比特混合"></a>比特混合</h1><p><br>假设通过第一步得到巴氏参数最小的4个子信道序号为“4，6，7，8”，则消息比特序号集合记为</p><script type="math/tex;mode=display">A=\left\{ 4,6,7,8 \right\}</script><p>则固定比特序号集合为</p><script type="math/tex;mode=display">{A^{c}}=\left\{ 1,2,3,5 \right\}</script><p>设信息比特集合为$\left( {i_{1}},{i_{2}},{i_{3}},{i_{4}} \right)=\left( 1,1,1,1 \right)$，固定比特集合为$\left( 0,0,0,0 \right)$，则最终得到</p><script type="math/tex;mode=display">u_{1}^{8}=\left[ 0,0,0,{i_{1}},0,{i_{2}},{i_{3}},{i_{4}} \right]=\left[ 0,0,0,1,0,1,1,1 \right]</script><h1 id="构造生成矩阵"><a href="#构造生成矩阵" class="headerlink" title="构造生成矩阵"></a>构造生成矩阵</h1><h2 id="求排序矩阵BN"><a href="#求排序矩阵BN" class="headerlink" title="求排序矩阵BN"></a>求排序矩阵BN</h2><p><br><strong>递归式：</strong></p><script type="math/tex;mode=display">{B_{8}}={R_{8}}\left( {I_{2}}\otimes {B_{4}} \right)</script><script type="math/tex;mode=display">{B_{4}}={R_{4}}\left( {I_{2}}\otimes {B_{2}} \right)</script><p><strong>计算：</strong></p><script type="math/tex;mode=display">{B_{2}}=\left[ \begin{matrix}
   1 & 0  \\
   0 & 1  \\
\end{matrix} \right]</script><script type="math/tex;mode=display">{I_{2}}\otimes {B_{2}}=\left[ \begin{matrix}
   1 & 0 & 0 & 0  \\
   0 & 1 & 0 & 0  \\
   0 & 0 & 1 & 0  \\
   0 & 0 & 0 & 1  \\
\end{matrix} \right]</script><p>${R_{4}}$由${I_{4}}$变换得来，先排${I_{4}}$的奇数列，再排${I_{4}}$的偶数列：</p><script type="math/tex;mode=display">{R_{4}}=\left[ \begin{matrix}
   1 & 0 & 0 & 0  \\
   0 & 0 & 1 & 0  \\
   0 & 1 & 0 & 0  \\
   0 & 0 & 0 & 1  \\
\end{matrix} \right]\Leftarrow {I_{4}}=\left[ \begin{matrix}
   1 & 0 & 0 & 0  \\
   0 & 1 & 0 & 0  \\
   0 & 0 & 1 & 0  \\
   0 & 0 & 0 & 1  \\
\end{matrix} \right]</script><script type="math/tex;mode=display">{ {B}_{4}}={ {R}_{4}}\left( { {I}_{2}}\otimes { {B}_{2}} \right)=\left[ \begin{matrix}
   1 & 0 & 0 & 0  \\
   0 & 0 & 1 & 0  \\
   0 & 1 & 0 & 0  \\
   0 & 0 & 0 & 1  \\
\end{matrix} \right]\cdot \left[ \begin{matrix}
   1 & 0 & 0 & 0  \\
   0 & 1 & 0 & 0  \\
   0 & 0 & 1 & 0  \\
   0 & 0 & 0 & 1  \\
\end{matrix} \right]\text{=}\left[ \begin{matrix}
   1 & 0 & 0 & 0  \\
   0 & 0 & 1 & 0  \\
   0 & 1 & 0 & 0  \\
   0 & 0 & 0 & 1  \\
\end{matrix} \right]</script><script type="math/tex;mode=display">{I_{2}}\otimes {B_{4}}=\left[ \begin{matrix}
   1 & 0 & 0 & 0 & 0 & 0 & 0 & 0  \\
   0 & 0 & 1 & 0 & 0 & 0 & 0 & 0  \\
   0 & 1 & 0 & 0 & 0 & 0 & 0 & 0  \\
   0 & 0 & 0 & 1 & 0 & 0 & 0 & 0  \\
   0 & 0 & 0 & 0 & 1 & 0 & 0 & 0  \\
   0 & 0 & 0 & 0 & 0 & 0 & 1 & 0  \\
   0 & 0 & 0 & 0 & 0 & 1 & 0 & 0  \\
   0 & 0 & 0 & 0 & 0 & 0 & 0 & 1  \\
\end{matrix} \right]</script><p>${R_{8}}$由${I_{8}}$变换得来，先排${I_{8}}$的奇数列，再排${I_{8}}$的偶数列：</p><script type="math/tex;mode=display">{R_{8}}=\left[ \begin{matrix}
   1 & 0 & 0 & 0 & 0 & 0 & 0 & 0  \\
   0 & 0 & 0 & 0 & 1 & 0 & 0 & 0  \\
   0 & 1 & 0 & 0 & 0 & 0 & 0 & 0  \\
   0 & 0 & 0 & 0 & 0 & 1 & 0 & 0  \\
   0 & 0 & 1 & 0 & 0 & 0 & 0 & 0  \\
   0 & 0 & 0 & 0 & 0 & 0 & 1 & 0  \\
   0 & 0 & 0 & 1 & 0 & 0 & 0 & 0  \\
   0 & 0 & 0 & 0 & 0 & 0 & 0 & 1  \\
\end{matrix} \right]\Leftarrow {I_{8}}=\left[ \begin{matrix}
   1 & 0 & 0 & 0 & 0 & 0 & 0 & 0  \\
   0 & 1 & 0 & 0 & 0 & 0 & 0 & 0  \\
   0 & 0 & 1 & 0 & 0 & 0 & 0 & 0  \\
   0 & 0 & 0 & 1 & 0 & 0 & 0 & 0  \\
   0 & 0 & 0 & 0 & 1 & 0 & 0 & 0  \\
   0 & 0 & 0 & 0 & 0 & 1 & 0 & 0  \\
   0 & 0 & 0 & 0 & 0 & 0 & 1 & 0  \\
   0 & 0 & 0 & 0 & 0 & 0 & 0 & 1  \\
\end{matrix} \right]</script><script type="math/tex;mode=display">\begin{align}
  & { {B}_{8}}={ {R}_{8}}\left( { {I}_{2}}\otimes { {B}_{4}} \right)=\nonumber \left[ \begin{matrix}
   1 & 0 & 0 & 0 & 0 & 0 & 0 & 0  \\
   0 & 0 & 0 & 0 & 1 & 0 & 0 & 0  \\
   0 & 1 & 0 & 0 & 0 & 0 & 0 & 0  \\
   0 & 0 & 0 & 0 & 0 & 1 & 0 & 0  \\
   0 & 0 & 1 & 0 & 0 & 0 & 0 & 0  \\
   0 & 0 & 0 & 0 & 0 & 0 & 1 & 0  \\
   0 & 0 & 0 & 1 & 0 & 0 & 0 & 0  \\
   0 & 0 & 0 & 0 & 0 & 0 & 0 & 1  \\
\end{matrix} \right]\cdot \left[ \begin{matrix}
   1 & 0 & 0 & 0 & 0 & 0 & 0 & 0  \\
   0 & 0 & 1 & 0 & 0 & 0 & 0 & 0  \\
   0 & 1 & 0 & 0 & 0 & 0 & 0 & 0  \\
   0 & 0 & 0 & 1 & 0 & 0 & 0 & 0  \\
   0 & 0 & 0 & 0 & 1 & 0 & 0 & 0  \\
   0 & 0 & 0 & 0 & 0 & 0 & 1 & 0  \\
   0 & 0 & 0 & 0 & 0 & 1 & 0 & 0  \\
   0 & 0 & 0 & 0 & 0 & 0 & 0 & 1  \\
\end{matrix} \right] \\ 
 & \begin{matrix}
   {} & {} & {} & \begin{matrix}
   {} & {} & = \nonumber \left[ \begin{matrix}
   1 & 0 & 0 & 0 & 0 & 0 & 0 & 0  \\
   0 & 0 & 0 & 0 & 1 & 0 & 0 & 0  \\
   0 & 0 & 1 & 0 & 0 & 0 & 0 & 0  \\
   0 & 0 & 0 & 0 & 0 & 0 & 1 & 0  \\
   0 & 1 & 0 & 0 & 0 & 0 & 0 & 0  \\
   0 & 0 & 0 & 0 & 0 & 1 & 0 & 0  \\
   0 & 0 & 0 & 1 & 0 & 0 & 0 & 0  \\
   0 & 0 & 0 & 0 & 0 & 0 & 0 & 1  \\
\end{matrix} \right]  \\
\end{matrix}  \\
\end{matrix} \\ 
\end{align}</script><h2 id="求F的n次克罗内克积"><a href="#求F的n次克罗内克积" class="headerlink" title="求F的n次克罗内克积"></a>求F的n次克罗内克积</h2><p><br><strong>递归式：</strong></p><script type="math/tex;mode=display">{F^{\otimes 3}}=F\otimes {F^{\otimes 2}}</script><script type="math/tex;mode=display">{F^{\otimes 2}}=F\otimes {F^{\otimes 1}}</script><p><strong>计算：</strong></p><script type="math/tex;mode=display">{F^{\otimes 1}}\text{=}F=\left[ \begin{matrix}
   1 & 0  \\
   1 & 1  \\
\end{matrix} \right]</script><script type="math/tex;mode=display">{F^{\otimes 2}}=F\otimes {F^{\otimes 1}}=\left[ \begin{matrix}
   1 & 0  \\
   1 & 1  \\
\end{matrix} \right]\otimes {F^{\otimes 1}}=\left[ \begin{matrix}
   {F^{\otimes 1}} & 0  \\
   {F^{\otimes 1}} & {F^{\otimes 1}}  \\
\end{matrix} \right]=\left[ \begin{matrix}
   1 & 0 & 0 & 0  \\
   1 & 1 & 0 & 0  \\
   1 & 0 & 1 & 0  \\
   1 & 1 & 1 & 1  \\
\end{matrix} \right]</script><script type="math/tex;mode=display">{F^{\otimes 3}}=F\otimes {F^{\otimes 2}}=\left[ \begin{matrix}
   1 & 0  \\
   1 & 1  \\
\end{matrix} \right]\otimes {F^{\otimes 2}}=\left[ \begin{matrix}
   {F^{\otimes 2}} & 0  \\
   {F^{\otimes 2}} & {F^{\otimes 2}}  \\
\end{matrix} \right]\text{=}\left[ \begin{matrix}
   1 & 0 & 0 & 0 & 0 & 0 & 0 & 0  \\
   1 & 1 & 0 & 0 & 0 & 0 & 0 & 0  \\
   1 & 0 & 1 & 0 & 0 & 0 & 0 & 0  \\
   1 & 1 & 1 & 1 & 0 & 0 & 0 & 0  \\
   1 & 0 & 0 & 0 & 1 & 0 & 0 & 0  \\
   1 & 1 & 0 & 0 & 1 & 1 & 0 & 0  \\
   1 & 0 & 1 & 0 & 1 & 0 & 1 & 0  \\
   1 & 1 & 1 & 1 & 1 & 1 & 1 & 1  \\
\end{matrix} \right]</script><h2 id="求生成矩阵GN"><a href="#求生成矩阵GN" class="headerlink" title="求生成矩阵GN"></a>求生成矩阵GN</h2><p><br><script type="math/tex">\begin{align}
  & { {G}_{8}}={ {B}_{8}}{ {F}^{\otimes 3}}=\nonumber \left[ \begin{matrix}
   1 & 0 & 0 & 0 & 0 & 0 & 0 & 0  \\
   0 & 0 & 0 & 0 & 1 & 0 & 0 & 0  \\
   0 & 0 & 1 & 0 & 0 & 0 & 0 & 0  \\
   0 & 0 & 0 & 0 & 0 & 0 & 1 & 0  \\
   0 & 1 & 0 & 0 & 0 & 0 & 0 & 0  \\
   0 & 0 & 0 & 0 & 0 & 1 & 0 & 0  \\
   0 & 0 & 0 & 1 & 0 & 0 & 0 & 0  \\
   0 & 0 & 0 & 0 & 0 & 0 & 0 & 1  \\
\end{matrix} \right]\cdot \left[ \begin{matrix}
   1 & 0 & 0 & 0 & 0 & 0 & 0 & 0  \\
   1 & 1 & 0 & 0 & 0 & 0 & 0 & 0  \\
   1 & 0 & 1 & 0 & 0 & 0 & 0 & 0  \\
   1 & 1 & 1 & 1 & 0 & 0 & 0 & 0  \\
   1 & 0 & 0 & 0 & 1 & 0 & 0 & 0  \\
   1 & 1 & 0 & 0 & 1 & 1 & 0 & 0  \\
   1 & 0 & 1 & 0 & 1 & 0 & 1 & 0  \\
   1 & 1 & 1 & 1 & 1 & 1 & 1 & 1  \\
\end{matrix} \right] \\ 
 & \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \text{=} \nonumber \left[ \begin{matrix}
   1 & 0 & 0 & 0 & 0 & 0 & 0 & 0  \\
   1 & 0 & 0 & 0 & 1 & 0 & 0 & 0  \\
   1 & 0 & 1 & 0 & 0 & 0 & 0 & 0  \\
   1 & 0 & 1 & 0 & 1 & 0 & 1 & 0  \\
   1 & 1 & 0 & 0 & 0 & 0 & 0 & 0  \\
   1 & 1 & 0 & 0 & 1 & 1 & 0 & 0  \\
   1 & 1 & 1 & 1 & 0 & 0 & 0 & 0  \\
   1 & 1 & 1 & 1 & 1 & 1 & 1 & 1  \\
\end{matrix} \right] \\ 
\end{align}</script></p><h1 id="生成Polar-Code"><a href="#生成Polar-Code" class="headerlink" title="生成Polar Code"></a>生成Polar Code</h1><p><br><script type="math/tex">\nonumber \begin{align}
  & c_{1}^{8}=u_{1}^{8}{G_{8}}=\left[ \begin{matrix}
   0 & 0 & 0 & 1 & 0 & 1 & 1 & 1  \\
\end{matrix} \right]\cdot \left[ \begin{matrix}
   1 & 0 & 0 & 0 & 0 & 0 & 0 & 0  \\
   1 & 0 & 0 & 0 & 1 & 0 & 0 & 0  \\
   1 & 0 & 1 & 0 & 0 & 0 & 0 & 0  \\
   1 & 0 & 1 & 0 & 1 & 0 & 1 & 0  \\
   1 & 1 & 0 & 0 & 0 & 0 & 0 & 0  \\
   1 & 1 & 0 & 0 & 1 & 1 & 0 & 0  \\
   1 & 1 & 1 & 1 & 0 & 0 & 0 & 0  \\
   1 & 1 & 1 & 1 & 1 & 1 & 1 & 1  \\
\end{matrix} \right] \\ 
 & \ \ \ \ =\left[ \nonumber \begin{matrix}
   0 & 1 & 1 & 0 & 1 & 0 & 0 & 1  \\
\end{matrix} \right] \\ 
\end{align}</script></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --&gt;&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;&lt;br&gt;在&lt;a href=&quot;https://marshallcomm.github.io/2017/03/04/polar-code-2-encoding-principle/&quot;&gt;《Polar Code（2）编码原理》&lt;/a&gt;中详细阐述了Polar Code编码原理，为更好地理解编码过程，本文将给出一个编码实例。&lt;/p&gt;&lt;p&gt;设码长为$N=8$，消息比特数$K=4$。列出所有使用到的公式：&lt;/p&gt;&lt;script type=&quot;math/tex;mode=display&quot;&gt;c_{1}^{N}=u_{1}^{N}{G_{N}}&lt;/script&gt;&lt;script type=&quot;math/tex;mode=display&quot;&gt;{G_{N}}={B_{N}}{F^{\otimes n}}&lt;/script&gt;
    
    </summary>
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/categories/Polar-Code/"/>
    
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/tags/Polar-Code/"/>
    
  </entry>
  
  <entry>
    <title>Polar Code（2）编码原理</title>
    <link href="https://marshallcomm.github.io/2017/03/04/polar-code-2-encoding-principle/"/>
    <id>https://marshallcomm.github.io/2017/03/04/polar-code-2-encoding-principle/</id>
    <published>2017-03-04T05:07:05.000Z</published>
    <updated>2017-08-04T09:02:42.583Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><br>在<a href="https://marshallcomm.github.io/2017/03/01/polar-code-1-summary/">《Polar Code（1）概述》</a>中建立了Polar Code初步印象，本文将详细阐述Polar Code编码原理。Polar Code是通过引入信道极化概念而构建的。信道极化分为两个阶段，分别是信道联合和信道分裂。通过信道的联合与分裂，各个子信道的对称容量将呈现两级分化的趋势：随着码长（也就是联合信道数）$N$的增加，一部分子信道的容量趋于1，而其余子信道的容量趋于0。Polar Code正是利用这一信道极化的现象，在容量趋于1的$K$个子信道上传输消息比特，在其余子信道上传输冻结比特（即收发双方已知的固定比特，通常设置为全零）。由此构成的编码即为Polar Code，码率为${K}/{N}\;$。</p><h1 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h1><p><br>一个二进制输入离散无记忆信道（B-DMC）可表示为$W:X\to Y$，$X$是输入符号集合，$Y$是输出符号集合，转移概率为$W\left( y|x \right),x\in X,y\in Y$。由于信道是二进制输入，集合$X=\left\{ 0,1 \right\}$；$Y$和$W\left( y|x \right)$是任意值。对信道$W$的$N$次使用后的信道可表示为${W^{N}}$，则信道${W^{N}}:{X^{N}}\to {Y^{N}}$的转移概率为${W^{N}}\left( y_1^{N}|x_{1}^{N} \right)=\prod\nolimits_{i=1}^{N}{W\left( y|x \right)}$。</p><a id="more"></a><p>对于一个B-DMC $W$，有两个重要的信道参数：</p><p>对称容量（Symmetric Capacity）</p><script type="math/tex;mode=display">I\left( W \right)\triangleq \sum\limits_{y\in Y}{\sum\limits_{x\in X}{\frac{1}{2}}}W\left( y|x \right)\log \frac{W\left( y|x \right)}{\frac{1}{2}W\left( y|0 \right)+\frac{1}{2}W\left( y|1 \right)}</script><p>巴氏参数（Bhattacharyya Parameter）</p><script type="math/tex;mode=display">Z\left( W \right)\triangleq \sum\limits_{y\in Y}{\sqrt{W\left( y|0 \right)W\left( y|1 \right)}}</script><p>$I\left( W \right)$是对信道速率的度量，$Z\left( W \right)$对信道可靠性的度量。$I\left( W \right)$是信道$W$在等概率输入下的可靠传输时的最大速率；而$Z\left( W \right)$是信道$W$只传输0或1下的最大似然判决错误概率的上限。</p><p>$I\left( W \right)$与$Z\left( W \right)$的取值范围均为$\left[ 0,1 \right]$。由于对数以2为底，因此码率和信道容量的单位为bit。$I\left( W \right)$与$Z\left( W \right)$满足这样的关系：且仅当$Z\left( W \right)\approx 0$时，$I\left( W \right)\approx 1$；当且仅当$Z\left( W \right)\approx 1$时，$I\left( W \right)\approx 0$。</p><p>当$W$为对称信道时，$I\left( W \right)$等于香农容量。所谓信道对称，即满足：对于任意$y\in Y$，有$W\left( y|0 \right)=W\left( -y|1 \right)$。二进制对称信道（Binary Symmetric Channel，BSC）和二进制删除信道（Binary Erasure Channel，BEC）都是满足对称性的B-DMC。具体地说，对于$Y=\left\{ 0,1 \right\}$，满足$W\left( 0|0 \right)=W\left( 1|1 \right)$且$W\left( 1|0 \right)=W\left( 0|1 \right)$的B-DMC是为BSC。对于$y\in Y$，满足$W\left( y|0 \right)W\left( y|1 \right)=0$或$W\left( y|0 \right)=W\left( y|1 \right)$的B-DMC是为BEC。对于BEC，符号$y$称为删除符号（Erasure Symbol）。</p><p>行向量$\left( {a_{1}},…,{a_{N}} \right)$在这里简写为$a_{1}^{N}$。对于给定的行向量$a_{1}^{N}$，其子向量表示为$a_{i}^{j},1\le i,j\le N$，且$i\le j$。对于给定的$a_{1}^{N}$和$A\subset \left\{ 1,…,N \right\}$，记${a_{A}}$表示子向量$\left( {a_{i}}:i\in A \right)$。记$a_{1,o}^{j}$表示奇数索引的子向量<br>$\left( {a_{k}}:1\le k\le j;\begin{matrix}<br>k &amp; odd \\<br>\end{matrix} \right)$，记$a_{1,e}^{j}$表示偶数索引的子向量$\left( {a_{k}}:1\le k\le j;\begin{matrix}<br>k &amp; even \\<br>\end{matrix} \right)$。例如，对于向量$a_{1}^{5}=\left( 5,4,6,2,1 \right)$，有$a_{2}^{4}=\left( 4,6,2 \right)$，$a_{1,e}^{5}=\left( 4,2 \right)$，$a_{1,o}^{4}\left( 5,6 \right)$。全零向量则记为$0_{1}^{N}$。</p><p>在此所讨论的向量、矩阵的运算均是在二元域上的运算，即GF（2）。记$\oplus $为模2加，记$\otimes $为克罗内克积（Kronecker Power）。记${A^{\otimes n}}$表示$A$的$n$次克罗内克积，有递归式${A^{\otimes n}}=A\otimes {A^{\otimes \left( n-1 \right)}},n\ge 1$，并且定义${A^{\otimes 0}}=\left[ 1 \right]$。</p><p>记$\left| A \right|$表示集合$A$中元素的个数。记${1_{A}}$表示集合$A$的指示函数，若$x\in A$，则${1_{A\left( x \right)}}=1$；若$x\notin A$，则${1_{A\left( x \right)}}=0$。</p><h1 id="信道极化"><a href="#信道极化" class="headerlink" title="信道极化"></a>信道极化</h1><p><br>信道极化分为两个阶段：信道联合阶段（Channel Combining）和信道分裂（Channel Splitting）阶段。</p><h2 id="信道联合"><a href="#信道联合" class="headerlink" title="信道联合"></a>信道联合</h2><p><br>在这一阶段，联合B-DMC $W$的$N$个独立副本，通过递归方式产生一个向量信道${W_{N}}:{X^{N}}\to {Y^{N}}$，其中$N$为2的幂次$N={2^{n}},n\ge 0$。递归开始于第0级（$n=0$），只使用$W$的1个副本，并定义${W_{1}}\triangleq W$。第1级（$n=1$）递归联合了2个独立副本，如图1所示，得到向量信道${W_{2}}:{X^{2}}\to {Y^{2}}$，其转移概率为</p><script type="math/tex;mode=display">{W_{2}}\left( {y_{1}},{y_{2}}|{u_{1}},{u_{2}} \right)=W\left( {y_{1}}|{u_{1}}\oplus {u_{2}} \right)W\left( {y_{2}}|{u_{2}} \right)</script><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170305/175817308.png" title="图 1 信道${W_{2}}$"></p><p>第2级（$n=2$）递归如图2所示，联合信道${W_{2}}$的2个独立副本得到信道${W_{4}}:{X^{4}}\to {Y^{4}}$，其转移概率为</p><script type="math/tex;mode=display">{W_{4}}\left( y_{1}^{4}|u_{1}^{4} \right)={W_{2}}\left( y_{1}^{2}|{u_{1}}\oplus {u_{2}},{u_{3}}\oplus {u_{4}} \right){W_{2}}\left( y_{3}^{4}|{u_{2}},{u_{4}} \right)</script><p>在图2中，${R_{4}}$是完成从$\left( {s_{1}},{s_{2}},{s_{3}},{s_{4}} \right)$到$v_{1}^{4}=\left( {s_{1}},{s_{3}},{s_{2}},{s_{4}} \right)$的置换操作（排序）。从信道${W_{4}}$的输入${W^{4}}$的输入的映射$u_{1}^{4}\to x_{1}^{4}$可用公式表示为$x_{1}^{4}=u_{1}^{4}{G_{4}}$，${G_{4}}=\left[ \begin{matrix}<br>1 &amp; 0 &amp; 0 &amp; 0 \\<br>1 &amp; 0 &amp; 1 &amp; 0 \\<br>1 &amp; 1 &amp; 0 &amp; 0 \\<br>1 &amp; 1 &amp; 1 &amp; 1 \\<br>\end{matrix} \right]$。因此${W_{4}}$和${W^{4}}$的转移概率有关系式${W_{4}}\left( y_{1}^{4}|u_{1}^{4} \right)={W^{4}}\left( y_{1}^{4}|u_{1}^{4}{G_{4}} \right)$。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170305/191031392.png" title="图 2 信道${W_{4}}$"></p><p>图3所示为递归结构的一般形式。${W_{N/{2}\;}}$的2个独立副本联合产生信道${W_{N}}$。输入向量$u_{1}^{N}$进入信道${W_{N}}$，首先被转换为$s_{1}^{N}$：${s_{2i-1}}={u_{2i-1}}\oplus {u_{2i}}$，${s_{2i}}={u_{2i}}$，$1\le i\le {N}/{2}\;$。${R_{N}}$表示比特反转排序操作，输入为$s_{1}^{N}$，输出为$v_{1}^{N}=\left( {s_{1}},{s_{3}},…,{s_{N-1}},{s_{2}},{s_{4}},…,{s_{N}} \right)$。$v_{1}^{N}$则成为2个${W_{N/{2}\;}}$独立副本的输入。</p><p><img src="http://olyzl8414.bkt.clouddn.com/blog/20170305/192049297.png" title="图 3 信道${W_{N}}$的递归结构"></p><p>映射$u_{1}^{N}\to v_{1}^{N}$是二元域GF（2）上的线性变换。$u_{1}^{N}\to x_{1}^{N}$是由复合信道${W_{N}}$的输入到原始信道${W^{N}}$的输入的映射，其映射过程也是线性变换。因此有$x_{1}^{N}=u_{1}^{N}{G_{N}}$。称${G_{N}}$为$N$维生成矩阵。信道${W_{N}}$和${W^{N}}$的转移概率有如下关系：</p><script type="math/tex;mode=display">{W_{N}}\left( y_{1}^{N}|u_{1}^{N} \right)={W^{N}}\left( y_{1}^{N}|u_{1}^{N}{G_{N}} \right)</script><p>其中$y_{1}^{N}\in {Y^{N}},u_{1}^{N}\in {X^{N}}$。</p><h2 id="信道分裂"><a href="#信道分裂" class="headerlink" title="信道分裂"></a>信道分裂</h2><p><br>这是信道极化的第二阶段。将信道联合构成的复合信道${W_{N}}$分裂为$N$个二进制输入的坐标信道（Coordinate Channels）$W_{N}^{\left( i \right)}:X\to {Y^{N}}\times {X^{i-1}},1\le i\le N$，定义其转移概率为</p><script type="math/tex;mode=display">W_{N}^{\left( i \right)}\left( y_{1}^{N},u_{1}^{i-1}|{u_{i}} \right)\triangleq \sum\limits_{u_{i+1}^{N}\in {X^{N-i}}}{\frac{1}{2^{N-1}}{W_{N}}\left( y_{1}^{N}|u_{1}^{N} \right)}</script><p>其中$\left( y_{1}^{N},u_{1}^{i-1} \right)$表示$W_{N}^{\left( i \right)}$的输出，而${u_{i}}$表示$W_{N}^{\left( i \right)}$的输入。</p><p>奇序分裂子信道和偶序分裂子信道的转移概率由两个递归式得到。对任何$n\ge 0,N={2^{n}},1\le i\le {N}/{2}\;$，有</p><script type="math/tex;mode=display">W_{N}^{\left( 2i-1 \right)}\left( y_{1}^{N},u_{1}^{2i-2}|{u_{2i-1}} \right)=\sum\limits_{u_{2i}}{\frac{1}{2}W_{N/{2}\;}^{\left( i \right)}\left( y_{1}^{N/{2}\;},u_{1,o}^{2i-2}\oplus u_{1,e}^{2i-2}|{u_{2i-1}}\oplus {u_{2i}} \right)\cdot W_{N/{2}\;}^{\left( i \right)}\left( y_{N/{2}\;+1}^{N},u_{1,e}^{2i-2}|{u_{2i}} \right)}</script><script type="math/tex;mode=display">W_{N}^{\left( 2i \right)}\left( y_{1}^{N},u_{1}^{2i-1}|{u_{2i}} \right)=\frac{1}{2}W_{N/{2}\;}^{\left( i \right)}\left( y_{1}^{N/{2}\;},u_{1,o}^{2i-2}\oplus u_{1,e}^{2i-2}|{u_{2i-1}}\oplus {u_{2i}} \right)\cdot W_{N/{2}\;}^{\left( i \right)}\left( y_{N/{2}\;+1}^{N},u_{1,e}^{2i-2}|{u_{2i}} \right)</script><h2 id="信道极化定理"><a href="#信道极化定理" class="headerlink" title="信道极化定理"></a>信道极化定理</h2><p><br><strong>定理1</strong>：对任意B-DMC $W$与任意$\delta \in \left( 0,1 \right)$，当$N$以2的幂次趋近于无穷大时，极化信道$W_{N}^{\left( i \right)}$中，满足$I\left( W_{N}^{\left( i \right)} \right)\in \left( 1-\delta ,1 \right]$的信道数占总信道数$N$的比例趋于$I\left( W \right)$；满足$I\left( W_{N}^{\left( i \right)} \right)\in \left[ 0,\delta \right)$的信道所占的比例趋于$1-I\left( W \right)$。</p><p><strong>定理2</strong>：对任意B-DMC $W$，$I\left( W \right)&gt;0$，且对任意$R&lt;I\left( W \right)$，存在一个序列集合${A_{N}}\subset \left\{ 1,…,N \right\},N\in \left\{ 1,2,…,{2^{n}},… \right\}$，对所有$i\in {A_{N}}$有$\left| {A_{N}} \right|\ge NR$且$Z\left( W_{N}^{\left( i \right)} \right)\le O\left( {N^{-5/{4}\;}} \right)$。</p><h1 id="极化编码"><a href="#极化编码" class="headerlink" title="极化编码"></a>极化编码</h1><p><br>利用极化现象构建的编码可以达到对称容量$I\left( W \right)$，称为极化编码（Polar Coding）。极化编码的基本思想是：只在$Z\left( W_{N}^{\left( i \right)} \right)$近于0的坐标信道$W_{N}^{\left( i \right)}$上发送数据比特。极化码具有一般的二元线性分组码的基本编码要素，因而可以通过显示地写出其生成矩阵来完成编码：</p><script type="math/tex;mode=display">x_{1}^{N}=u_{1}^{N}{G_{N}}</script><p>其中$u_{1}^{N}$为原始比特序列，$x_{1}^{N}$为编码后的比特序列，${G_{N}}$为生成矩阵，码长为$N={2^{n}}$。</p><p>极化编码步骤：</p><ol><li>极化信道可靠性估计</li><li>比特混合</li><li>构造生成矩阵</li></ol><h2 id="极化信道可靠性估计"><a href="#极化信道可靠性估计" class="headerlink" title="极化信道可靠性估计"></a>极化信道可靠性估计</h2><p><br>对于BEC，Arikan给出的方法是计算巴氏参数</p><script type="math/tex;mode=display">Z\left( W_{N}^{\left( i \right)} \right)=\sum\limits_{y_{1}^{N}\in {Y^{N}}}{\sum\limits_{u_{1}^{i-1}\in {X^{i-1}}}{\sqrt{W_{N}^{\left( i \right)}\left( y_{1}^{N},u_{1}^{i-1}|0 \right)W_{N}^{\left( i \right)}\left( y_{1}^{N},u_{1}^{i-1}|1 \right)}}}</script><p>$Z\left( W_{N}^{\left( i \right)} \right)$越小，相应的对称容量$I\left( W_{N}^{\left( i \right)} \right)$越大；反之，$Z\left( W_{N}^{\left( i \right)} \right)$越大，说明该信道越不可靠。</p><p>对于非BEC，如BSC信道或AWGNC，不能得到精确的巴氏参数，需要采用密度进化或高斯近似法估计信道的可靠性，详见<a href="https://marshallcomm.github.io/2017/03/07/polar-code-4-encoding-chan-rel-est/">《Polar Code（4）编码之极化信道可靠性估计》</a>。</p><h2 id="比特混合"><a href="#比特混合" class="headerlink" title="比特混合"></a>比特混合</h2><p><br>在这一步的规则是：选择可靠性最大的$K$个分裂子信道传输消息比特，其他分裂子信道传输冻结比特。这一步的输出即为编码的原始比特$u_{1}^{N}$。</p><p>对于BEC来说，选择巴氏参数最小的$K$个子信道放置消息比特。</p><h2 id="构造生成矩阵"><a href="#构造生成矩阵" class="headerlink" title="构造生成矩阵"></a>构造生成矩阵</h2><p><br>生成矩阵表示为</p><script type="math/tex;mode=display">{G_{N}}\text{=}{B_{N}}{F^{\otimes n}}</script><p>其中${F^{\otimes n}}$表示对矩阵$F=\left[ \begin{matrix}<br>1 &amp; 0 \\<br>1 &amp; 1 \\<br>\end{matrix} \right]$的$n$次克罗内克积，有递归式${F^{\otimes n}}\text{=}F\otimes {F^{\otimes \left( n-1 \right)}}$。${B_{N}}$是排序矩阵，用以完成比特反序重排操作。所有比特反序重排，就是将每个原序列的十进制序号$i\in \left\{ 1,2,…,N \right\}$按二进制表示为$\left( i-1 \right)\to \left( {b_{n}},{b_{n-1}},…,{b_{1}} \right)$，其中${b_{n}}$为最高有效位；再将该二进制序列反序，得到$\left( {b_{1}},{b_{2}},…,{b_{n}} \right)$；最后以${b_{1}}$为最高有效位重新按十进制表示成$\left( {b_{1}},{b_{2}},…,{b_{n}} \right)\to \left( j-1 \right)$，令输出序列的第$j$个元素取值为原序列的第$i$个元素。${B_{N}}$的递归式定义为</p><script type="math/tex;mode=display">{B_{N}}={R_{N}}\left( {I_{2}}\otimes {B_{N/{2}\;}} \right)</script><p>其中${I_{2}}$为2维单位阵，${B_{2}}={I_{2}}$；矩阵${R_{N}}$为置换矩阵，对输入序列完成奇序元素和偶序元素的分离，即先排奇序元素，再排偶序元素，其作为效果如下</p><script type="math/tex;mode=display">\left( {u_{1}},{u_{2}},{u_{3}},{u_{4}},...,u{}_{N} \right)\times {R_{N}}=\left( {u_{1}},{u_{3}},{u_{5}},...,{u_{N-1}},{u_{2}},{u_{4}},{u_{6}},...,{u_{N}} \right)</script><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p><br>本文首先介绍了Polar Code的预备知识，如对称容量、巴氏参数以及所涉及的数学符号的表示。其次介绍了信道极化的两个阶段：信道联合与信道分裂。最后阐述了Polar Code的编码过程：通过构造生成矩阵获得${G_{N}}$，通过计算各个分裂子信道的错误概率用以判断消息比特位置从而获得$u_{1}^{N}$；两者相乘$u_{1}^{N}{G_{N}}$即为Polar Code。</p><p>极化码是一种线性分组码，通过构造生成矩阵而获得编码。只要给定码长$N$，编译码结构就唯一确定。极化码基于信道极化现象，做到了扬长而避短。在最可靠的子信道上传输消息比特是为扬长，在最不可靠的子信道上传输冻结比特是为避短。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><br>[1] Arikan E. Channel Polarization: A Method for Constructing Capacity-Achieving Codes for Symmetric Binary-Input Memoryless Channels[J]. IEEE Transactions on Information Theory, 2008, 55(7):3051-3073.</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --&gt;&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;&lt;br&gt;在&lt;a href=&quot;https://marshallcomm.github.io/2017/03/01/polar-code-1-summary/&quot;&gt;《Polar Code（1）概述》&lt;/a&gt;中建立了Polar Code初步印象，本文将详细阐述Polar Code编码原理。Polar Code是通过引入信道极化概念而构建的。信道极化分为两个阶段，分别是信道联合和信道分裂。通过信道的联合与分裂，各个子信道的对称容量将呈现两级分化的趋势：随着码长（也就是联合信道数）$N$的增加，一部分子信道的容量趋于1，而其余子信道的容量趋于0。Polar Code正是利用这一信道极化的现象，在容量趋于1的$K$个子信道上传输消息比特，在其余子信道上传输冻结比特（即收发双方已知的固定比特，通常设置为全零）。由此构成的编码即为Polar Code，码率为${K}/{N}\;$。&lt;/p&gt;&lt;h1 id=&quot;预备知识&quot;&gt;&lt;a href=&quot;#预备知识&quot; class=&quot;headerlink&quot; title=&quot;预备知识&quot;&gt;&lt;/a&gt;预备知识&lt;/h1&gt;&lt;p&gt;&lt;br&gt;一个二进制输入离散无记忆信道（B-DMC）可表示为$W:X\to Y$，$X$是输入符号集合，$Y$是输出符号集合，转移概率为$W\left( y|x \right),x\in X,y\in Y$。由于信道是二进制输入，集合$X=\left\{ 0,1 \right\}$；$Y$和$W\left( y|x \right)$是任意值。对信道$W$的$N$次使用后的信道可表示为${W^{N}}$，则信道${W^{N}}:{X^{N}}\to {Y^{N}}$的转移概率为${W^{N}}\left( y_1^{N}|x_{1}^{N} \right)=\prod\nolimits_{i=1}^{N}{W\left( y|x \right)}$。&lt;/p&gt;
    
    </summary>
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/categories/Polar-Code/"/>
    
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/tags/Polar-Code/"/>
    
  </entry>
  
  <entry>
    <title>Polar Code（1）概述</title>
    <link href="https://marshallcomm.github.io/2017/03/01/polar-code-1-summary/"/>
    <id>https://marshallcomm.github.io/2017/03/01/polar-code-1-summary/</id>
    <published>2017-03-01T08:23:13.000Z</published>
    <updated>2017-08-04T09:02:32.122Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --><p>2016年11月18日，在美国内华达州里诺召开的3GPP RAN1 #87次会议，确定<strong>Polar Code</strong>作为5G <strong>eMBB</strong>（增强移动宽带）场景下<strong>控制信道</strong>编码方案。</p><p>2008年，Erdal Arikan在国际信息论ISIT会议上首次提出了<strong>信道极化（Channel Polarization）</strong>的概念；2009年在“IEEE Transaction on Information Theory”期刊上发表了一篇长达23页的论文更加详细地阐述了信道极化，并基于信道极化给出了一种新的编码方式，名称为<strong>极化码（Polar Code）</strong>。极化码具有确定性的构造方法，并且是已知的唯一一种能够被严格证明“达到”信道容量的信道编码方法。</p><a id="more"></a><p>从代数编码和概率编码的角度来说，极化码具备了两者各自的特点。首先，只要给定编码长度，极化码的编译码结构就唯一确定了，而且可以通过生成矩阵的形式完成编码过程，这一点和代数编码的常见思维是一致的。其次，极化码在设计时并没有考虑最小距离特性，而是利用了<strong>信道联合（Channel Combination）与信道分裂（Channel Splitting）</strong>的过程来选择具体的编码方案，而且在译码时也是采用概率算法，这一点比较符合概率编码的思想。</p><p>对于长度为$N={2^{n}}$（$n$为任意正整数）的极化码，它利用信道$W$的N个独立副本，进行信道联合和信道分裂，得到新的N个分裂之后的信道$\left\{ W_{N}^{\left( 1 \right)},W_{N}^{\left( 2 \right)},…,W_{N}^{\left( N \right)} \right\}$。随着码长N的增加，分裂之后的信道将向两个极端发展：其中一部分分裂信道会趋近于完美信道，即信道容量趋近于1的无噪声信道；而另一部分分裂信道会趋近于完全噪声信道，即信道容量趋近于0的信道。假设原信道$W$的二进制输入对称容量记作$I\left(W\right)$，那么当码长N趋近于无穷大时，信道容量趋近于1的分裂信道比例约为$K=N\times I\left( W \right)$，而信道容量趋近于0的比例约为$N\times \left( 1-I\left( W \right) \right)$。对于信道容量为1的可靠信道，可以直接放置消息比特而不采用任何编码，即相当于编码速率为$R=1$；而对于信道容量为0的不可靠信道，可以放置发送端和接收端都事先已知的冻结比特，即相当于编码速率为$R=0$。那么当码长$N\to \infty $时，极化码的可达编码速率$R=N\times I\left(W\right)/N=I\left(W\right)$，即在理论上，极化码可以被证明是可达信道容量的。</p><p>在极化码编码时，首先要区分出N个分裂信道的可靠程度，即哪些属于可靠信道，哪些属于不可靠信道。对各个极化信道的可靠性进行度量常用的有三种方法：<strong>巴氏参数</strong>（Bhattacharyya Parameter）法、<strong>密度进化</strong>（Density Evolution，DE）法和<strong>高斯近似</strong>（Gaussian Approximation）法：</p><ol><li>最初，极化码采用巴氏参数$Z\left( W \right)$来作为每个分裂信道的可靠性度量，$Z\left( W \right)$越大表示信道的可靠程度越低。当信道$W$是二元删除信道（Binary Erasure Channel，BEC）时，每个$Z\left( W_{N}^{\left( i \right)} \right)$都可以采用递归的方式计算出来，复杂度为$O\left( N\log N \right)$。然而，对于其他信道，如二进制输入对称信道（Binary-input Symmeric Channel，BSC）或者二进制输入加性高斯白噪声信道（Binary-input Additive White Gaussian Channel，BAWGNC）并不存在准确的能够计算$Z\left( W_{N}^{\left( i \right)} \right)$的方法。</li><li>因此，Mori等人提出了一种采用密度进化方法跟踪每个子信道概率密度函数（Probability Density Function，PDF），从而估计每个子信道错误概率的方法。这种方法适用于所有类型的二进制输入离散无记忆信道（Binary-input Discrete Memoryless Channel，B-DMC）信道。</li><li>在大多数研究场景下，信道编码的传输信道模型均为BAWGNC信道。在BAWGNC信道下，可以将密度进化中的对数似然比（Likelihood Rate，LLR）的概率密度函数用一族方差为均值2倍的高斯分布来近似，从而简化成了对一维均值的计算，大大降低计算量，这种对DE的简化计算即为高斯近似。</li></ol><p>参考文献：<br>[1] Arikan E. Channel polarization: A method for constructing capacity-achieving codes[C]// IEEE International Symposium on Information Theory. IEEE, 2008:1173-1177.<br>[2] Arikan E. Channel Polarization: A Method for Constructing Capacity-Achieving Codes for Symmetric Binary-Input Memoryless Channels[J]. IEEE Transactions on Information Theory, 2008, 55(7):3051-3073.<br>[3] 陈凯. 极化编码理论与实用方案研究[D]. 北京邮电大学, 2014.</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 21 2017 21:59:46 GMT+0800 (中国标准时间) --&gt;&lt;p&gt;2016年11月18日，在美国内华达州里诺召开的3GPP RAN1 #87次会议，确定&lt;strong&gt;Polar Code&lt;/strong&gt;作为5G &lt;strong&gt;eMBB&lt;/strong&gt;（增强移动宽带）场景下&lt;strong&gt;控制信道&lt;/strong&gt;编码方案。&lt;/p&gt;&lt;p&gt;2008年，Erdal Arikan在国际信息论ISIT会议上首次提出了&lt;strong&gt;信道极化（Channel Polarization）&lt;/strong&gt;的概念；2009年在“IEEE Transaction on Information Theory”期刊上发表了一篇长达23页的论文更加详细地阐述了信道极化，并基于信道极化给出了一种新的编码方式，名称为&lt;strong&gt;极化码（Polar Code）&lt;/strong&gt;。极化码具有确定性的构造方法，并且是已知的唯一一种能够被严格证明“达到”信道容量的信道编码方法。&lt;/p&gt;
    
    </summary>
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/categories/Polar-Code/"/>
    
    
      <category term="Polar Code" scheme="https://marshallcomm.github.io/tags/Polar-Code/"/>
    
  </entry>
  
</feed>
